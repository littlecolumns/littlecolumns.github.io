<!doctype html>
<html lang="en-US">

<head>
  <meta charset="utf-8">
  <title>In The Dark - Feature selection with p values</title>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" rel="stylesheet">
  <!-- <link href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.5/css/bulma.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Raleway:400,700|Open+Sans:400,700&display=swap" rel="stylesheet"> -->
  <link rel="stylesheet" href="/ds4j/css/spectre.min.css">
  <link rel="stylesheet" href="/ds4j/css/spectre-exp.min.css">
  <link rel="stylesheet" href="/ds4j/css/spectre-icons.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="/ds4j/css/style.css" rel="stylesheet">
  <link href="/ds4j/css/highlight.css" rel="stylesheet">
</head>

<body>
  <div class="nav-holder bg-secondary">
  <div class='content'>
    <header class="navbar">
      <section class="navbar-section">
        <a href="/ds4j/" class="navbar-brand mr-2">DS4J</a>
      </section>
      <section class="navbar-section">
        <a href="/ds4j/projects" class="btn btn-link">Projects</a>
        <a href="/ds4j/topics" class="btn btn-link">Topics</a>
        <a href="/ds4j/curriculum" class="btn btn-link">Curriculum</a>
        <a href="/ds4j/about" class="btn btn-link">About</a>
      </section>
    </header>
  </div>
</div>
  
<div class="content text-based">
  <div class="columns">
    <div class="column col-12 notebook">
      <ul class="breadcrumb">
        <li class="breadcrumb-item">
          <a href="#">Projects</a>
        </li>
        <li class="breadcrumb-item">
          <a href="/ds4j/apm-reports-jury-bias/">Bias in the jury selection process</a>
        </li>
        <li class="breadcrumb-item">
          <a href="/ds4j/apm-reports-jury-bias/in-the-dark-feature-selection-with-p-values">In The Dark - Feature selection with p values</a>
        </li>
      </ul>

      <div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Feature-selection-with-p-values">Feature selection with p-values<a class="anchor-link" href="#Feature-selection-with-p-values">#</a></h1><p>When you're performing a regression, not all fields have a connection with the output. We'll use p-values to cull the less important columns to refine our model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p class="reading-options">
  <a class="btn" href="/ds4j/apm-reports-jury-bias/in-the-dark-feature-selection-with-p-values">
    <i class="fa fa-sm fa-book"></i>
    Read online
  </a>
  <a class="btn" href="/ds4j/apm-reports-jury-bias/notebooks/In The Dark - Feature selection with p values.ipynb">
    <i class="fa fa-sm fa-download"></i>
    Download notebook
  </a>
  <a class="btn" href="#">
    <i class="fa fa-sm fa-laptop"></i>
    Interactive version
  </a>
</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Imports">Imports<a class="anchor-link" href="#Imports">#</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.width&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.float_format&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Read-in-the-data">Read in the data<a class="anchor-link" href="#Read-in-the-data">#</a></h1><p>We'll start by reading in the pre-cleaned dataset. We've already joined the potential jurors, the trial information, and the judge information. We've also added the <code>struck_by_state</code> column and converted true and false values into ones and zeroes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/jury-cleaned.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id_x</th>
      <th>juror_id</th>
      <th>juror_id__trial__id</th>
      <th>no_responses</th>
      <th>married</th>
      <th>children</th>
      <th>religious</th>
      <th>education</th>
      <th>leans_state</th>
      <th>leans_defense</th>
      <th>leans_ambi</th>
      <th>moral_hardship</th>
      <th>job_hardship</th>
      <th>caretaker</th>
      <th>communication</th>
      <th>medical</th>
      <th>employed</th>
      <th>social</th>
      <th>prior_jury</th>
      <th>crime_victim</th>
      <th>fam_crime_victim</th>
      <th>accused</th>
      <th>fam_accused</th>
      <th>eyewitness</th>
      <th>fam_eyewitness</th>
      <th>...</th>
      <th>prosecutor_3</th>
      <th>prosecutors_more_than_three</th>
      <th>def_attny_1</th>
      <th>def_attny_2</th>
      <th>def_attny_3</th>
      <th>def_attnys_more_than_three</th>
      <th>offense_code_1</th>
      <th>offense_title_1</th>
      <th>offense_code_2</th>
      <th>offense_title_2</th>
      <th>offense_code_3</th>
      <th>offense_title_3</th>
      <th>offense_code_4</th>
      <th>offense_title_4</th>
      <th>offense_code_5</th>
      <th>offense_title_5</th>
      <th>offense_code_6</th>
      <th>offense_title_6</th>
      <th>more_than_six</th>
      <th>verdict</th>
      <th>case_appealed</th>
      <th>batson_claim_by_defense</th>
      <th>batson_claim_by_state</th>
      <th>voir_dire_present</th>
      <th>struck_by_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1521</td>
      <td>107.00000</td>
      <td>3.00000</td>
      <td>0</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>NaN</td>
      <td>0</td>
      <td>M. Kevin Horan</td>
      <td>Elizabeth Davis</td>
      <td>NaN</td>
      <td>0</td>
      <td>41-29-139(a)(1)(b)(3)</td>
      <td>sale of marihuana (less than 30 grams)</td>
      <td>41-29-139(a)(1)(b)(1)</td>
      <td>sale of cocaine</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>Guilty on at least one offense</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1524</td>
      <td>108.00000</td>
      <td>3.00000</td>
      <td>0</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>NaN</td>
      <td>0</td>
      <td>M. Kevin Horan</td>
      <td>Elizabeth Davis</td>
      <td>NaN</td>
      <td>0</td>
      <td>41-29-139(a)(1)(b)(3)</td>
      <td>sale of marihuana (less than 30 grams)</td>
      <td>41-29-139(a)(1)(b)(1)</td>
      <td>sale of cocaine</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>Guilty on at least one offense</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 118 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That is a <strong>lot</strong> of columns! But don't worry, we can <em>add some more, too</em>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Adding-additional-features">Adding additional features<a class="anchor-link" href="#Adding-additional-features">#</a></h1><p>Since we're going to be selecting from a lot of columns, let's get crazy and add a few more.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;is_black&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">race</span> <span class="o">==</span> <span class="s1">&#39;Black&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;same_race&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">race</span> <span class="o">==</span> <span class="n">df</span><span class="o">.</span><span class="n">defendant_race</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;juror_id__gender_m&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">gender</span> <span class="o">==</span> <span class="s1">&#39;Male&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;juror_id__gender_unknown&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">gender</span> <span class="o">==</span> <span class="s1">&#39;Unknown&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;trial__defendant_race_asian&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">defendant_race</span> <span class="o">==</span> <span class="s1">&#39;Asian&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;trial__defendant_race_black&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">defendant_race</span> <span class="o">==</span> <span class="s1">&#39;Black&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;trial__defendant_race_unknown&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">defendant_race</span> <span class="o">==</span> <span class="s1">&#39;Unknown&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;trial__judge_Loper&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">judge</span> <span class="o">==</span> <span class="s1">&#39;Joseph Loper, Jr&#39;</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;trial__judge_OTHER&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">judge</span> <span class="o">==</span> <span class="s1">&#39;Other&#39;</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id_x</th>
      <th>juror_id</th>
      <th>juror_id__trial__id</th>
      <th>no_responses</th>
      <th>married</th>
      <th>children</th>
      <th>religious</th>
      <th>education</th>
      <th>leans_state</th>
      <th>leans_defense</th>
      <th>leans_ambi</th>
      <th>moral_hardship</th>
      <th>job_hardship</th>
      <th>caretaker</th>
      <th>communication</th>
      <th>medical</th>
      <th>employed</th>
      <th>social</th>
      <th>prior_jury</th>
      <th>crime_victim</th>
      <th>fam_crime_victim</th>
      <th>accused</th>
      <th>fam_accused</th>
      <th>eyewitness</th>
      <th>fam_eyewitness</th>
      <th>...</th>
      <th>offense_title_2</th>
      <th>offense_code_3</th>
      <th>offense_title_3</th>
      <th>offense_code_4</th>
      <th>offense_title_4</th>
      <th>offense_code_5</th>
      <th>offense_title_5</th>
      <th>offense_code_6</th>
      <th>offense_title_6</th>
      <th>more_than_six</th>
      <th>verdict</th>
      <th>case_appealed</th>
      <th>batson_claim_by_defense</th>
      <th>batson_claim_by_state</th>
      <th>voir_dire_present</th>
      <th>struck_by_state</th>
      <th>is_black</th>
      <th>same_race</th>
      <th>juror_id__gender_m</th>
      <th>juror_id__gender_unknown</th>
      <th>trial__defendant_race_asian</th>
      <th>trial__defendant_race_black</th>
      <th>trial__defendant_race_unknown</th>
      <th>trial__judge_Loper</th>
      <th>trial__judge_OTHER</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1521</td>
      <td>107.00000</td>
      <td>3.00000</td>
      <td>0</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>sale of cocaine</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>Guilty on at least one offense</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1524</td>
      <td>108.00000</td>
      <td>3.00000</td>
      <td>0</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>unknown</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>sale of cocaine</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0</td>
      <td>Guilty on at least one offense</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>True</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
      <td>True</td>
      <td>False</td>
      <td>False</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 127 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since these new columns are true and false, not ones and zeroes, we'll also need to convert those.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">replace</span><span class="p">({</span>
    <span class="kc">False</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="kc">True</span><span class="p">:</span> <span class="mi">1</span>
<span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Run-a-regression">Run a regression<a class="anchor-link" href="#Run-a-regression">#</a></h1><p>We'll start by running a simple regression: <strong>What's the relaitonship between a potential juror being black, and their chance of being struck by the state?</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;struck_by_state ~ is_black&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Optimization terminated successfully.
         Current function value: 0.463138
         Iterations 6
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>Logit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>struck_by_state</td> <th>  No. Observations:  </th>   <td>  2295</td>  
</tr>
<tr>
  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  2293</td>  
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>  
</tr>
<tr>
  <th>Date:</th>            <td>Mon, 04 Nov 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.1759</td>  
</tr>
<tr>
  <th>Time:</th>                <td>14:03:44</td>     <th>  Log-Likelihood:    </th>  <td> -1062.9</td> 
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1289.7</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.148e-100</td>
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   -2.0515</td> <td>    0.080</td> <td>  -25.692</td> <td> 0.000</td> <td>   -2.208</td> <td>   -1.895</td>
</tr>
<tr>
  <th>is_black</th>  <td>    2.1894</td> <td>    0.109</td> <td>   20.155</td> <td> 0.000</td> <td>    1.976</td> <td>    2.402</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Although this result might tell us how much more likely a black juror is to be rejected than a non-black juror, <strong>it's woefully incomplete</strong>. We know more about the situation than just their race, and it would be irresponsible to just ignore it.</p>
<p>We might start by adding one more feature - let's see <strong>whether the juror is black, and whether the student is male.</strong> Looking at two features instead of one allows us to dig a little bit deeper into the dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;struck_by_state ~ is_black + juror_id__gender_m&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Optimization terminated successfully.
         Current function value: 0.463129
         Iterations 6
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>Logit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>struck_by_state</td> <th>  No. Observations:  </th>  <td>  2295</td>  
</tr>
<tr>
  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  2292</td>  
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  
</tr>
<tr>
  <th>Date:</th>            <td>Mon, 04 Nov 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.1759</td>  
</tr>
<tr>
  <th>Time:</th>                <td>14:07:39</td>     <th>  Log-Likelihood:    </th> <td> -1062.9</td> 
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -1289.7</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.012e-99</td>
</tr>
</table>
<table class="simpletable">
<tr>
           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>          <td>   -2.0611</td> <td>    0.093</td> <td>  -22.074</td> <td> 0.000</td> <td>   -2.244</td> <td>   -1.878</td>
</tr>
<tr>
  <th>is_black</th>           <td>    2.1911</td> <td>    0.109</td> <td>   20.101</td> <td> 0.000</td> <td>    1.977</td> <td>    2.405</td>
</tr>
<tr>
  <th>juror_id__gender_m</th> <td>    0.0221</td> <td>    0.111</td> <td>    0.199</td> <td> 0.842</td> <td>   -0.196</td> <td>    0.240</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's a slightly more complete model, but we have far, far, far more variables than just those two! <strong>How do we pick which features to use?</strong> Do we just throw all of them in?</p>
<p>The process of picking which features you're going to include in your model is called <strong>feature selection</strong>. One simple technique for picking features is to throw everything you know at the problem, then remove anything that (statistically) doesn't seem to make sense.</p>
<p>It might sound like an exceptionally boring, odd, or imprecise method, but let's take a look!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Add-many,-many-more-features">Add many, many more features<a class="anchor-link" href="#Add-many,-many-more-features">#</a></h1><p>We're going to start off by tacking a ton of features onto our regression! We're following the original story's methodology, starting about halfway through - the data is cleaned, we've kicked out some of the features that are always accepted/rejected, and now we're beginning our regressions.</p>
<p>From the report:</p>
<blockquote><p><strong>APM Reports first ran every variable through a logistic regression model.</strong></p>
</blockquote>
<p>Let's do that now - just like we did above, but with a million more variables. It's a little bit longer than the first couple formulas, but they do the exact same thing.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">logit</span><span class="p">(</span><span class="n">formula</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    struck_by_state ~ </span>
<span class="s2">        is_black + same_race + juror_id__gender_m + juror_id__gender_unknown</span>
<span class="s2">        + trial__defendant_race_asian + trial__defendant_race_black</span>
<span class="s2">        + trial__defendant_race_unknown + trial__judge_Loper + trial__judge_OTHER</span>
<span class="s2">        + no_responses + leans_ambi + prior_jury + crime_victim + fam_crime_victim</span>
<span class="s2">        + accused + fam_accused + law_enforcement + fam_law_enforcement</span>
<span class="s2">        + know_def + know_vic + know_wit + know_attny + prior_info + death_hesitation</span>
<span class="s2">&quot;&quot;&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Optimization terminated successfully.
         Current function value: 0.405530
         Iterations 7
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>Logit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>struck_by_state</td> <th>  No. Observations:  </th>   <td>  2295</td>  
</tr>
<tr>
  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  2270</td>  
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    24</td>  
</tr>
<tr>
  <th>Date:</th>            <td>Mon, 04 Nov 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.2784</td>  
</tr>
<tr>
  <th>Time:</th>                <td>14:21:25</td>     <th>  Log-Likelihood:    </th>  <td> -930.69</td> 
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1289.7</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.878e-136</td>
</tr>
</table>
<table class="simpletable">
<tr>
                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>                     <td>   -2.3416</td> <td>    0.223</td> <td>  -10.489</td> <td> 0.000</td> <td>   -2.779</td> <td>   -1.904</td>
</tr>
<tr>
  <th>is_black</th>                      <td>    1.9325</td> <td>    0.143</td> <td>   13.506</td> <td> 0.000</td> <td>    1.652</td> <td>    2.213</td>
</tr>
<tr>
  <th>same_race</th>                     <td>    0.4585</td> <td>    0.142</td> <td>    3.228</td> <td> 0.001</td> <td>    0.180</td> <td>    0.737</td>
</tr>
<tr>
  <th>juror_id__gender_m</th>            <td>    0.0488</td> <td>    0.123</td> <td>    0.397</td> <td> 0.691</td> <td>   -0.192</td> <td>    0.290</td>
</tr>
<tr>
  <th>juror_id__gender_unknown</th>      <td>   -0.0303</td> <td>    0.376</td> <td>   -0.081</td> <td> 0.936</td> <td>   -0.768</td> <td>    0.707</td>
</tr>
<tr>
  <th>trial__defendant_race_asian</th>   <td>    0.7465</td> <td>    0.546</td> <td>    1.368</td> <td> 0.171</td> <td>   -0.323</td> <td>    1.816</td>
</tr>
<tr>
  <th>trial__defendant_race_black</th>   <td>   -0.1635</td> <td>    0.151</td> <td>   -1.079</td> <td> 0.280</td> <td>   -0.460</td> <td>    0.133</td>
</tr>
<tr>
  <th>trial__defendant_race_unknown</th> <td>    0.5651</td> <td>    0.410</td> <td>    1.378</td> <td> 0.168</td> <td>   -0.239</td> <td>    1.369</td>
</tr>
<tr>
  <th>trial__judge_Loper</th>            <td>    0.1796</td> <td>    0.134</td> <td>    1.337</td> <td> 0.181</td> <td>   -0.084</td> <td>    0.443</td>
</tr>
<tr>
  <th>trial__judge_OTHER</th>            <td>    0.0056</td> <td>    0.466</td> <td>    0.012</td> <td> 0.990</td> <td>   -0.907</td> <td>    0.918</td>
</tr>
<tr>
  <th>no_responses</th>                  <td>   -0.2995</td> <td>    0.164</td> <td>   -1.822</td> <td> 0.068</td> <td>   -0.622</td> <td>    0.023</td>
</tr>
<tr>
  <th>leans_ambi</th>                    <td>    0.3274</td> <td>    0.666</td> <td>    0.492</td> <td> 0.623</td> <td>   -0.977</td> <td>    1.632</td>
</tr>
<tr>
  <th>prior_jury</th>                    <td>   -0.2290</td> <td>    0.210</td> <td>   -1.089</td> <td> 0.276</td> <td>   -0.641</td> <td>    0.183</td>
</tr>
<tr>
  <th>crime_victim</th>                  <td>   -0.0287</td> <td>    0.315</td> <td>   -0.091</td> <td> 0.928</td> <td>   -0.647</td> <td>    0.589</td>
</tr>
<tr>
  <th>fam_crime_victim</th>              <td>    0.5037</td> <td>    0.281</td> <td>    1.792</td> <td> 0.073</td> <td>   -0.047</td> <td>    1.055</td>
</tr>
<tr>
  <th>accused</th>                       <td>    2.4623</td> <td>    0.548</td> <td>    4.492</td> <td> 0.000</td> <td>    1.388</td> <td>    3.537</td>
</tr>
<tr>
  <th>fam_accused</th>                   <td>    1.7964</td> <td>    0.175</td> <td>   10.275</td> <td> 0.000</td> <td>    1.454</td> <td>    2.139</td>
</tr>
<tr>
  <th>law_enforcement</th>               <td>   -0.9703</td> <td>    0.503</td> <td>   -1.929</td> <td> 0.054</td> <td>   -1.957</td> <td>    0.016</td>
</tr>
<tr>
  <th>fam_law_enforcement</th>           <td>   -0.6832</td> <td>    0.173</td> <td>   -3.957</td> <td> 0.000</td> <td>   -1.022</td> <td>   -0.345</td>
</tr>
<tr>
  <th>know_def</th>                      <td>    1.3204</td> <td>    0.239</td> <td>    5.536</td> <td> 0.000</td> <td>    0.853</td> <td>    1.788</td>
</tr>
<tr>
  <th>know_vic</th>                      <td>    0.2446</td> <td>    0.239</td> <td>    1.022</td> <td> 0.307</td> <td>   -0.224</td> <td>    0.714</td>
</tr>
<tr>
  <th>know_wit</th>                      <td>   -0.3940</td> <td>    0.236</td> <td>   -1.666</td> <td> 0.096</td> <td>   -0.857</td> <td>    0.069</td>
</tr>
<tr>
  <th>know_attny</th>                    <td>    0.3438</td> <td>    0.237</td> <td>    1.451</td> <td> 0.147</td> <td>   -0.120</td> <td>    0.808</td>
</tr>
<tr>
  <th>prior_info</th>                    <td>   -0.2074</td> <td>    0.200</td> <td>   -1.039</td> <td> 0.299</td> <td>   -0.599</td> <td>    0.184</td>
</tr>
<tr>
  <th>death_hesitation</th>              <td>    1.8562</td> <td>    0.598</td> <td>    3.103</td> <td> 0.002</td> <td>    0.684</td> <td>    3.029</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="No,-wait!-We're-going-to-do-this-a-different-way">No, wait! We're going to do this a different way<a class="anchor-link" href="#No,-wait!-We're-going-to-do-this-a-different-way">#</a></h2><p>I know that writing things out in formulas is nice a pretty and very very readable! <strong>But we're going to stop doing that, right now.</strong></p>
<p>Unfortunately, the writing-out-formulas method involves, well, writing out formulas. Manually! And if we're going to be automating this process, we don't want to write out a bunch of <code>... + ... + ... + ...</code> statements manually as we filter out different columns.</p>
<blockquote><p>Yes, you could technically automate the <code>... + ... + ... + ...</code> process but the code is kinda ugly.</p>
</blockquote>
<p>Instead of writing out formulas, we're going to make dataframes with <em>exactly</em> the columns we're using, and feed that to our regression. To start, let's make a list of the columns we'll use in our regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;is_black&#39;</span><span class="p">,</span>
    <span class="s1">&#39;same_race&#39;</span><span class="p">,</span>
    <span class="s1">&#39;juror_id__gender_m&#39;</span><span class="p">,</span>
    <span class="s1">&#39;juror_id__gender_unknown&#39;</span><span class="p">,</span>
    <span class="s1">&#39;trial__defendant_race_asian&#39;</span><span class="p">,</span>
    <span class="s1">&#39;trial__defendant_race_black&#39;</span><span class="p">,</span>
    <span class="s1">&#39;trial__defendant_race_unknown&#39;</span><span class="p">,</span>
    <span class="s1">&#39;trial__judge_Loper&#39;</span><span class="p">,</span>
    <span class="s1">&#39;trial__judge_OTHER&#39;</span><span class="p">,</span>
    <span class="s1">&#39;no_responses&#39;</span><span class="p">,</span>
    <span class="s1">&#39;leans_ambi&#39;</span><span class="p">,</span>
    <span class="s1">&#39;prior_jury&#39;</span><span class="p">,</span>
    <span class="s1">&#39;crime_victim&#39;</span><span class="p">,</span>
    <span class="s1">&#39;fam_crime_victim&#39;</span><span class="p">,</span>
    <span class="s1">&#39;accused&#39;</span><span class="p">,</span>
    <span class="s1">&#39;fam_accused&#39;</span><span class="p">,</span>
    <span class="s1">&#39;law_enforcement&#39;</span><span class="p">,</span>
    <span class="s1">&#39;fam_law_enforcement&#39;</span><span class="p">,</span>
    <span class="s1">&#39;know_def&#39;</span><span class="p">,</span>
    <span class="s1">&#39;know_vic&#39;</span><span class="p">,</span>
    <span class="s1">&#39;know_wit&#39;</span><span class="p">,</span>
    <span class="s1">&#39;know_attny&#39;</span><span class="p">,</span>
    <span class="s1">&#39;prior_info&#39;</span><span class="p">,</span>
    <span class="s1">&#39;death_hesitation&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This list of columns will allow us to filter our original dataframe to keep only the columns we're interested in. Then we'll feed this to <code>sm.Logit</code>, which does logistic regressions with dataframes instead of written formulas. It's not what we did before, but it's the same basic idea and the exact same results.</p>
<blockquote><p><strong>If you're curious:</strong> We need to do <code>sm.add_constant(X)</code> below because by default <code>smf.Logit</code> doesn't add an intercept. If you use a writen formula with <code>sm.logit</code>, though, it <em>does</em> add an intercept. If you aren't quite sure what that means, it's okay, just know we need the constant to make the two work methods the same. You can also read TODO LINK for more information.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">struck_by_state</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Optimization terminated successfully.
         Current function value: 0.405530
         Iterations 7
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>Logit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>struck_by_state</td> <th>  No. Observations:  </th>   <td>  2295</td>  
</tr>
<tr>
  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  2270</td>  
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>    24</td>  
</tr>
<tr>
  <th>Date:</th>            <td>Mon, 04 Nov 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.2784</td>  
</tr>
<tr>
  <th>Time:</th>                <td>14:34:28</td>     <th>  Log-Likelihood:    </th>  <td> -930.69</td> 
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1289.7</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.878e-136</td>
</tr>
</table>
<table class="simpletable">
<tr>
                <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>                         <td>   -2.3416</td> <td>    0.223</td> <td>  -10.489</td> <td> 0.000</td> <td>   -2.779</td> <td>   -1.904</td>
</tr>
<tr>
  <th>is_black</th>                      <td>    1.9325</td> <td>    0.143</td> <td>   13.506</td> <td> 0.000</td> <td>    1.652</td> <td>    2.213</td>
</tr>
<tr>
  <th>same_race</th>                     <td>    0.4585</td> <td>    0.142</td> <td>    3.228</td> <td> 0.001</td> <td>    0.180</td> <td>    0.737</td>
</tr>
<tr>
  <th>juror_id__gender_m</th>            <td>    0.0488</td> <td>    0.123</td> <td>    0.397</td> <td> 0.691</td> <td>   -0.192</td> <td>    0.290</td>
</tr>
<tr>
  <th>juror_id__gender_unknown</th>      <td>   -0.0303</td> <td>    0.376</td> <td>   -0.081</td> <td> 0.936</td> <td>   -0.768</td> <td>    0.707</td>
</tr>
<tr>
  <th>trial__defendant_race_asian</th>   <td>    0.7465</td> <td>    0.546</td> <td>    1.368</td> <td> 0.171</td> <td>   -0.323</td> <td>    1.816</td>
</tr>
<tr>
  <th>trial__defendant_race_black</th>   <td>   -0.1635</td> <td>    0.151</td> <td>   -1.079</td> <td> 0.280</td> <td>   -0.460</td> <td>    0.133</td>
</tr>
<tr>
  <th>trial__defendant_race_unknown</th> <td>    0.5651</td> <td>    0.410</td> <td>    1.378</td> <td> 0.168</td> <td>   -0.239</td> <td>    1.369</td>
</tr>
<tr>
  <th>trial__judge_Loper</th>            <td>    0.1796</td> <td>    0.134</td> <td>    1.337</td> <td> 0.181</td> <td>   -0.084</td> <td>    0.443</td>
</tr>
<tr>
  <th>trial__judge_OTHER</th>            <td>    0.0056</td> <td>    0.466</td> <td>    0.012</td> <td> 0.990</td> <td>   -0.907</td> <td>    0.918</td>
</tr>
<tr>
  <th>no_responses</th>                  <td>   -0.2995</td> <td>    0.164</td> <td>   -1.822</td> <td> 0.068</td> <td>   -0.622</td> <td>    0.023</td>
</tr>
<tr>
  <th>leans_ambi</th>                    <td>    0.3274</td> <td>    0.666</td> <td>    0.492</td> <td> 0.623</td> <td>   -0.977</td> <td>    1.632</td>
</tr>
<tr>
  <th>prior_jury</th>                    <td>   -0.2290</td> <td>    0.210</td> <td>   -1.089</td> <td> 0.276</td> <td>   -0.641</td> <td>    0.183</td>
</tr>
<tr>
  <th>crime_victim</th>                  <td>   -0.0287</td> <td>    0.315</td> <td>   -0.091</td> <td> 0.928</td> <td>   -0.647</td> <td>    0.589</td>
</tr>
<tr>
  <th>fam_crime_victim</th>              <td>    0.5037</td> <td>    0.281</td> <td>    1.792</td> <td> 0.073</td> <td>   -0.047</td> <td>    1.055</td>
</tr>
<tr>
  <th>accused</th>                       <td>    2.4623</td> <td>    0.548</td> <td>    4.492</td> <td> 0.000</td> <td>    1.388</td> <td>    3.537</td>
</tr>
<tr>
  <th>fam_accused</th>                   <td>    1.7964</td> <td>    0.175</td> <td>   10.275</td> <td> 0.000</td> <td>    1.454</td> <td>    2.139</td>
</tr>
<tr>
  <th>law_enforcement</th>               <td>   -0.9703</td> <td>    0.503</td> <td>   -1.929</td> <td> 0.054</td> <td>   -1.957</td> <td>    0.016</td>
</tr>
<tr>
  <th>fam_law_enforcement</th>           <td>   -0.6832</td> <td>    0.173</td> <td>   -3.957</td> <td> 0.000</td> <td>   -1.022</td> <td>   -0.345</td>
</tr>
<tr>
  <th>know_def</th>                      <td>    1.3204</td> <td>    0.239</td> <td>    5.536</td> <td> 0.000</td> <td>    0.853</td> <td>    1.788</td>
</tr>
<tr>
  <th>know_vic</th>                      <td>    0.2446</td> <td>    0.239</td> <td>    1.022</td> <td> 0.307</td> <td>   -0.224</td> <td>    0.714</td>
</tr>
<tr>
  <th>know_wit</th>                      <td>   -0.3940</td> <td>    0.236</td> <td>   -1.666</td> <td> 0.096</td> <td>   -0.857</td> <td>    0.069</td>
</tr>
<tr>
  <th>know_attny</th>                    <td>    0.3438</td> <td>    0.237</td> <td>    1.451</td> <td> 0.147</td> <td>   -0.120</td> <td>    0.808</td>
</tr>
<tr>
  <th>prior_info</th>                    <td>   -0.2074</td> <td>    0.200</td> <td>   -1.039</td> <td> 0.299</td> <td>   -0.599</td> <td>    0.184</td>
</tr>
<tr>
  <th>death_hesitation</th>              <td>    1.8562</td> <td>    0.598</td> <td>    3.103</td> <td> 0.002</td> <td>    0.684</td> <td>    3.029</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's a <strong>lot lot lot</strong> of columns, and not all of them are useful!</p>
<p>P-values - the <code>P&gt;|z|</code> column - are commonly referred to as "what's the chance that this result was just an accident?" For example, <strong>juror_id__gender_m</strong> has a p-value of 0.691, which (kind of, somewhat) means there's a 69.1% chance that this was just random fluctuations in the data, and nothing meaningful.</p>
<blockquote><p><strong>That isn't actually what p-values mean,</strong> but just work with me here! It's definitely close enough conceptually for what we're doing. You could also read <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4635100/">something like this</a> if you want more details about what p-values really mean.</p>
</blockquote>
<p>Generally speaking, most people feel that keeping that chance at below 5% makes a result meaningful. From a technical perspective, that would mean only the variables with a p-value under 0.05 are meaningful.</p>
<p>If you look at these p-values, they're all over the place - some are bascially zero, while one is as high as 98%!</p>
<h1 id="Feature-selection-based-on-p-values">Feature selection based on p values<a class="anchor-link" href="#Feature-selection-based-on-p-values">#</a></h1><p>When you're trying to decide what features should go into your model and what shouldn't, <strong>p-values</strong> seem to be are one thing to pay attention to. If a feature is likely just related to our outcome by chance, it doesn't seem very effective, does it? We should probably remove those columns to simplify things and remove noise.</p>
<p>From APM Reports' whitepaper:</p>
<blockquote><p>APM Reports first ran every variable through a logistic regression model. <strong>We then removed all variables with a p-value &gt; 0.1.</strong></p>
</blockquote>
<p>We can do the same thing! It can be done pretty easily with some fun coding tricks, so let's give it a shot.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Filtering-regression-variables-by-p-values-(the-explain-y-way)">Filtering regression variables by p values (the explain-y way)<a class="anchor-link" href="#Filtering-regression-variables-by-p-values-(the-explain-y-way)">#</a></h2><p>In other notebooks, we've taken results of a regression and put them into another dataframe for easy viewing. For example, we can do that now and sort it by p-values.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;coef&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="s1">&#39;odds ratio&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">),</span>
    <span class="s1">&#39;pvalue&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="p">,</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">index</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;pvalue&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">coefs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coef</th>
      <th>odds ratio</th>
      <th>pvalue</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>trial__judge_OTHER</th>
      <td>0.00565</td>
      <td>1.00566</td>
      <td>0.99032</td>
      <td>trial__judge_OTHER</td>
    </tr>
    <tr>
      <th>juror_id__gender_unknown</th>
      <td>-0.03033</td>
      <td>0.97012</td>
      <td>0.93575</td>
      <td>juror_id__gender_unknown</td>
    </tr>
    <tr>
      <th>crime_victim</th>
      <td>-0.02865</td>
      <td>0.97175</td>
      <td>0.92758</td>
      <td>crime_victim</td>
    </tr>
    <tr>
      <th>juror_id__gender_m</th>
      <td>0.04885</td>
      <td>1.05006</td>
      <td>0.69120</td>
      <td>juror_id__gender_m</td>
    </tr>
    <tr>
      <th>leans_ambi</th>
      <td>0.32740</td>
      <td>1.38736</td>
      <td>0.62276</td>
      <td>leans_ambi</td>
    </tr>
    <tr>
      <th>know_vic</th>
      <td>0.24461</td>
      <td>1.27712</td>
      <td>0.30675</td>
      <td>know_vic</td>
    </tr>
    <tr>
      <th>prior_info</th>
      <td>-0.20741</td>
      <td>0.81269</td>
      <td>0.29879</td>
      <td>prior_info</td>
    </tr>
    <tr>
      <th>trial__defendant_race_black</th>
      <td>-0.16346</td>
      <td>0.84920</td>
      <td>0.28040</td>
      <td>trial__defendant_race_black</td>
    </tr>
    <tr>
      <th>prior_jury</th>
      <td>-0.22904</td>
      <td>0.79530</td>
      <td>0.27603</td>
      <td>prior_jury</td>
    </tr>
    <tr>
      <th>trial__judge_Loper</th>
      <td>0.17956</td>
      <td>1.19669</td>
      <td>0.18116</td>
      <td>trial__judge_Loper</td>
    </tr>
    <tr>
      <th>trial__defendant_race_asian</th>
      <td>0.74649</td>
      <td>2.10958</td>
      <td>0.17131</td>
      <td>trial__defendant_race_asian</td>
    </tr>
    <tr>
      <th>trial__defendant_race_unknown</th>
      <td>0.56507</td>
      <td>1.75957</td>
      <td>0.16818</td>
      <td>trial__defendant_race_unknown</td>
    </tr>
    <tr>
      <th>know_attny</th>
      <td>0.34379</td>
      <td>1.41029</td>
      <td>0.14665</td>
      <td>know_attny</td>
    </tr>
    <tr>
      <th>know_wit</th>
      <td>-0.39398</td>
      <td>0.67437</td>
      <td>0.09566</td>
      <td>know_wit</td>
    </tr>
    <tr>
      <th>fam_crime_victim</th>
      <td>0.50367</td>
      <td>1.65478</td>
      <td>0.07320</td>
      <td>fam_crime_victim</td>
    </tr>
    <tr>
      <th>no_responses</th>
      <td>-0.29947</td>
      <td>0.74121</td>
      <td>0.06846</td>
      <td>no_responses</td>
    </tr>
    <tr>
      <th>law_enforcement</th>
      <td>-0.97034</td>
      <td>0.37895</td>
      <td>0.05379</td>
      <td>law_enforcement</td>
    </tr>
    <tr>
      <th>death_hesitation</th>
      <td>1.85622</td>
      <td>6.39948</td>
      <td>0.00191</td>
      <td>death_hesitation</td>
    </tr>
    <tr>
      <th>same_race</th>
      <td>0.45847</td>
      <td>1.58165</td>
      <td>0.00125</td>
      <td>same_race</td>
    </tr>
    <tr>
      <th>fam_law_enforcement</th>
      <td>-0.68325</td>
      <td>0.50497</td>
      <td>0.00008</td>
      <td>fam_law_enforcement</td>
    </tr>
    <tr>
      <th>accused</th>
      <td>2.46227</td>
      <td>11.73140</td>
      <td>0.00001</td>
      <td>accused</td>
    </tr>
    <tr>
      <th>know_def</th>
      <td>1.32043</td>
      <td>3.74504</td>
      <td>0.00000</td>
      <td>know_def</td>
    </tr>
    <tr>
      <th>fam_accused</th>
      <td>1.79644</td>
      <td>6.02814</td>
      <td>0.00000</td>
      <td>fam_accused</td>
    </tr>
    <tr>
      <th>const</th>
      <td>-2.34159</td>
      <td>0.09618</td>
      <td>0.00000</td>
      <td>const</td>
    </tr>
    <tr>
      <th>is_black</th>
      <td>1.93254</td>
      <td>6.90702</td>
      <td>0.00000</td>
      <td>is_black</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Even though we do have odds ratios for each of these columns, the <strong>ones with high p-values are just noise</strong>. It's no use talking about a feature if its relationship to the output is likely just accidental.</p>
<p>For example: <code>trial__judge_OTHER</code> has a 99% chance of being nothing but chance! That's definitely gotta go. This is what we'll be doing by filtering by p-values, getting rid of clutter that doesn't really mean anything. They also confuse our model and get in the way of our other, useful features, too ("Pay attention to the things that matter!").</p>
<p>If we wanted to be <strong>very explicit</strong> about what's happening when we're picking our useful features and kicking out the chance-y ones, we could use this dataframe to find everything with a p value of less than <code>0.1</code>.</p>
<p>First we'll filter for features that meet the p-value threshold. Then we'll drop <code>const</code> because it isn't <em>actually</em> one of our columns, it's just some magic thrown in by the regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">coefs</span><span class="p">[</span><span class="n">coefs</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;const&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coef</th>
      <th>odds ratio</th>
      <th>pvalue</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>know_wit</th>
      <td>-0.39398</td>
      <td>0.67437</td>
      <td>0.09566</td>
      <td>know_wit</td>
    </tr>
    <tr>
      <th>fam_crime_victim</th>
      <td>0.50367</td>
      <td>1.65478</td>
      <td>0.07320</td>
      <td>fam_crime_victim</td>
    </tr>
    <tr>
      <th>no_responses</th>
      <td>-0.29947</td>
      <td>0.74121</td>
      <td>0.06846</td>
      <td>no_responses</td>
    </tr>
    <tr>
      <th>law_enforcement</th>
      <td>-0.97034</td>
      <td>0.37895</td>
      <td>0.05379</td>
      <td>law_enforcement</td>
    </tr>
    <tr>
      <th>death_hesitation</th>
      <td>1.85622</td>
      <td>6.39948</td>
      <td>0.00191</td>
      <td>death_hesitation</td>
    </tr>
    <tr>
      <th>same_race</th>
      <td>0.45847</td>
      <td>1.58165</td>
      <td>0.00125</td>
      <td>same_race</td>
    </tr>
    <tr>
      <th>fam_law_enforcement</th>
      <td>-0.68325</td>
      <td>0.50497</td>
      <td>0.00008</td>
      <td>fam_law_enforcement</td>
    </tr>
    <tr>
      <th>accused</th>
      <td>2.46227</td>
      <td>11.73140</td>
      <td>0.00001</td>
      <td>accused</td>
    </tr>
    <tr>
      <th>know_def</th>
      <td>1.32043</td>
      <td>3.74504</td>
      <td>0.00000</td>
      <td>know_def</td>
    </tr>
    <tr>
      <th>fam_accused</th>
      <td>1.79644</td>
      <td>6.02814</td>
      <td>0.00000</td>
      <td>fam_accused</td>
    </tr>
    <tr>
      <th>is_black</th>
      <td>1.93254</td>
      <td>6.90702</td>
      <td>0.00000</td>
      <td>is_black</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks pretty good! Now we can grab the name of the column and we'll be all set.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">feature_cols</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[</span><span class="n">coefs</span><span class="o">.</span><span class="n">pvalue</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">]</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;const&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">index</span>
<span class="n">feature_cols</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;know_wit&#39;, &#39;fam_crime_victim&#39;, &#39;no_responses&#39;, &#39;law_enforcement&#39;, &#39;death_hesitation&#39;,
       &#39;same_race&#39;, &#39;fam_law_enforcement&#39;, &#39;accused&#39;, &#39;know_def&#39;, &#39;fam_accused&#39;, &#39;is_black&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>We're using <code>.index</code> because it displays nicer than looking at <code>.name</code>.</p>
</blockquote>
<h2 id="Filtering-regression-variables-by-p-values-(the-short-way)">Filtering regression variables by p values (the short way)<a class="anchor-link" href="#Filtering-regression-variables-by-p-values-(the-short-way)">#</a></h2><p>While this method works, and might be easier to read, <strong>I prefer a more compact technique.</strong> We can't always use it - sometimes you have calculated columns or weird categories or whatever - but it's great when it works.</p>
<p>Instead of dragging ourselves through a dataframe, we can just look at the <strong>p values for the results.</strong> We'll also drop <code>const</code> again, since it isn't a real column.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;const&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>is_black                        0.00000
same_race                       0.00125
juror_id__gender_m              0.69120
juror_id__gender_unknown        0.93575
trial__defendant_race_asian     0.17131
trial__defendant_race_black     0.28040
trial__defendant_race_unknown   0.16818
trial__judge_Loper              0.18116
trial__judge_OTHER              0.99032
no_responses                    0.06846
leans_ambi                      0.62276
prior_jury                      0.27603
crime_victim                    0.92758
fam_crime_victim                0.07320
accused                         0.00001
fam_accused                     0.00000
law_enforcement                 0.05379
fam_law_enforcement             0.00008
know_def                        0.00000
know_vic                        0.30675
know_wit                        0.09566
know_attny                      0.14665
prior_info                      0.29879
death_hesitation                0.00191
dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we can compare each one of those p-values to <code>0.1</code>, just like we did before.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;const&#39;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>is_black                          True
same_race                         True
juror_id__gender_m               False
juror_id__gender_unknown         False
trial__defendant_race_asian      False
trial__defendant_race_black      False
trial__defendant_race_unknown    False
trial__judge_Loper               False
trial__judge_OTHER               False
no_responses                      True
leans_ambi                       False
prior_jury                       False
crime_victim                     False
fam_crime_victim                  True
accused                           True
fam_accused                       True
law_enforcement                   True
fam_law_enforcement               True
know_def                          True
know_vic                         False
know_wit                          True
know_attny                       False
prior_info                       False
death_hesitation                  True
dtype: bool</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This gives us a set of true and falses. You know the original variable we used to feed into our logistic regression, <code>X</code>? We can ask X for a list of all the columns we used in our regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;const&#39;, &#39;is_black&#39;, &#39;same_race&#39;, &#39;juror_id__gender_m&#39;, &#39;juror_id__gender_unknown&#39;,
       &#39;trial__defendant_race_asian&#39;, &#39;trial__defendant_race_black&#39;,
       &#39;trial__defendant_race_unknown&#39;, &#39;trial__judge_Loper&#39;, &#39;trial__judge_OTHER&#39;, &#39;no_responses&#39;,
       &#39;leans_ambi&#39;, &#39;prior_jury&#39;, &#39;crime_victim&#39;, &#39;fam_crime_victim&#39;, &#39;accused&#39;, &#39;fam_accused&#39;,
       &#39;law_enforcement&#39;, &#39;fam_law_enforcement&#39;, &#39;know_def&#39;, &#39;know_vic&#39;, &#39;know_wit&#39;, &#39;know_attny&#39;,
       &#39;prior_info&#39;, &#39;death_hesitation&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And then filter that list for all the columns that had an <strong>acceptable p-value</strong>. We can then take those column names and use them as our new list of feature columns!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;const&#39;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;is_black&#39;, &#39;same_race&#39;, &#39;no_responses&#39;, &#39;fam_crime_victim&#39;, &#39;accused&#39;, &#39;fam_accused&#39;,
       &#39;law_enforcement&#39;, &#39;fam_law_enforcement&#39;, &#39;know_def&#39;, &#39;know_wit&#39;, &#39;death_hesitation&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And there we go!</p>
<h2 id="Filtering-regression-variables-by-p-values-(the-short,-in-action)">Filtering regression variables by p values (the short, in action)<a class="anchor-link" href="#Filtering-regression-variables-by-p-values-(the-short,-in-action)">#</a></h2><p>We broke the p-values filter into a lot of steps, but we can actually bake it into a single line. If we want to re-run our regression with only the columns that have a p-value less than <code>0.1</code>, it's a small tweak to our original regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Filter our original features to only keep ones with a p-value less than 0.1</span>
<span class="n">feature_cols</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;const&#39;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">]</span>

<span class="c1"># Run our regression just like we normally do</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">struck_by_state</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-1-2a76a3b2cb2e&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-red-fg"># Filter our original features to only keep ones with a p-value less than 0.1</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>feature_cols <span class="ansi-blue-fg">=</span> X<span class="ansi-blue-fg">.</span>columns<span class="ansi-blue-fg">[</span>results<span class="ansi-blue-fg">.</span>pvalues<span class="ansi-blue-fg">.</span>drop<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;const&#39;</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">&lt;</span> <span class="ansi-cyan-fg">0.1</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> 
<span class="ansi-green-intense-fg ansi-bold">      4</span> <span class="ansi-red-fg"># Run our regression just like we normally do</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> X <span class="ansi-blue-fg">=</span> df<span class="ansi-blue-fg">[</span>feature_cols<span class="ansi-blue-fg">]</span>

<span class="ansi-red-fg">NameError</span>: name &#39;X&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now that we've removed some variables and re-run our regression, <strong>our coefficients have changed!</strong> The noise and randomness from the other columns has decreased, and things are looking a lot better.</p>
<p>But if we check out our p-value column, we see it's changed, as well. We have a good number of p-values around 0, a couple around 0.7-0.8, and then one that jumped up to 0.151. APM Reports felt that doing a another pass of filtering would help, removing anything that has a p-value of under 0.5. From their methodology:</p>
<blockquote><p>Finally, we selected all factors with a <strong>p-value &lt; 0.05</strong> and ran the model a third time.</p>
</blockquote>
<p>We can actually just cut and paste the code from our last cell, and adjust the boundary from <code>0.1</code> to <code>0.05</code>. Note that it will filter the results of our <strong>most recent regression</strong>, not our original regression.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Filter our original features to only keep ones with a p-value less than 0.05</span>
<span class="n">feature_cols</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;const&#39;</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">]</span>

<span class="c1"># Run our regression just like we normally do</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">feature_cols</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">struck_by_state</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">Logit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">results</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Optimization terminated successfully.
         Current function value: 0.411232
         Iterations 6
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<table class="simpletable">
<caption>Logit Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>struck_by_state</td> <th>  No. Observations:  </th>   <td>  2295</td>  
</tr>
<tr>
  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  2287</td>  
</tr>
<tr>
  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     7</td>  
</tr>
<tr>
  <th>Date:</th>            <td>Mon, 04 Nov 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.2682</td>  
</tr>
<tr>
  <th>Time:</th>                <td>14:37:46</td>     <th>  Log-Likelihood:    </th>  <td> -943.78</td> 
</tr>
<tr>
  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1289.7</td> 
</tr>
<tr>
  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>3.815e-145</td>
</tr>
</table>
<table class="simpletable">
<tr>
           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>const</th>               <td>   -2.4307</td> <td>    0.101</td> <td>  -24.017</td> <td> 0.000</td> <td>   -2.629</td> <td>   -2.232</td>
</tr>
<tr>
  <th>is_black</th>            <td>    1.8972</td> <td>    0.141</td> <td>   13.443</td> <td> 0.000</td> <td>    1.621</td> <td>    2.174</td>
</tr>
<tr>
  <th>same_race</th>           <td>    0.3603</td> <td>    0.140</td> <td>    2.575</td> <td> 0.010</td> <td>    0.086</td> <td>    0.635</td>
</tr>
<tr>
  <th>accused</th>             <td>    2.5128</td> <td>    0.545</td> <td>    4.606</td> <td> 0.000</td> <td>    1.444</td> <td>    3.582</td>
</tr>
<tr>
  <th>fam_accused</th>         <td>    1.8476</td> <td>    0.162</td> <td>   11.402</td> <td> 0.000</td> <td>    1.530</td> <td>    2.165</td>
</tr>
<tr>
  <th>fam_law_enforcement</th> <td>   -0.5627</td> <td>    0.162</td> <td>   -3.468</td> <td> 0.001</td> <td>   -0.881</td> <td>   -0.245</td>
</tr>
<tr>
  <th>know_def</th>            <td>    1.3257</td> <td>    0.223</td> <td>    5.937</td> <td> 0.000</td> <td>    0.888</td> <td>    1.763</td>
</tr>
<tr>
  <th>death_hesitation</th>    <td>    1.8243</td> <td>    0.592</td> <td>    3.084</td> <td> 0.002</td> <td>    0.665</td> <td>    2.984</td>
</tr>
</table>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And there we go! Now that we have a solid selection of features with very low p-values, we can go ahead and examine our odds ratios!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;coef&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="s1">&#39;odds ratio&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">values</span><span class="p">),</span>
    <span class="s1">&#39;pvalue&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">pvalues</span><span class="p">,</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">results</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">index</span>
<span class="p">})</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;odds ratio&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">coefs</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coef</th>
      <th>odds ratio</th>
      <th>pvalue</th>
      <th>name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>accused</th>
      <td>2.51278</td>
      <td>12.33918</td>
      <td>0.00000</td>
      <td>accused</td>
    </tr>
    <tr>
      <th>is_black</th>
      <td>1.89716</td>
      <td>6.66696</td>
      <td>0.00000</td>
      <td>is_black</td>
    </tr>
    <tr>
      <th>fam_accused</th>
      <td>1.84760</td>
      <td>6.34456</td>
      <td>0.00000</td>
      <td>fam_accused</td>
    </tr>
    <tr>
      <th>death_hesitation</th>
      <td>1.82434</td>
      <td>6.19873</td>
      <td>0.00204</td>
      <td>death_hesitation</td>
    </tr>
    <tr>
      <th>know_def</th>
      <td>1.32570</td>
      <td>3.76481</td>
      <td>0.00000</td>
      <td>know_def</td>
    </tr>
    <tr>
      <th>same_race</th>
      <td>0.36026</td>
      <td>1.43370</td>
      <td>0.01004</td>
      <td>same_race</td>
    </tr>
    <tr>
      <th>fam_law_enforcement</th>
      <td>-0.56268</td>
      <td>0.56968</td>
      <td>0.00052</td>
      <td>fam_law_enforcement</td>
    </tr>
    <tr>
      <th>const</th>
      <td>-2.43071</td>
      <td>0.08797</td>
      <td>0.00000</td>
      <td>const</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Review">Review<a class="anchor-link" href="#Review">#</a></h2><p>We learned how <strong>p-values relate to features</strong> in a logistic regression model. The lower a feature's p-value is, the greater a chance that the relationship is accurate. Typically p-values below <code>0.05</code> (aka <code>5%</code>) are thought of as good p-values.</p>
<p>To make a simple and non-noisy model, we ran an initial regression and then <strong>filtered our features</strong> to only keep those with low p-values. We did this across a few rounds: first we used all of our variables, then the ones that met a <code>0.1</code> threshold, and then those that met a <code>0.05</code> threshold. This allowed us to drop from 24 features down to 7 features.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Discussion-topics">Discussion topics<a class="anchor-link" href="#Discussion-topics">#</a></h2><ul>
<li>Why are values below <code>0.05</code> thought of as a good p-value?</li>
<li>If you had a feature at <code>0.049</code> and one at <code>0.051</code>, would you keep the first and discard the second?</li>
<li>By removing features from a model, we're ignoring data that we have and could be using. What are the arguments in favor or against it, and how comfortable do you feel with it?</li>
<li>Do you prefer using the formula method or the dataframe method for a logistic regression? Is there a difference in readability or understandability between the two?</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 


    </div>
  </div>
</div>

<script>
  [...document.querySelectorAll(".code_cell")].filter(cell => cell.innerText.trim().length === 0).forEach(cell => cell.remove())
</script>

  <div class="footer bg-secondary">
  <div class="content">
    <div class="columns">
      <div class="column col-6 col-sm-12">
        <p><strong>Hi, welcome to Data Science for Journalism!</strong></p>
        <p>There's been a lot of buzz about machine learning and "artificial intelligence" being used in stories over
          the past few years. It's mostly not that complicated - a little stats, a classifier here or there - but it's
          hard to know where to start without a little help.</p>
        <p>Hopefully this site can be that help! <a href="/ds4j/about">Learn more about this project here.</a></p>
      </div>
      <div class="column col-3 col-sm-6">
        <p><strong>Quick links</strong></p>
        <!-- <p><a href="#">Something here</a></p>
        <p><a href="#">Something here</a></p>
        <p><a href="#">Something here</a></p> -->
      </div>
      <div class="column col-3 col-sm6">
        <p><strong>Contact</strong></p>
        <p><a href="mailto:hello@littlecolumns.com">hello@littlecolumns.com</a></p>
      </div>
    </div>
  </div>
</div>
  <script src="/ds4j/js/tocbot.js"></script>

  <script>
    try {
      let toc = document.createElement("div")
      toc.setAttribute('class', 'js-toc')
      document.querySelector(".reading-options").parentNode.appendChild(toc)
    } catch (err) {

    }

    // Chapter TOC
    tocbot.init({
      // Where to render the table of contents.
      tocSelector: '.js-toc',
      // Where to grab the headings to build the table of contents.
      contentSelector: '.notebook',
      // Which headings to grab inside of the contentSelector element.
      headingSelector: 'h1, h2, h3, h4',
      activeLinkClass: 'active',
      listClass: 'nav',
      listItemClass: 'nav-item',
      headingLabelCallback: function (label) {
        return label.replace("#", "")
      }
    });
  </script>

</body>

</html>