[
["index.html", "1 Introduction", " 1 Introduction "],
["preface.html", "2 Preface", " 2 Preface With a large set of documents, sometimes you need a little help reading through them. After you’ve read a few, you can tell the computer “find me more like this” without too much trouble! 2.0.1 The original story As opposed to one simple story, the investigation of the Takata airbag recall was a years-long saga that affected tens of millions of cars. New York Times reporter Hiroko Tabuchi had to comb through millions of complaints to the federal government looking for cases that might be related to the recall. Daeil Kim, a data scientist who was working at the New York Times, used machine learning to try to lend a hand. "],
["the-data.html", "3 The Data ", " 3 The Data "],
["turning-our-question-into-measureables.html", "3.1 Turning our question into measureables", " 3.1 Turning our question into measureables First, we’ll need to break our question down into something measureable, then figure out where we can get the necessary information. The question in this case is, “can we find vehicle malfunctions related to Takata airbags?” This question will be broken down into two pieces: finding instances of vehicle malfunctions, and then refining that list down to airbag-related complaints. "],
["data-car-issue-issues.html", "3.2 Data: Car issue issues", " 3.2 Data: Car issue issues We need to find incidents of problems related to airbags. There’s not a specific airbag registry, but there’s something close: the National Highway Traffic Safety Administration (part of the U.S. Department of Transportation) has a section called the Office of Defects Investigation. The NHTSA/ODI takes complaints about car issues that might be related to safety, and if it notices a pattern in them a recall may happen. Under the “Complaints” section of the NHTSA/ODI Database site, you can find a set of files that contain all complaints received since 1995. FLAT_CMPL.zip: The complaints themselves, unzips into a 1GB+ text file CMPL.txt: the data dictionary for the complaints file Import_Instructions.pdf: how to import the files into Microsoft Access (which we won’t be doing) "],
["data-suspicious-airbag-issues.html", "3.3 Data: Suspicious airbag issues", " 3.3 Data: Suspicious airbag issues Our end goal is going to be help a computer understand what a suspicious airbag comment looks like. In order to teach our computer what a suspicious airbag comment looks like, we need to read through a few ourselves first. We’ll mark which ones are suspicious and which aren’t suspicious, which will give the computer an idea of which complaints belong in which category. We’ll need to do this low-tech style: we’ll open up the complaints database, take out some complaints (some about airbags, some not) and manually read them. We’ll do this using pandas, a Python data analysis library, but you can use most any technique to pull out a handful. 3.3.1 Extracting a sample of complaints There are many, many columns in this dataset, so we’re going to ask pandas to display lots and lots of columns. The description column can be pretty long, so we’ll also tell pandas to display up to 100 characters in a single column. import pandas as pd pd.set_option(&quot;display.max_columns&quot;, 100) pd.set_option(&quot;display.max_colwidth&quot;, 100) Now we’ll open FLAT_CMPL.txt, our complaints file form the NHSTA. Programming things to notice: It’s tab-separated instead of comma-separated, so we use sep='\\t' We need encoding=latin-1 because it’s written just for English-language data Some of the lines are bad, but we’ll just throw them out with error_bad_lines=False There’s no header row, so we’ve pulled out all of the column names from CMPL.txt Since here are a lot of codes that might have leading zeroes we’re reading in all columns as strings We’re only interested in complaints from before 2015 column_names = [&#39;CMPLID&#39;, &#39;ODINO&#39;, &#39;MFR_NAME&#39;, &#39;MAKETXT&#39;, &#39;MODELTXT&#39;, &#39;YEARTXT&#39;, &#39;CRASH&#39;, &#39;FAILDATE&#39;, &#39;FIRE&#39;, &#39;INJURED&#39;, &#39;DEATHS&#39;, &#39;COMPDESC&#39;, &#39;CITY&#39;, &#39;STATE&#39;, &#39;VIN&#39;, &#39;DATEA&#39;, &#39;LDATE&#39;, &#39;MILES&#39;, &#39;OCCURENCES&#39;, &#39;CDESCR&#39;, &#39;CMPL_TYPE&#39;, &#39;POLICE_RPT_YN&#39;, &#39;PURCH_DT&#39;, &#39;ORIG_OWNER_YN&#39;, &#39;ANTI_BRAKES_YN&#39;, &#39;CRUISE_CONT_YN&#39;, &#39;NUM_CYLS&#39;, &#39;DRIVE_TRAIN&#39;, &#39;FUEL_SYS&#39;, &#39;FUEL_TYPE&#39;, &#39;TRANS_TYPE&#39;, &#39;VEH_SPEED&#39;, &#39;DOT&#39;, &#39;TIRE_SIZE&#39;, &#39;LOC_OF_TIRE&#39;, &#39;TIRE_FAIL_TYPE&#39;, &#39;ORIG_EQUIP_YN&#39;, &#39;MANUF_DT&#39;, &#39;SEAT_TYPE&#39;, &#39;RESTRAINT_TYPE&#39;, &#39;DEALER_NAME&#39;, &#39;DEALER_TEL&#39;, &#39;DEALER_CITY&#39;, &#39;DEALER_STATE&#39;, &#39;DEALER_ZIP&#39;, &#39;PROD_TYPE&#39;, &#39;REPAIRED_YN&#39;, &#39;MEDICAL_ATTN&#39;, &#39;VEHICLES_TOWED_YN&#39;] df = pd.read_csv(&quot;data/FLAT_CMPL.txt&quot;, sep=&#39;\\t&#39;, dtype=&#39;str&#39;, header=None, error_bad_lines=False, encoding=&#39;latin-1&#39;, names=column_names) # We&#39;re only interested in pre-2015 df = df[df.DATEA &lt; &#39;2015&#39;] df.head() CMPLID ODINO MFR_NAME MAKETXT MODELTXT YEARTXT CRASH FAILDATE FIRE INJURED DEATHS COMPDESC CITY STATE VIN DATEA LDATE MILES OCCURENCES CDESCR CMPL_TYPE POLICE_RPT_YN PURCH_DT ORIG_OWNER_YN ANTI_BRAKES_YN CRUISE_CONT_YN NUM_CYLS DRIVE_TRAIN FUEL_SYS FUEL_TYPE TRANS_TYPE VEH_SPEED DOT TIRE_SIZE LOC_OF_TIRE TIRE_FAIL_TYPE ORIG_EQUIP_YN MANUF_DT SEAT_TYPE RESTRAINT_TYPE DEALER_NAME DEALER_TEL DEALER_CITY DEALER_STATE DEALER_ZIP PROD_TYPE REPAIRED_YN MEDICAL_ATTN VEHICLES_TOWED_YN 0 1 958173 Ford Motor Company LINCOLN TOWN CAR 1994 Y 19941222 N 0 0 SERVICE BRAKES, HYDRAULIC:PEDALS AND LINKAGES HIGH LAND PA MI 1LNLM82W8RY 19950103 19950103 NaN 1 BRAKE PEDAL PUSH ROD RETAINER WAS NOT PROPERLY INSTALLED, CAUSING BRAKES TO FAIL, RESULTING IN AN ACCIDENT AFTER RECALL REPAIRS (94V-129). *AK EVOQ NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN V NaN NaN NaN 1 2 958146 General Motors LLC GMC SONOMA 1995 NaN 19941215 N 0 0 SERVICE BRAKES, HYDRAULIC:FOUNDATION COMPONENTS MOBILE AL 1GTCS19W3S8 19950103 19950103 NaN NaN VEHICLE STALLS AT HIGH SPEED, RESULTING IN LOSS OF STEERING AND BRAKING ABILITY. TT EVOQ NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN V NaN NaN NaN 2 3 958127 Ford Motor Company FORD RANGER 1994 NaN NaN N 0 0 ENGINE AND ENGINE COOLING:EXHAUST SYSTEM N. LAUDERDAL FL NaN 19950103 19950103 NaN NaN EXHAUST SYSTEM FAILS; PLEASE DESCRIBE DETAILS. TT EVOQ NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN V NaN NaN NaN 3 4 958170 Ford Motor Company MERCURY COUGAR 1995 NaN 19950101 N 0 0 SERVICE BRAKES, HYDRAULIC:FOUNDATION COMPONENTS CORRAL SPRIN FL 1MELM62W5SH 19950103 19950103 NaN 1 BRAKING SYSTEM FAILURE WITHOUT ABS BRAKES. TT EVOQ NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN V NaN NaN NaN 4 5 958149 Nissan North America, Inc. NISSAN MAXIMA 1987 NaN 19941223 N 0 0 VISIBILITY:SUN ROOF ASSEMBLY COLUMBUS OH JN1HU11P3HX 19950103 19950103 NaN 1 VEHICLES SUN ROOF GLASS FLEW OFF WHILE DRIVING. TT EVOQ NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN V NaN NaN NaN We aren’t really concerned with the data itself just now, as we’re only going to take a sample. Again, most will be about airbags, some will not. We’re only going to save the complaint description because that’s all we really care about! # Take a random sample of rows sampled = df.sample(50) # Take a sample involving airbags airbag_df = df[df.CDESCR.str.contains(&quot;AIR ?BAG&quot;, na=False)] airbag_df = airbag_df.sample(300) # Combine them so we have all sorts for the machine to learn about sampled = pd.concat([sampled, airbag_df]) # We don&#39;t know whether they&#39;re suspicious or not sampled[&#39;is_suspicious&#39;] = &#39;&#39; # We only want a few columns sampled = sampled[[&#39;is_suspicious&#39;, &#39;CDESCR&#39;]] # Save them sampled.to_csv(&quot;data/sampled-unlabeled.csv&quot;, index=False) 3.3.2 Labeling our sample of complaints Now comes the fun part: opening up sampled-unlabeled.csv and filling in labels for each and every one of those hundreds of rows. We’ll use 1 if it’s suspicious, 0 if it isn’t. For example, this complaint isn’t suspicious because it’s about an air bag not deploying: DURING AN ACCIDENT AIR BAG&#39;S DID NOT DEPLOY. DEALER HAS BEEN CONTACTED. *AK This next one isn’t suspicious either, because it isn’t even about airbags! DRIVERS SEAT BACK COLLAPSED AND BENT WHEN REAR ENDED. PLEASE DESCRIBE DETAILS. TT But if something involving explosions or shrapnel happens, it’s probably worth marking as suspicious: I WAS DRIVEN IN A SCHOOL ZONE STREET AND THE LIGHTS OF AIRBAG ON AND APROX. 2 MINUTES THE AIR BAGS EXPLODED IN MY FACE, THE DRIVE AND PASSENGERS SIDE, THEN I STOPPED THE JEEP, IT SMELL LIKE SOMETHING IS BURNING AND HOT, I DID NOT SEE FIRE. *TR We’ll just go down the left-hand column in Excel, filling them in as 0 or 1. You’ll probably want to turn on Wrap Text in Excel so you don’t have to scroll left and right so much. "],
["preparing-our-data.html", "4 Preparing our data", " 4 Preparing our data While there are fancier (and more effective!) ways to do what we’re about to do, the simple start below is going to provide a foundation for later work. To teach our computer how to find suspicious complaints, we first need to think about how we find those complaints as human beings. By reading, right? So let’s teach the computer how to read, and what to look for. In machine learning, the things you tell the algorithm to pay attention to are called features. "],
["designing-our-features.html", "4.1 Designing our features", " 4.1 Designing our features Let’s take a look at what the airbag issue is, according Consumer Reports: Vehicles made by 19 different automakers have been recalled to replace frontal airbags on the driver’s side or passenger’s side, or both in what NHTSA has called “the largest and most complex safety recall in U.S. history.” The airbags, made by major parts supplier Takata, were mostly installed in cars from model year 2002 through 2015. Some of those airbags could deploy explosively, injuring or even killing car occupants. At the heart of the problem is the airbag’s inflator, a metal cartridge loaded with propellant wafers, which in some cases has ignited with explosive force. If the inflator housing ruptures in a crash, metal shards from the airbag can be sprayed throughout the passenger cabin—a potentially disastrous outcome from a supposedly life-saving device. If we’re going through a list of vehicle complaints, it isn’t too hard for us to figure out which complaints we might want to investigate further. If the complaint’s about seatbelts or rear-view mirrors, we probably don’t care about it. If the word “airbag” shows up in the description, though, we’re going to start paying attention. We aren’t interested in all complaints with the word “airbag,” though. Since we’re worried about exploding airbags, something like “the airbag did not deploy” would get our attention because of the word “airbag,” but then we could ignore it once we saw the airbag just didn’t work. 4.1.1 Selecting our features Since we just read a long long list of airbag complaints, we can probably brainstorm some words or phrases that might make a comment interesting or not interesting. A quick start might be these few: airbag air bag failed did not deploy violent explode shrapnel These features are the things that the machine learning algorithm is going to pay attention to. For each comment, we’ll say eiter YES it contains this word or NO it does not contain this word. There are lots of words in each complaint, but these are the only ones it will care about! "],
["classification.html", "4.2 Classification", " 4.2 Classification The kind of problem we’re dealing with here is called a classification problem. That’s because we have two different classes of complaints: Complaints that are suspicious Complaints that are not suspicious We’re going to take the complaints that we didn’t label, and hold it up to the computer - the machine’s job is to classify new complaints in one of those two categories. Before we put it on the job, though, we need to teach it what each category of complaint looks like. 4.2.1 Training data Teaching a machine learning algorithm about a dataset is called training. We train our classifier the same way we trained ourselves - by making it read all a bunch of comments! Because we marked each one as suspicious or not suspicious, the computer is able to learn from the work we did. Using code, we’ll present each row to the classifier and say hi, please remember that a comment like this is suspicious (or not suspicious). labeled_df = pd.read_csv(&quot;data/sampled-labeled.csv&quot;) # Some weren&#39;t labeled - let&#39;s just drop those! labeled_df = labeled_df.dropna() labeled_df.head() is_suspicious CDESCR 0 0 ALTHOUGH I LOVED THE CAR OVERALL AT THE TIME I DECIDED TO OWN, , MY DREAM CAR CADILLAC CTS HAS TURNED INTO MY DREAM NIGHTMARE. CADILLAC CTS 3.6 2008 WHEN I GET ON IT A LITTLE BIT ACCELERATION IT MAKES A SOUND THAT SOUNDS LIKE ALL AIR LEAKS INSIDE THE CAR. THE DEALER WAS REPORTED EVER SINCE MY FIRST EARLY VISIT TO SERVICE CENTER BUT IT’S ONLY DURING MY LAST VISIT TO THE DEALER THEY MENTIONED GM HAS SANCTIONED APPROVAL IE. AT THE TIME THE ODOMETER READS 65000KM? STRANGE! THE DOOR LOCKS ARE TERRIBLE?DESPITE RECTIFYING; TIME AND AGAIN BY YOUR DEALER THE PROBLEM STILL PERSIST TO DATE. SAFETY HAZARD INDEED. THE COMPUTER HAD ERROR AS FOR TYRE LOW AIR PRESSURE VERY BAD ON SAFETY STANDARDS. ON 12TH AUG 2012 WHILE I WAS EN-ROUTE TO THE CADILLAC SERVICE CENTER THE VEHICLE HAD A BREAK DOWN. ON THE DISPLAY SCREEN NEAR ODOMETER IT DISPLAYED ENGINE TEMPERATURE TOO HIGH ?. DUE TO THIS I HAD TO PULL THE CAR TOWARDS SAFETY AND GOT STRANDED IN THE MIDDLE OF THE ROAD UNDER THE HOT SUN. HOW CAN YOU JUSTIFY A CAR WHICH IS REGULARLY MAINTAINED BY YOUR AUTHORIZED AGENCY AT REGULAR PERIODIC INTERVALS TO HAVE SUCH A FATE? I FELT IT WAS GOOD TO HAVE IT SERVICED DURING MY ABSENCE IN TOWN BEFORE THE REGULAR KM INTERVAL; BUT, ONLY TO GET STRANDED ON THE ROAD IN THE HOT SUN. IT IS INDEED, TOO MUCH TO SUFFER AFTER BUYING A CAR OF GM FLAGSHIP BRAND &lt; CADILLAC &gt; AND SUFFER AGONY ON THE ROAD SIDE. NOT TO MENTION THE DEALERSHIPS WARRANTY YOU PROVIDE WITH THE PURCHASE OF THE NEW CAR FROM YOUR AUTHORIZED AGENTS, PROBABLY DON’T FIX ANYTHING WITH THE WARRANTY SERVICE PROGRAM. IF THE JOB WAS RIGHT THEN THE ENGINE SHOULD NOT HAVE OVER HEATED ESPECIALLY WHEN THE CAR IS JUST RUN 71000 KMS. APPROX… *TR 1 0 CONSUMER SHUT SLIDING DOOR WHEN ALL POWER LOCKS ON ALL DOORS LOCKED BY ITSELF, TRAPPING INFANT INSIDE THE VEHICLE. VEHICLE WAS RUNNING AT THE TIME. *AK 2 0 DRIVERS SEAT BACK COLLAPSED AND BENT WHEN REAR ENDED. PLEASE DESCRIBE DETAILS. TT 3 0 TL* THE CONTACT OWNS A 2009 NISSAN ALTIMA. THE CONTACT STATED THAT THE START BUTTON FOR THE IGNITION WOULD NOT START THE VEHICLE. THE STEERING LOCK LIGHT ILLUMINATED ON THE INSTRUMENT PANEL WHEN THE FAILURE OCCURRED. THE VEHICLE WAS TOWED TO THE DEALER WHO STATED THE STEERING LOCK NEEDED TO BE REPLACED. THE DEALER RESPONDED AS IF THIS WAS AN ISOLATED ISSUE. THE VEHICLE WAS REPAIRED. THE FAILURE MILEAGE AND CURRENT MILEAGE WAS 57,915. UPDATED 3/28/13 CN UPDATED 05/10/2013 JS 4 0 THE FRONT MIDDLE SEAT DOESN’T LOCK IN PLACE. *AK Remember how we picked a list of features, or words for our algorithm to pay attention to? Let’s now make a dataframe to see which rows have which words. To use the list of words, we’re just going to make a new dataframe where there’s a 1 if the word is in the description and a 0 if it isn’t. .str.contains gives us False or True, and making it an integer with .astype(int) will turn it into 0 or 1 (machine learning gets grumpy about anything that isn’t numbers). Along with the words, we’ll also save the is_suspicious label to keep everything in the same place. training_features = pd.DataFrame({ &#39;is_suspicious&#39;: labeled_df.is_suspicious, &#39;airbag&#39;: labeled_df.CDESCR.str.contains(&quot;AIRBAG&quot;, na=False).astype(int), &#39;air bag&#39;: labeled_df.CDESCR.str.contains(&quot;AIR BAG&quot;, na=False).astype(int), &#39;failed&#39;: labeled_df.CDESCR.str.contains(&quot;FAILED&quot;, na=False).astype(int), &#39;did not deploy&#39;: labeled_df.CDESCR.str.contains(&quot;DID NOT DEPLOY&quot;, na=False).astype(int), &#39;violent&#39;: labeled_df.CDESCR.str.contains(&quot;VIOLENT&quot;, na=False).astype(int), &#39;explode&#39;: labeled_df.CDESCR.str.contains(&quot;EXPLODE&quot;, na=False).astype(int), &#39;shrapnel&#39;: labeled_df.CDESCR.str.contains(&quot;SHRAPNEL&quot;, na=False).astype(int), }) training_features.head() is_suspicious airbag air bag failed did not deploy violent explode shrapnel 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 Not all of the comments we have are suspicious (which is correct, since we need examples of both!). How many suspicious airbag events do we have in our dataset? training_features.is_suspicious.value_counts() ## 0.0 150 ## 1.0 15 ## Name: is_suspicious, dtype: int64 Okay, maybe we need to do a better job getting more suspicious ones in there. We’ll try to cope with it for now, though. "],
["analyzing-our-data.html", "5 Analyzing our data", " 5 Analyzing our data Now that we’ve prepared our dataset, we just need to create our algorithm. After it’s been built, we’ll be able to show it comments that it hasn’t seen before and it will predict whether it’s suspicious or not. Then we’ll be able to read the comments the computer flagged instead of the entire dataset. "],
["building-a-classifier.html", "5.1 Building a classifier", " 5.1 Building a classifier Classification is the act of putting things in categories. There are approximately ten billion kinds of classifiers, most of which work roughly the same way. Features: the 1s and 0s that are the words in each comment Labels: 1 or 0, whether the comment was suspicious or not If you’re familiar with linear regression, it takes a bunch of inputs to predict a number. Instead we’re going to use logistic regression, which (in this case) takes a bunch of inputs to predict a category. from sklearn.linear_model import LogisticRegression # Every column EXCEPT whether it&#39;s suspicious X = training_features.drop(columns=&#39;is_suspicious&#39;) # ONLY if it&#39;s suspicious y = training_features.is_suspicious # Build a new classifier # C=1e9 is a magic number we gotta use clf = LogisticRegression(C=1e9) # Teach the classifier about the complaints we read clf.fit(X, y) ## LogisticRegression(C=1000000000.0, class_weight=None, dual=False, ## fit_intercept=True, intercept_scaling=1, l1_ratio=None, ## max_iter=100, multi_class=&#39;warn&#39;, n_jobs=None, penalty=&#39;l2&#39;, ## random_state=None, solver=&#39;warn&#39;, tol=0.0001, verbose=0, ## warm_start=False) ## ## /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. ## FutureWarning) That was it! That’s all it took! Our classifier is done! When it comes to machine learning, you’ll spend most of your time finding and tending to your data. Once you get to the actual “algorithm” part it’s usually just a matter of making small tweaks here or there. "],
["interpreting-our-classifier.html", "5.2 Interpreting our classifier", " 5.2 Interpreting our classifier Now we have a machine that can tell us whether a complain is suspicious or not. We taught it using a list of words to pay attention to (aka features), but how does it really work? The classifier looks at words the same way we do - some are more important than others, and will either mark a comment as suspicious or not. We can use a library called eli5 to explain the which words the classifier is looking at! import eli5 feature_names = list(training_features.drop(columns=&#39;is_suspicious&#39;).columns) eli5.explain_weights_df(clf, feature_names=feature_names) target feature weight 1 violent 10.3622783 1 explode 1.2691041 1 air bag 1.2681947 1 airbag 0.9455542 1 &lt;BIAS&gt; -2.8487556 1 shrapnel -6.5557720 1 failed -8.6491094 1 did not deploy -10.6061532 A positive number means it means “this looks suspicious!”, while a negative number suggests the complain is not suspicious. We can see that “violent” is a strong suggester that we might want to read the complaint, while “did not deply” means that even though it’s airbag-related it probably doesn’t concern us. "],
["using-our-classifier.html", "5.3 Using our classifier", " 5.3 Using our classifier The point of a classifier is to classify documents it hasn’t seen before, to read them and put them into the appropriate category. Before we can do this, we need to extract features from our original dataframe, the one that doesn’t have labels. We’ll do this the same way we did with our set of labeled data, by checking for each item in the list of words. features = pd.DataFrame({ &#39;airbag&#39;: df.CDESCR.str.contains(&quot;AIRBAG&quot;, na=False).astype(int), &#39;air bag&#39;: df.CDESCR.str.contains(&quot;AIR BAG&quot;, na=False).astype(int), &#39;failed&#39;: df.CDESCR.str.contains(&quot;FAILED&quot;, na=False).astype(int), &#39;did not deploy&#39;: df.CDESCR.str.contains(&quot;DID NOT DEPLOY&quot;, na=False).astype(int), &#39;violent&#39;: df.CDESCR.str.contains(&quot;VIOLENT&quot;, na=False).astype(int), &#39;explode&#39;: df.CDESCR.str.contains(&quot;EXPLODE&quot;, na=False).astype(int), &#39;shrapnel&#39;: df.CDESCR.str.contains(&quot;SHRAPNEL&quot;, na=False).astype(int), }) features.head() airbag air bag failed did not deploy violent explode shrapnel 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 Notice that we didn’t create a is_suspicious category - that’s because we don’t know if these ones are suspicious or not! Now we can have our classifier predict whether they’re suspicious or not based on whether or not they have the suspicious words inside. Let’s add it as a new column as to whether it looked suspicious or not to the classifier. features[&#39;is_suspicious&#39;] = clf.predict(features) features.head() airbag air bag failed did not deploy violent explode shrapnel is_suspicious 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 Let’s take a look at only the suspicious ones. features[features.is_suspicious == 1].head(20) airbag air bag failed did not deploy violent explode shrapnel is_suspicious 56 0 0 0 0 1 0 0 1 1217 1 0 0 0 1 0 0 1 1868 0 0 0 0 1 0 0 1 2035 0 0 0 0 1 0 0 1 2960 0 0 0 0 1 0 0 1 4129 0 0 0 0 1 0 0 1 5362 0 0 0 0 1 0 0 1 5663 0 1 0 0 1 0 0 1 5672 0 1 0 0 1 0 0 1 7507 0 0 0 0 1 0 0 1 7581 0 0 0 0 1 0 0 1 7686 0 0 0 0 1 0 0 1 8100 0 0 0 0 1 0 0 1 8834 0 0 0 0 1 0 0 1 10341 0 1 0 0 1 0 0 1 10425 0 1 0 0 1 0 0 1 11196 0 1 0 0 1 0 0 1 11202 0 1 0 0 1 0 0 1 13135 0 0 0 0 1 0 0 1 13518 0 1 0 0 1 0 0 1 We can see most of the ones marked as suspicious include the words “airbag” and “violent,” and none of them include “failed” or “did not deploy.” That all makes sense, but what about all of the ones that include the word “violent” but not “airbag” or “air bag?” None of those should be good! While we could just filter it to only include ones with the word “airabg” in it, we probably need a way to test the quality of our classifier. "],
["testing-our-classifier.html", "5.4 Testing our classifier", " 5.4 Testing our classifier When we look at the results of our classifier, we know some of them are wrong - complaints shouldn’t be suspicious if they don’t have airbags in them! But it would be nice to have an automated process to give us an idea of how well our classifier does. We test a classifier just like our teachers test us in class: we’ll show our classifier rows we you know the answer to, and see if it gets them right. The problem is we can’t test it on our unlabeled data, because we doesn’t know what’s right and what’s wrong. Instead, we have to test on the labeled data we know the answer to. One technique would be having our classifier compare the actual labels on our training data (suspicious, not suspicious) to what it would predict those labels to be. # Look at our training data, predict the labels, # then compare the labels to the actual labels clf.score(X, y) ## 0.9212121212121213 Incredible, 92% accuracy! It got 92% correct! …that’s good, right? Well, not really. There are two major reason why this isn’t impressive: We’re testing it on data it’s already seen The vast majority of our samples are not suspicious 5.4.1 Test-train split The biggest problem with our classifier is that we’re testing it on data it’s already seen. While it’s cool to have a study sheet for a quiz, it doesn’t quite seem fair if the study sheet is exactly the same as the test. Instead, we should try to reproduce what the real world is like - training it on one set of data, and testing it on similar data… but similar data we already know the labels for! It’s like how a teacher gives sample quizzes that are similar - but not the same - as the the real one. To make this happen we use something called train/test split, where instead of using the entire dataset for training, we only use most of it - maybe 75% or so. The code on the line below automatically splits the dataset into two groups, one for training and a smaller one for testing. from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) That way when we give the model a test, it hasn’t seen the answers already! clf.score(X_test, y_test) ## 0.9285714285714286 Not bad, not bad. There are other ways to improve this further, but for now we have a larger problem to tackle. 5.4.2 The confusion matrix Our accuracy is looking great, hovering somewhere in the 90’s. Feeling good, right? Unfortunately, things aren’t actually that rosy. Let’s take a look at how many suspicious and how many non-suspicious complaints we have: labeled_df.is_suspicious.value_counts() ## 0.0 150 ## 1.0 15 ## Name: is_suspicious, dtype: int64 We have a lot more non-suspicious ones as compared to suspicious, right? Let’s say we were classifying, and we always guessed “not suspicious”. Since there are so few suspicious ones, we wouldn’t get very many wrong, and our accuracy would be really high! If we have 99 non-suspicious and 1 suspicious, if we always guess “non-suspicious” we’d have 99% accuracy. Even though our accuracy would look great, the result would be super boring. Since zero of our complaints would have been marked as suspicious, we wouldn’t have anything to read or research. It’d be much nicer if we could identify the difference between getting one category right compared to the other. And hey, that’s easy! We use this thing called a confusion matrix. It looks like this: from sklearn.metrics import confusion_matrix y_true = y y_pred = clf.predict(X) confusion_matrix(y_true, y_pred) ## array([[150, 0], ## [ 13, 2]]) …which is pretty terrible-looking, right? It’s hard as heck to understand! Let’s try to spice it up a little bit and make it a little nicer to read: from sklearn.metrics import confusion_matrix # Save the true label, but also save the predicted label y_true = y y_pred = clf.predict(X) # We could also use just the test dataset # y_true = y_test # y_pred = clf.predict(X_test) # Build the confusion matrix matrix = confusion_matrix(y_true, y_pred) # But then make it look nice label_names = pd.Series([&#39;not suspicious&#39;, &#39;suspicious&#39;]) pd.DataFrame(matrix, columns=&#39;Predicted &#39; + label_names, index=&#39;Is &#39; + label_names) Predicted not suspicious Predicted suspicious Is not suspicious 150 0 Is suspicious 13 2 So now we can see what’s going on a little bit better. According to the confusion matrix, when using our test set: We correctly predicted 38 of 38 not-suspicious We only correctly predicted 2 of 4 suspicious ones. Not nearly as good as we’d hoped. "],
["conclusion.html", "5.5 Conclusion", " 5.5 Conclusion If you found this short walkthrough interesting, you’ll want to check out the full notebooks on the page. They dive deep into using different classifiers, and different ways of counting words. In the end, though, this airbags research is just a toy example to prove that throwing data science at a problem doesn’t automatically solve it. If we labeled more cases our classifier would probably be better, yes, but in all honestly we should just search for “airbag” and manually read the cases. It’ll take a little more time, but we’ll be able to have much more faith in our end result. "]
]
