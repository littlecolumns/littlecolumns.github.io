<!doctype html>
<html lang="en-US">

<head>
  <meta charset="utf-8">
  <title>Actual analysis</title>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" rel="stylesheet">
  <!-- <link href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.5/css/bulma.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Raleway:400,700|Open+Sans:400,700&display=swap" rel="stylesheet"> -->
  <link rel="stylesheet" href="/ds4j/css/spectre.min.css">
  <link rel="stylesheet" href="/ds4j/css/spectre-exp.min.css">
  <link rel="stylesheet" href="/ds4j/css/spectre-icons.min.css">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="/ds4j/css/style.css" rel="stylesheet">
  <link href="/ds4j/css/highlight.css" rel="stylesheet">
</head>

<body>
  <div class="nav-holder bg-secondary">
  <div class='content'>
    <header class="navbar">
      <section class="navbar-section">
        <a href="/ds4j/" class="navbar-brand mr-2">DS4J</a>
      </section>
      <section class="navbar-section">
        <a href="/ds4j/projects" class="btn btn-link">Projects</a>
        <a href="/ds4j/topics" class="btn btn-link">Topics</a>
        <a href="/ds4j/curriculum" class="btn btn-link">Curriculum</a>
        <a href="/ds4j/about" class="btn btn-link">About</a>
      </section>
    </header>
  </div>
</div>
  
<div class="content text-based">
  <div class="columns">
    <div class="column col-12 notebook">
      <ul class="breadcrumb">
        <li class="breadcrumb-item">
          <a href="#">Projects</a>
        </li>
        <li class="breadcrumb-item">
          <a href="/ds4j/latimes-crime-classification/">Building a crime classification engine</a>
        </li>
        <li class="breadcrumb-item">
          <a href="/ds4j/latimes-crime-classification/actual-analysis">Actual analysis</a>
        </li>
      </ul>

      <div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Finding-downgraded-crimes-using-machine-learning">Finding downgraded crimes using machine learning<a class="anchor-link" href="#Finding-downgraded-crimes-using-machine-learning">#</a></h1><p>Using a machine learning algorithm, The Los Angeles Times found the LAPD was downgrading serious assaults to the less serious "simple assault" category for years. We're going to reproduce this by manually downgrading 15% of the serious assaults in a database, then trying to see if we can detect which ones we edited.</p>
<p>We'll be using actual assault reports from the LAPD, reported between the years of 2008-2012.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p class="reading-options">
  <a class="btn" href="/ds4j/latimes-crime-classification/actual-analysis">
    <i class="fa fa-sm fa-book"></i>
    Read online
  </a>
  <a class="btn" href="/ds4j/latimes-crime-classification/notebooks/Actual analysis.ipynb">
    <i class="fa fa-sm fa-download"></i>
    Download notebook
  </a>
  <a class="btn" href="#">
    <i class="fa fa-sm fa-laptop"></i>
    Interactive version
  </a>
</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Imports-and-setup">Imports and setup<a class="anchor-link" href="#Imports-and-setup">#</a></h2><p>First we'll set some options up to make everything display correctly. It's mostly because these assault descriptions can be quite long, and the default is to truncate text after a few words.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Read-in-our-data">Read in our data<a class="anchor-link" href="#Read-in-our-data">#</a></h2><p>Our dataset is going to be a database of crimes committed between 2008 and 2012. The data has been cleaned and filtered a bit, though, so we're only left with two columns:</p>
<ul>
<li><code>CCDESC</code>, what criminal code was violated</li>
<li><code>DO_NARRATIVE</code>, a short text description of what happened</li>
</ul>
<p>We're going to use this description to see if we can separate serious cases of assault compared to non-serious cases of assault.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/2008-2012.csv&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CCDESC</th>
      <th>DO_NARRATIVE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SHOPLIFTING - PETTY THEFT ($950 &amp; UNDER)</td>
      <td>DO-SUSP WAS SEEN THROUGH SURVAILANCE CONCEALING SEVERAL ITEMS INTO HER    SHOPPING AND PERSONAL BAG LEAVING WITHOUT PAYING DEPT STORE</td>
    </tr>
    <tr>
      <th>1</th>
      <td>VIOLATION OF COURT ORDER</td>
      <td>DO-SUSP ARRIVED AT VICTS RESID AND ENTERED VICTS RESID IN VIOLATION OF    RESTRAINING ORDER</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-S APPRCHED V AND STATED ARE YOU GOING TO FCK ME V REPLIED NO SUSP PULL ED OUT A KNIFE AND STATED IM HERE TO HURT YOU BTCH S USED PROFANITIES</td>
    </tr>
    <tr>
      <th>3</th>
      <td>THEFT PLAIN - PETTY ($950 &amp; UNDER)</td>
      <td>DO-UNK SUSP TOOK VICT PREPAID GIFT CARD SUSP PURCHASED PRODUCTS WITH ITEM</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BATTERY - SIMPLE ASSAULT</td>
      <td>DO-SUSP USED RIGHT FIST TO PUNCH VICT IN THE HEAD ONCE N PULL VICT HAIR   FOR APPRX 15 SECONDS</td>
    </tr>
    <tr>
      <th>5</th>
      <td>THEFT OF IDENTITY</td>
      <td>DO-UNK SUSP USED VICTS PERSONAL INFO FOR GAIN WITHOUT THE VICTS CONSENT ORKNOWLEDGE</td>
    </tr>
    <tr>
      <th>6</th>
      <td>SHOPLIFTING - PETTY THEFT ($950 &amp; UNDER)</td>
      <td>DO-SUSP ENTERED MKT AND SEL ITEMS SUSP CONCEALED ITEMS AND EXITED STORE WOPAYING</td>
    </tr>
    <tr>
      <th>7</th>
      <td>BURGLARY</td>
      <td>DO-UNK SUSP ENTERED VICTS RESIDENCE BY UNLOCKED FRONT DOOR SUSP REMOVED VCTICTS PROPERTY SUSP FLED LOC</td>
    </tr>
    <tr>
      <th>8</th>
      <td>OTHER MISCELLANEOUS CRIME</td>
      <td>DO-SUSP ADMITTED TO PLACING 2010 REG TAG HE ILLEGALLY OBTAINED ON HIS LIC PLATE HIS VEH REG WAS STILL EXP</td>
    </tr>
    <tr>
      <th>9</th>
      <td>BATTERY - SIMPLE ASSAULT</td>
      <td>DO-S APPROACHED V IN VEH S SLAPPED AND LUNGGED AT V</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How much data do we have?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(830218, 2)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Clean-the-data">Clean the data<a class="anchor-link" href="#Clean-the-data">#</a></h1><p>We don't get to use all 800,000 rows, though! We're just going to stick to assaults. First we'll filter our dataset to only include crimes with a description that includes the word <code>ASSAULT</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">CCDESC</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;ASSAULT&quot;</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(165965, 2)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Assaults come in two forms:</p>
<ul>
<li>Serious or Part I assaults, which are Aggravated and Serious assaults</li>
<li>Non-Serious or Part II assaults, which are Simple assaults</li>
</ul>
<p>Let's make a new column called <code>serious</code> where we save whether the assault is serious/Part I or not.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;serious&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">CCDESC</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;AGGRAVATED&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">df</span><span class="o">.</span><span class="n">CCDESC</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s2">&quot;DEADLY&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;serious&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;serious&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;serious&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">CCDESC</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>serious  CCDESC                                        
0        BATTERY - SIMPLE ASSAULT                          71951
         INTIMATE PARTNER - SIMPLE ASSAULT                 42102
         CHILD ABUSE (PHYSICAL) - SIMPLE ASSAULT            4297
         OTHER ASSAULT                                       394
1        ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT    43385
         INTIMATE PARTNER - AGGRAVATED ASSAULT              1606
         CHILD ABUSE (PHYSICAL) - AGGRAVATED ASSAULT        1481
         ASSAULT WITH DEADLY WEAPON ON POLICE OFFICER        749
Name: CCDESC, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How many are serious vs simple assaults?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">serious</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0    118744
1     47221
Name: serious, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have about 2.5x as many serious assaults as we do simple assaults. Typically you want to have equal numbers of both, but we'll see how it goes for now.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Downgrading-some-serious-assaults">Downgrading some serious assaults<a class="anchor-link" href="#Downgrading-some-serious-assaults">#</a></h2><p>The Los Angeles Times looked for (and found) Part I crimes that the LAPD had downgraded to Part II. We don't have access to these original attributions, though, so we'll need to randomly select serious crimes to downgrade.</p>
<p>Let's take 15% of the serious crimes and downgrade them to Part II. I'd rather not save this in another file because I don't want to imply it's real - <strong>it's just us faking the downgrade for the purposes of the exercise.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Select a random sample of 15% of the part I crimes</span>
<span class="n">serious_subset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">serious</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>

<span class="c1"># So we can flag the ones we&#39;re downgrading</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;downgraded&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Update the original dataframe to downgrade them to part_ii</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">serious_subset</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;downgraded&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">serious_subset</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="s1">&#39;serious&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>How many did we downgrade?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">downgraded</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>7083</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Before we had 118,744 simple assaults and 47,221 serious assaults. What's that number look like now?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">serious</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0    125827
1     40138
Name: serious, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And now we'll take a look at some of the downgraded assaults. Bear in mind that <strong>we selected the assaults to downgrade randomly.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">downgraded</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CCDESC</th>
      <th>DO_NARRATIVE</th>
      <th>serious</th>
      <th>downgraded</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-S APPRCHED V AND STATED ARE YOU GOING TO FCK ME V REPLIED NO SUSP PULL ED OUT A KNIFE AND STATED IM HERE TO HURT YOU BTCH S USED PROFANITIES</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>64</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-SUSP DROVE TO THE DRIVER SIDE OF THE VICTS VEH S1 FRNT PSGR OF THE SUPSVEH PRODUCED HANDGUN FIRED APPROX FIVE ROUNDS AT VICT ASSIGNED TO GANG DETS</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>87</th>
      <td>CHILD ABUSE (PHYSICAL) - AGGRAVATED ASSAULT</td>
      <td>DO-V WAS STRUCK WITH BELT</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>243</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-SUSP DROVE UP ALONG SIDE VICTS DRIVER SIDE WINDOW AND STATED BITCH YOU TRIED TO HIT MY SON SUSP REMOVED BOTTLE WITH RIGHT HAND AND THREW IT AT VICT</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>716</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO- S YELLED AT V FUK SOUTH LOS AND SHOT 8X WITH HANDGUN                  AT V WHO WAS IN V VEH S FLED ON FOOT TO UNK LOC</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>778</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO- SUSP BECAME ANGRY AT VICT CHALLENGED TO FIGHT PULLED HANDGUN FROM REARWAISTBAND PRESSED AGAINST VICTS HEAD AND PULLED TRIGGER MAKING CLICK  SUSP STAT</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1069</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-S1 FIRED AT UNK MOTORIST AND STRUCK VICT VEH S2 STOOD BY AS A LOOKOUT</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1184</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-V TRIED TO BREAK UP FIGHT BETWEEN WIT AND S S STABBED V ON THE ABDOMEN S FLED IN VEH IN UNK DIR</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1519</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-SUSPS AND VICT WERE INVOVLED IN VERBAL DISPUTE  SUSPS BECAME UPSET AND STRUCK VICT W WOODEN STICKS CAUSING INJURY</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1736</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-SUSPS1-3 PUNCHED AND KICKED VIC CAUSING A SMALL CONTUSION BEHIND HER RTEAR AND TO LOSE CONSCIOUSNESS</td>
      <td>0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Time-to-classify">Time to classify<a class="anchor-link" href="#Time-to-classify">#</a></h1><p>Now we're going to build a classifier that can predict whether an assault is serious or non-serious. To do that, we first need to count all the words in each description.</p>
<h2 id="Stemming">Stemming<a class="anchor-link" href="#Stemming">#</a></h2><p>When we talk about "words," we can mean a few different things. Do you feel like "stab," "stabbed," and "stabbing" should all count the same? If yes, you're interested in <strong>stemming.</strong></p>
<p>Stemming is the process of trying to convert words to their root. There are a few different kinds of stemmers, but we'll be using one called <strong>SnowballStemmer</strong> that comes with NLTK.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">SnowballStemmer</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">SnowballStemmer</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's see how it works in the case of different tenses of the word "stabbing:"</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;stab&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;stabbed&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;stabbing&quot;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>stab
stab
stab
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Looks good! It also works with singular and plurals.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;gun&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;guns&quot;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>gun
gun
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It can have trouble with more complicated words, though. Here's an example with "knife" as compared to "knives."</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;knife&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;knifed&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="s2">&quot;knives&quot;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>knife
knife
knive
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If it gets most of what we're looking for, though, I think we're okay.</p>
<h2 id="Building-a-vectorizer-that-uses-stemming">Building a vectorizer that uses stemming<a class="anchor-link" href="#Building-a-vectorizer-that-uses-stemming">#</a></h2><p>Vectorizing is the process of converting words to numbers, and counting each of them (along with any other transformations). It's a little complex to incorporate stemming into the process, but here we go.</p>
<p>We're also using a <code>TfidfVectorizer</code>, which doesn't count words exactly. More common words become less meaningful, and words in short sentences mean more than words in longer sentences.</p>
<p>For example, your name showing up in a tweet probably means the tweet is about you. If your name shows up once in a big, big book, though, the chances are much lower that the entire book is about you.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">stemmer</span> <span class="o">=</span> <span class="n">SnowballStemmer</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">StemmedTfidfVectorizer</span><span class="p">(</span><span class="n">TfidfVectorizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">build_analyzer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">analyzer</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">StemmedTfidfVectorizer</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build_analyzer</span><span class="p">()</span>
        <span class="k">return</span> <span class="k">lambda</span> <span class="n">doc</span><span class="p">:(</span><span class="n">stemmer</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">analyzer</span><span class="p">(</span><span class="n">doc</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we'll actually use our vectorizer to count the words. We're being a little picky, in that:</p>
<ul>
<li>We're only using words that show up at least 15 times in our dataset, and</li>
<li>We're ignoring anything that shows up in more than half of the police reports</li>
</ul>
<p>This helps cut down on noise. Adjusting the terms will give us a greater or fewer number of words, and might also affect our accuracy later on.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">StemmedTfidfVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">DO_NARRATIVE</span><span class="p">)</span>
<span class="n">X</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 1min 8s, sys: 859 ms, total: 1min 9s
Wall time: 1min 15s
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;165965x3417 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39;
	with 2119793 stored elements in Compressed Sparse Row format&gt;</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we're only paying attention to words that show up at least 15 times, and are ignoring words that show up in half of the reports, how many words we we using?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>3417</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Examining-our-words">Examining our words<a class="anchor-link" href="#Examining-our-words">#</a></h2><p>While it doesn't do us much good in terms of analysis, we can take a pick look at our words and sentences to see what shows up where.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">words_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> <span class="n">columns</span><span class="o">=</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
<span class="n">words_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>01</th>
      <th>08</th>
      <th>09</th>
      <th>10</th>
      <th>100</th>
      <th>101</th>
      <th>103rd</th>
      <th>10time</th>
      <th>10x</th>
      <th>10yr</th>
      <th>11</th>
      <th>112</th>
      <th>112th</th>
      <th>118</th>
      <th>11th</th>
      <th>11yr</th>
      <th>12</th>
      <th>12yr</th>
      <th>13</th>
      <th>14</th>
      <th>14yr</th>
      <th>15</th>
      <th>15yr</th>
      <th>16</th>
      <th>16yr</th>
      <th>17</th>
      <th>18</th>
      <th>18th</th>
      <th>18yr</th>
      <th>19</th>
      <th>1cic</th>
      <th>1s</th>
      <th>1st</th>
      <th>1x</th>
      <th>1yr</th>
      <th>20</th>
      <th>20yr</th>
      <th>21</th>
      <th>22</th>
      <th>23</th>
      <th>23rd</th>
      <th>24</th>
      <th>25</th>
      <th>25yr</th>
      <th>28th</th>
      <th>2gether</th>
      <th>2mos</th>
      <th>2nd</th>
      <th>2time</th>
      <th>2x</th>
      <th>...</th>
      <th>witmer</th>
      <th>wk</th>
      <th>wks</th>
      <th>wlkd</th>
      <th>wlkng</th>
      <th>wndw</th>
      <th>wo</th>
      <th>woke</th>
      <th>woman</th>
      <th>women</th>
      <th>wood</th>
      <th>wooden</th>
      <th>woodman</th>
      <th>word</th>
      <th>work</th>
      <th>worker</th>
      <th>workplac</th>
      <th>would</th>
      <th>wouldnt</th>
      <th>wound</th>
      <th>wout</th>
      <th>wrap</th>
      <th>wre</th>
      <th>wrench</th>
      <th>wrestl</th>
      <th>wrist</th>
      <th>write</th>
      <th>wrong</th>
      <th>wrote</th>
      <th>ws</th>
      <th>wth</th>
      <th>wtih</th>
      <th>wy</th>
      <th>xboyfriend</th>
      <th>xs</th>
      <th>yall</th>
      <th>yank</th>
      <th>yard</th>
      <th>year</th>
      <th>yell</th>
      <th>yellow</th>
      <th>yes</th>
      <th>yo</th>
      <th>you</th>
      <th>younger</th>
      <th>your</th>
      <th>yourself</th>
      <th>yr</th>
      <th>yrs</th>
      <th>zone</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.296974</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.4045</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.205927</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.224758</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>10 rows  3417 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Classify">Classify<a class="anchor-link" href="#Classify">#</a></h2><blockquote><p>"SVM models perform better on sparse data than does trees in general. For example in document classification you may have thousands, even tens of thousands of features and in any given document vector only a small fraction of these features may have a value greater than zero."</p>
<p><a href="https://towardsdatascience.com/support-vector-machine-vs-logistic-regression-94cc2975433f">https://towardsdatascience.com/support-vector-machine-vs-logistic-regression-94cc2975433f</a></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">words_df</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">serious</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>CPU times: user 6 s, sys: 6.3 s, total: 12.3 s
Wall time: 16.6 s
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,
          intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000,
          multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=None, tol=0.0001,
          verbose=0)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="What-words-are-important?">What words are important?<a class="anchor-link" href="#What-words-are-important?">#</a></h2><p>Before we see how our classifier performs, let's take a look at which words point towards a report being either simple or aggravated assault. In this case, we're going to look at the top and bottom 20 terms.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># This is the older way to do it, leaving it here for historical reasons</span>

<span class="c1"># top_features = 20</span>
<span class="c1"># feature_names = vectorizer.get_feature_names()</span>

<span class="c1"># coef = clf.coef_.ravel()</span>
<span class="c1"># sorted_coefs = np.argsort(coef)</span>
<span class="c1"># coef_indices = np.r_[0:top_features, -top_features:0]</span>
<span class="c1"># top_coefficients = sorted_coefs[coef_indices]</span>

<span class="c1"># terms = np.array(feature_names)[top_coefficients]</span>
<span class="c1"># coefs = coef[top_coefficients]</span>

<span class="c1"># terms = pd.DataFrame({&#39;coef&#39;: coefs }, index=terms)</span>
<span class="c1"># terms.sort_values(by=&#39;coef&#39;, ascending=False)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">eli5</span>

<span class="n">eli5</span><span class="o">.</span><span class="n">show_weights</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">vec</span><span class="o">=</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

    <style>
    table.eli5-weights tr:hover {
        filter: brightness(85%);
    }
</style>



    

    

    

    

    

    


    

    

    

    
        

    

        
            
                
                
    
        <p style="margin-bottom: 0.5em; margin-top: 0em">
            <b>
    
        y=1
    
</b>

top features
        </p>
    
    <table class="eli5-weights"
           style="border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;">
        <thead>
        <tr style="border: none;">
            
                <th style="padding: 0 1em 0 0.5em; text-align: right; border: none;" title="Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.">
                    Weight<sup>?</sup>
                </th>
            
            <th style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">Feature</th>
            
        </tr>
        </thead>
        <tbody>
        
            <tr style="background-color: hsl(120, 100.00%, 80.00%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.652
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        stab
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 82.21%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.244
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        degre
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 82.33%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.222
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        shot
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 82.41%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.207
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        bat
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 82.70%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.156
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        knife
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 82.76%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.145
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        andstab
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 83.00%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.102
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        stabe
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 83.30%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +2.050
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        great
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 83.70%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.981
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        shovel
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 84.18%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.898
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        brass
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 84.60%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.826
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        machet
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 84.61%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.825
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        shoot
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 84.86%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.781
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        acceler
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 85.02%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.755
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        baton
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 85.09%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.743
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        crowbar
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 85.13%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.737
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        hatchet
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 85.18%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.728
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        bottl
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 85.21%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.723
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        usd
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 85.22%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.722
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        ram
    </td>
    
</tr>
        
            <tr style="background-color: hsl(120, 100.00%, 85.22%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        +1.722
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        hammer
    </td>
    
</tr>
        
        
            <tr style="background-color: hsl(120, 100.00%, 85.22%); border: none;">
                <td colspan="2" style="padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;">
                    <i>&hellip; 2125 more positive &hellip;</i>
                </td>
            </tr>
        

        
            <tr style="background-color: hsl(0, 100.00%, 89.48%); border: none;">
                <td colspan="2" style="padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;">
                    <i>&hellip; 1253 more negative &hellip;</i>
                </td>
            </tr>
        
        
            <tr style="background-color: hsl(0, 100.00%, 89.48%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.059
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        phne
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 89.37%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.076
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        nt
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 89.34%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.080
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        ph
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 89.30%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.086
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        airsoft
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 89.27%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.090
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        andchok
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 89.09%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.115
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        spit
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 89.02%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.126
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        wouldnt
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.85%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.151
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        spat
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.75%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.165
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        grade
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.61%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.186
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        usag
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.59%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.190
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        inuri
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.51%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.201
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        sand
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.46%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.209
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        spent
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.46%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.209
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        patient
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.43%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.214
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        egg
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 88.18%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.251
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        cam
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 87.98%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.281
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        flick
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 87.75%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.317
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        ahead
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 87.38%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.374
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        push
    </td>
    
</tr>
        
            <tr style="background-color: hsl(0, 100.00%, 86.49%); border: none;">
    <td style="padding: 0 1em 0 0.5em; text-align: right; border: none;">
        -1.515
    </td>
    <td style="padding: 0 0.5em 0 0.5em; text-align: left; border: none;">
        ppa
    </td>
    
</tr>
        

        </tbody>
    </table>

            
        

        



    

    

    

    


    

    

    

    

    

    


    

    

    

    

    

    




</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we jump through a couple hoops, we can also have a nice colored graphic!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Build a dataframe of what we have above</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">eli5</span><span class="o">.</span><span class="n">explain_weights_df</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">vec</span><span class="o">=</span><span class="n">vectorizer</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>

<span class="c1"># Pick colors based on being above or below zero</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">weight</span><span class="p">:</span> <span class="s1">&#39;lightblue&#39;</span> <span class="k">if</span> <span class="n">weight</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;tan&#39;</span><span class="p">)</span>

<span class="c1"># Sort it and plot it</span>
<span class="n">weights</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
    <span class="n">by</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span>
    <span class="n">ascending</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="s1">&#39;feature&#39;</span><span class="p">,</span>
    <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;barh&#39;</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">),</span>
    <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x2397dd9b0&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAdQAAAHSCAYAAABVfjpxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdebheVWH2/+8NAQnzlPoT5RgUZEogwsHXCKEBwRcVFSsWJVbjFBkKoj+sVlFBqYq0L6IINPZFkKRIiThScWAMYUpCRsa2EotiNREIU8AQ7vePvY48HM6Uk+c5z3Duz3XlevZZe+211+afxdp77XvLNhEREbFhNmp2ByIiIjpBBtSIiIg6yIAaERFRBxlQIyIi6iADakRERB1kQI2IiKiDMc3uQCvbcccdPX78+GZ3IyIiWsTChQtX2R7X174MqAMYP348CxYsaHY3IiKiRUj6dX/72v6Wr6RTJG0+hHorJO04En2KiIjRpxNmqKcAs4Anm92RiP4su+qfmt2FiFFv4pv//4a231YzVElbSLpK0hJJyyV9HtgJuE7SdaXOBZIWSLpT0hm9mvg7Scsk3S5p1xG/gIiI6FjtNkM9AnjQ9psBJG0DvB84xPaqUuczth+StDFwjaR9bC8t+1bbnijpvcDXgCN7n0DSDGAGQFdXV4MvJyIiOkVbzVCBZcDhks6SNMX26j7q/LWkO4BFwN7AXjX7Lqv5ndzXCWzPtN1tu3vcuD4XckVERLxAW81Qbd8naT/gTcCZkq6p3S9pF+BU4ADbD0u6GNistol+tiMiIjZIWw2oknYCHrI9S9IjwIeAx4CtgFXA1sATwGpJLwbeCFxf08QxwFfK7y0j2PUY5Rq9GCIimq+tBlRgInC2pGeBtcDxVLdur5b0oO1DJC0C7gEeAOb1On47SUuBp4F3j2C/IyKiwykfGO9fd3e3E+wQERE9JC203d3XvnZblBQREdGSMqBGRETUQUsPqJJOl3Rqs/sRERExmHZblLTeJI2x/Uyz+xGjW6IHY7QaTSvcW26GKukzku6TdBOweyl7paSrJS2UNFfSHjXlt5Y4wTMlPV7Kp5Z6PwLuKmXvKZGDiyX9c0lSioiIqIuWGlAl7Q+8C5hEFd5wQNk1EzjJ9v5UwQ3nl/JzgXNtTwR+06u5/YCP2n6VpD2p3j090PYkYB0wrZ8+zChZwAtWrlxZx6uLiIhO1mq3fKcA37f9JECZYW4GvA64QlJPvReV38nAUWX7X4F/rGnrdtv3l+3XA/sD80sbY4E/9NUB2zOpBnC6u7vzTlFERAxJqw2ofdkIeKTMLNfHEzXbAi6x/ff161ZERMRzWm1AvRG4WNKXqfr2FuCfgfslvdP2FaqmmPvYXgLcCrwDuJzqVnF/rgF+KOkc23+QtD2wle1+v7weUU+jaWFGxGjVUs9Qbd9BNTguAX4KzC+7pgEflLQEuBN4Wyk/Bfh4iRPcFejr6zPYvgs4Dfh5qfsL4CWNuo6IiBh92jp6UNLmwBrblvQu4N223zbYcUOV6MGIiKg1UPRgq93yXV/7A+eV28CPAB9ocn8iImKUausB1fZcSdsA3bZXDeUYSVOBP9m+uaGdi4iIUaWtB9Rhmgo8DmRAjRGTpKQYbUbjQryWWpQ0GElbSLpK0hJJyyUdU3adJOmOkpjUk6K0vaQfSFpa0pT2kTQeOA74WElMmtKkS4mIiA7TVgMqcATwoO19bU8Ari7lq2zvB1xAlaQEcAawyPY+wKeB79heAVwInGN7ku25I9v9iIjoVO02oC4DDpd0lqQptntek7my/C4Expftg4BLAWxfC+wgaevBTpDowYiIGI62GlBt30eV0bsMOFPS58qup8vvOjbwubDtmba7bXePGzduQ5qKiIhRpK0GVEk7AU/angWcTTW49mcuJQC/rOxdZftR4DFgqwZ3NSIiRpl2W+U7EThb0rPAWuB4YE4/dU8HLirJSE8C7yvlPwbmSHob1Rds8hw1Gm40rniMGG3aOimp0ZKUFBERtQZKSmqrW74RERGtKgNqREREHbT9gCppvKTl61F/elncFBERUTfttiipHqYDy4EHm9yPGEUSPRijyWhdhNf2M9RijKTZku6WNEfS5pI+J2l+iSicqcrRQDcwu0QPjm12xyMiojN0yoC6O3C+7T2BR4ETgPNsH1AiCscCR9qeAywAppXowTXN63JERHSSThlQH7A9r2zPooodPETSbZKWAYcCew+loUQPRkTEcHTKgNr7ZVoD5wNH254IfAvYbEgNJXowIiKGoVMG1C5Jk8v2scBNZXuVpC2Bo2vqJnowIiLqrlNW+d4LnCjpIuAuqs+4bUe1mvd/gPk1dS8GLpS0Bpic56gxEkbrqseI0STRgwNI9GBERNRK9GBERESDZUCNiIiog5YfUIcRLfjvkrYt2yeXsIfZjethRERE5yxK+jPbb6r58wTgMNu/aVZ/IiDRg9G5suDuOS0/Q60l6RWSFkn6hKQrJV0t6T8kfbWmzgpJO0q6EHgF8FNJH5O0haSLJN1e2nhb864kIiI6TdvMUCXtDnyXKtz+1cCk8vs0cK+kb9h+oKe+7eMkHQEcYnuVpC8B19r+QLklfLukX9p+YsQvJiIiOk67zFDHAT+kyuBdUsqusb3a9lNU756+fJA23gB8StJi4Hqq5KSu3pUSPRgREcPRLjPU1cB/U2X03lXKnq7Zv47Br0XAO2zfO1Al2zOBmVC9hzqs3kZExKjTLjPUPwFvB94r6dhhtvEz4CRJApD06np1LiIiol1mqNh+QtKRwC+AS4fRxBeBrwFLJW0E3A8cWccuRvQrKyEjOl/LD6i2VwATyvYjwAF91DmyZnt8P9trgI80rqcRETGatcst34iIiJaWATUiIqIOWn5AlfT4IPs/XY92IiIiNkTLP0Mdgk8DX2p2JyIGkujB6ERZbPd8IzJDlfQDSQsl3SlpRil7XNI/SFoi6VZJLy7lu0i6RdIySWfWtPESSTdKWixpuaQpkr4CjC1ls/s7V00b55TyaySNG4lrj4iI0WGkbvl+wPb+QDdwsqQdgC2AW23vC9wIfLjUPRe4wPZE4Hc1bRwL/Mz2JGBfYLHtTwFrbE+yPW2Ac1HOt8D23sANwOcbdrURETHqjNSAerKkJcCtwM7AblRhDT8p+xcC48v2gcBlZbv2fdP5wPslnQ5MtP3YepwL4Fng8rI9iyp16QUSPRgREcPR8AFV0lTgMGBymY0uosrRXWu7J9qvd3TgCyL/bN8IHAz8FrhY0nvX41x96TNW0PZM2922u8eNy13hiIgYmpFYlLQN8LDtJyXtAbx2kPrzgHdRzSJ7buMi6eXAb2x/S9KLgP2A7wBrJW1ie+0g59oIOJrqizXHAjfV5/IiBpfFGxGdbyRu+V4NjJF0N/AVqluxA/kocKKkZcBLa8qnAkskLQKOoXrWClWQ/dKyKGmgcz0BvEbScuBQ4AsbdFURERE19Nxd1+itu7vbCxYsaHY3IiKiRUhaaLu7r30tH+wQERHRDjKgRkRE1EHbDKiSTpG0+RDqrZC040j0KSIiokc7RQ+eQrXy98lmdyRifSV6MDpFVqz3ryVnqJK2kHRViSVcLunzwE7AdZKuK3UuKAEMd0o6o1cTf1eiC2+XtGupP07S9yTNL/8OHOHLioiIDtaqM9QjgAdtvxlA0jbA+4FDbK8qdT5j+yFJGwPXSNrH9tKyb7XtiSX84WvAkVSv2Zxj+yZJXcDPgD1H8qIiIqJzteQMFVgGHC7pLElTbK/uo85fS7qDKg1pb2Cvmn2X1fxOLtuHAedJWgz8CNha0pa9G030YEREDEdLzlBt3ydpP+BNwJmSrqndL2kX4FTgANsPS7qY50cMuo/tjYDX2n5qkHPPpAqLoLu7Oy/pRkTEkLTkgCppJ+Ah27MkPQJ8CHgM2ApYBWxNlXy0unz27Y3A9TVNHEOVlHQMcEsp+zlwEnB2Occk24sbfzURWcgRMRq05IAKTATOlvQssBY4nurW7dWSHrR9SIkgvAd4gCr/t9Z2kpYCTwPvLmUnA98s5WOoPhl3XOMvJSIiRoNEDw4g0YMREVEr0YMRERENlgE1IiKiDkbdgCppkqQ3NbsfERHRWVp1UdKQSBpj+5n1PGwS0A38ewO6FNGnRA9GO8rq9PXT0jNUSZ+VdK+kmyRdJulUSddL+pqkBcBH+4sUlPQaSbdIWiTpZkm7S9qU6sPix0haLOmYpl5gRER0jJadoUo6AHgHsC+wCXAHsLDs3rRnlZWkf6XvSMF7gCm2n5F0GPAl2++Q9Dmg2/bf9nPeGcAMgK6ursZdYEREdJSWHVCBA4EflmSjpyT9uGbf5TXbhwF7Ser5uydScBvgEkm7UaUlbTKUkyYpKSIihqOVB9SBPFGz3WekoKTzgOtsv13SeJ6fpBQREVFXrTygzgP+WdKXqfp5JGXm2Et/kYLbAL8tdabX1O+JMIwYMVncEdH5WnZRku35VF+FWQr8lOoLNH19deZkoFvSUkl38Vyc4FeBL5eIwtr/cbiO6hZxFiVFRETdtHT0oKQtbT8uaXOq7N0Ztu8YqfMnejAiImoNFD3Yyrd8AWZK2ovq02yXjORgGhERsT5aekC1fWyz+xARETEULfkMVdIKSTs2sP3pZRVwREREXbT0DDWiUyR6MFpZVqHXR9NnqJK2kHSVpCWSltesvD1J0h2Slknao9TdXtIPyoreWyXtI2mjMqPdtqbN/5D04v5iCSMiIuqt6QMqcATwoO19bU8Ari7lq2zvB1wAnFrKzgAW2d4H+DTwHdvPAj8E3g4g6X8Bv7b9e+BcqljCnhjDfxmsM5JmSFogacHKlSvrd5UREdHRWmFAXQYcLuksSVNs97xremX5XQiML9sHAZcC2L4W2EHS1lRRhD0z23fxXDThYcB5khZTvdPaE0vYL9szbXfb7h43btyGX11ERIwKTX+Gavs+SfsBbwLOlHRN2fV0+V3H4P28BdhV0jjgKODMUt5fLGFd+h4REdGj6QOqpJ2Ah2zPkvQI8KEBqs8FpgFflDSV6rbwo6Wd7wP/B7jb9h9L/f5iCSNGVBZ9RHS+pg+owETgbEnPAmuB44E5/dQ9HbhI0lLgSeB9NfsuB+bz/Nzek4FvlvpjqNKWjiMiIqLOWjp6sNkSPRgREbUGih5shUVJERERba9lB1RJ4yUtb3Y/IiIihqIVnqEOm6SNba9rdj8iBpOkpGi2LIxrvJadoRZjJM2WdLekOZI2L6lIZ0m6A3inpA+XFKQlJRVpcwBJ7yzJS0sk3VjK9pZ0e/kW6lJJuzX16iIiomO0+oC6O3C+7T2BR4ETSvkfbe9n+7vAlbYPsL0vcDfwwVLnc8D/LuVvLWXHAefangR0A78ZqQuJiIjO1uoD6gO255XtWVRJSfBcEhLABElzJS2jekd171I+D7hY0oeBjUvZLcCnJX0SeLntNb1PmOjBiIgYjlYfUHu/09Pz9xM1ZRcDf2t7IlXW72YAto8DTgN2BhZK2sH2v1LNVtcA/y7p0BecMNGDERExDK0+oHZJmly2jwVu6qPOVsDvJG1CNUMFQNIrbd9m+3PASmBnSa8AfmX761SB+vs0tvsRETFatPoq33uBEyVdBNxF9eWZk3rV+SxwG9WgeRvVAAtV+tJugIBrgCXAJ4G/kbQW+B/gSw2/ggiywjJiNEhS0gCSlBQREbWSlBQREdFgGVAjIiLqoO0H1BL0sON61J8k6U2N7FNERIw+rb4oqRF6Qh3+vdkdidEj0YMxUrIArnlGdIZaAu/vkXSxpPtKrOBhkuZJ+g9Jryn/bpG0SNLNknYvx24s6R9LnOBSSbWrfU+SdIekZZL2KPW3kHRRiRpcJOltkjYFvgAcU+IHjxnJ64+IiM7VjBnqrsA7gQ9QfRD8WKoEpLcCnwbeC0yx/Yykw6hebXkHMAMYD0wq+7avaXOV7f0knQCcCnwI+Axwre0PSNoWuB34JVUkYbftv238pUZExGjRjAH1ftvLACTdCVxj2yU6cDywDXBJeYfUwCbluMOAC20/A2D7oZo2ryy/C4G/KttvAN4q6dTy92ZA12CdkzSDavCmq2vQ6hEREUBzFiU9XbP9bM3fz1IN8F8ErrM9AXgLJUpwiG2u47n/SRDwDtuTyr8u23cP1lCiByMiYjhacZXvNsBvy/b0mvJfAB+RNAag1y3fvvyM6tmqSv1Xl/LHeC5NKSIioi5acZXvV6lu+Z4GXFVT/i/Aq4ClJTrwW8B5A7TzReBrpf5GwP3AkcB1wKckLQa+bPvyAdqIqIusvIzofIkeHECiByMiolaiByMiIhosA2pEREQdtM2Aur4RgwO0M1XS6+rRp4iIiB6tuCip0aYCjwM3N7kfMYokejBGShbANU9LzlBLbOBVkpaUqMGeiMC+Iga3l/SDEkd4q6R9+iuXNB44DvhYiR6c0pQLjIiIjtOSAypwBPCg7X1LwMPVpXyV7f2AC6giBgHOABbZ3ocquvA7/ZXbXgFcCJxTwh7mjszlREREp2vVAXUZcLiksyRNsb26lNdGDI4v2wcBlwLYvhbYQdLWA5QPSNIMSQskLVi5cmXdLigiIjpbSw6otu8D9qMaWM+U9Lmyq6+IwXqfO9GDERGx3lpyQJW0E/Ck7VnA2VSDa3/mAtPKcVOpbgs/OkB5ogcjIqLuWnWV70TgbEnPAmuB44E5/dQ9HbhI0lLgSeB9g5T/GJgj6W3ASXmOGiMhKy8jOl+iBweQ6MGIiKiV6MGIiIgGy4AaERFRBx01oEq6XlKfU/GIiIhGatVFSSNC0sa21zW7H9H5Ej0YjZIFb62jKTPUEgm4UNKdkmaUsiNKrOASSdeUsi0lfbtEDS6V9I5S/gZJt5T6V0jaso9z9FmnhOyfJekO4J0jeNkREdHBmjVD/YDthySNBeZL+iHwLeBg2/dL2r7U+yyw2vZEAEnblS/OnAYcZvsJSZ8EPg58oafxIdT5Y4kwjIiIqItmDagnS3p72d4ZmAHcaPt+ANsPlX2HAe/qOcj2w5KOBPYC5kkC2BS4pVf7rx2kzuX9dazMmGcAdHV1DefaIiJiFBrxAbWkFh0GTLb9pKTrgcXAHkNtAviF7XdvQJ0n+jvQ9kxgJlTvoQ6xTxERMco14xnqNsDDZTDdg2o2uRlwsKRdoPr0Wqn7C+DEngMlbQfcChwoaddStoWkV/U6x1DqRERE1E0zbvleDRwn6W7gXqrBbyXVbdYrJW0E/AE4HDgT+Kak5VSB+GfYvlLSdOAySS8qbZ4G3NdzAtsrB6sTMZKyEjOi8yV6cACJHoyIiFqJHoyIiGiwDKgRERF10HIDqqTx5ZnpUOtPL99PjYiIaJpOiB6cDiwHHmxyPyL6lejBqLcsdGs9LTdDLcZImi3pbklzJG0u6XOS5ktaLmmmKkcD3cBsSYsljZX0ekmLSlzhRT2rfEvk4BklinBZeWUnIiKiLlp1QN0dON/2nsCjwAnAebYPsD0BGAscaXsOsACYZnsSYOBi4JgSVzgGOL6m3VUlcvAC4NQRu5qIiOh4rTqgPmB7XtmeBRwEHCLpNknLgEOBvfs4bnfgfts975teAhxcs//K8rsQGN/XiSXNkLRA0oKVK1du4GVERMRo0aoDau+XYw2cDxxdZp7fokpXWl9Pl9919PP82PZM2922u8eNGzeMU0RExGjUqouSuiRNtn0LcCxwE/A6YFX5DNvRwJxS9zFgq7J9LzBe0q62/xP4G+CGke16xAtlAUlE52vVAfVe4ERJFwF3UT3z3I5qNe//APNr6l4MXChpDTAZeD9whaQxpd6FI9jviIgYpRI9OIBED0ZERK1ED0ZERDRYBtSIiIg6aOsBtcQOntfsfkRERDR9UZKkMbafadK5N7a9rhnnjtEl0YNRT1k13ppGZIYq6b2SlkpaIulSSRdLulDSbcBXJW0v6Qelzq2S9inHLZO0bYkZ/KOk95by70g6vDS/s6TrJf2HpM/XnPMHkhZKulPSjJryxyX9k6QlVKuCIyIiNljDB1RJewOnAYfa3hf4aNn1MuB1tj8OnAEssr0P8GngO6XOPOBAqlSkXwFTSvlk4Oay/RrgHcA+wDsl9ay++oDt/amyfk+WtEMp3wK4zfa+tm+q+wVHRMSoNBIz1EOBK2yvArD9UCm/ouZ260HApWX/tcAOkrYG5lJFBx5M9S7qREkvBR62/UQ59he2/2h7DVW04EGl/OQyC70V2BnYrZSvA77XX2cTPRgREcPRzEVJTwxehRupZqVTgOuBlVQpSXNr6rwgplDSVOAwYHKZFS/iuajCpwZ6bprowYiIGI6RWJR0LfB9Sf/H9h8lbd9HnbnANOCLZTBcZftR4FFJOwKb2v6VpJuovhLztzXHHl7aXAMcBXwA6JnFPlk+0/bahl1dxBBkEUlE52v4gGr7Tkn/ANwgaR3VbLG304GLJC0FngTeV7PvNmDjsj0X+DJVtm+P26lu4b4MmGV7QfkizXGS7qaKMby1jpcUERHxAokeHECiByMiolaiByMiIhosA2pEREQdjNiAKmm8pOXrUf8oSXsNUmeqpJ+sZz+mS9ppfY6JiIgYTNOjBwdwFPATqu+h1tN0qu+qPljndiP6lejBqKesGm9NI33Ld2NJ3ypxgD+XNFbShyXNL7GE35O0uaTXAW8Fzpa0WNIrJe0q6Zel3h2SXlna3FLSHEn3SJotSQCS9pd0Q4kf/Jmkl0g6mio5aXZpd+wIX39ERHSokR5QdwO+aXtv4BGqyMArbR9QAhjuBj5o+2bgR8AnbE+y/V/A7HLsvsDrgN+VNl8NnALsBbwCOFDSJsA3gKNL/OBFwD/YngMsAKaVdtf07mCSkiIiYjhG+pbv/bYXl+2FwHhggqQzgW2BLYGf9T5I0lbAS21/H8D2U6Uc4Hbbvyl/Ly5tPgJMAH5R6mzMcwPwgGzPBGZC9drMMK4xIiJGoZEeUJ+u2V4HjAUuBo6yvUTSdGDqBrY5BhBwp+18TSYiIkZEKyxK2gr4XblNOw34bSl/rOzD9mOSfiPpKNs/kPQinktP6su9wDhJk23fUtp+le07a9uNGClZRBLR+VrhPdTPUsULzgPuqSn/LvAJSYvKAqS/ofqCzFKqT7f9f/01aPtPVCH6Z5Uvziymeu4K1Yz4wixKioiIekr04AASPRgREbUSPRgREdFgGVAjIiLqoG0G1GFEF54iafOavz/da//j9exfRESMbq2wyrdRTgFmUX1fFeDTwJea150YzRI9GPWSFeOtq21mqMWYEi94d4kb3FzS68tK4GWSLpL0IkknAzsB10m6TtJXgLFlZe/sJl9DRER0oHYbUHcHzre9J/Ao8HGq12COsT2RasZ9vO2vU4XfH2L7ENufAtaUuMFpA50g0YMRETEc7TagPmB7XtmeBbyeKs7wvlJ2CXDwhpzA9kzb3ba7x40btyFNRUTEKNJuA2rvl2YfaUovIiIiemm3RUldPXGCwLFUX475iKRdbf8nVZrSDaVuT8TgqvL3Wkmb2F474r2OUS8LSSI6X7vNUO8FTpR0N7AdcA7wfuAKScuAZ4ELS92ZwNWSrqv5e2kWJUVERCMkenAAiR6MiIhaiR6MiIhosFE7oEpaIWnHZvcjIiI6Q7stSopoS0lKinrI4rbW1tYDqqTxwE9sTyh/nwpsCTwEHAc8A9xl+12SdgAuA14K3AKoGX2OiIjO1Km3fD8FvNr2PlQDK8DngZts7w18H+hqVuciIqLzdOqAuhSYLek9VLNUqBKUZgHYvgp4uK8DEz0YERHD0e4D6jM8/xo2K79vBr4J7AfMlzTkW9uJHoyIiOFo9wH198BfSNpB0ouAI6muaWfb1wGfBLaheq56I1W6EpLeSBUMERERURdtvSjJ9lpJXwBuB34L3ANsDMyStA3VwqOv235E0hnAZZLuBG4G/rtZ/Y7RJ6szIzpfWw+oAOVTbV8fQr0/Am9ofI8iImI0avdbvhERES0hA2pEREQdZECNiIiog7Z/hipJVF/NebbZfYnoT6IHox6yuK21teUMVdJ4SfdK+g6wHPi/JYzhzrKat6feCklflrS47N9P0s8k/Zek4/o/Q0RExPpp5xnqbsD7bN8qaXvbD0naGLhG0j62l5Z6/217kqRzgIuBA6kCIJbz3MfIIyIiNkhbzlCLX9u+tWz/taQ7gEXA3sBeNfV+VH6XAbfZfsz2SuBpSdv2bjTRgxERMRyDDqiSXizp/0r6afl7L0kfbHzXBvUEgKRdgFOB15cw/Kt4LoIQ4Ony+2zNds/fL5ihJ3owIiKGYygz1IuBnwE7lb/vA05pVIeGYWuqwXW1pBcDb2xyfyIiYhQayjPUHW3/m6S/B7D9jKR1De7XkNleImkRVezgA8C8Jncp4gWyOjOi8w1lQH2ifJzbAJJeC6xuaK8GYXsFMKHm7+n91Btfs30x1Wz7BfsiIiI21FAG1I9TLex5paR5wDjg6Ib2KiIios0MOKBK2ohqgc9fArtTfb3lXttrR6BvERERbWPARUklfeibtp+xfaft5eszmJYAhuUb3MuIiIgWN5RbvtdIegdwpW03ukMjSdIY2880ux/R+RI9GPWQxW2tbSivzXwEuIIqCOFRSY9JenQ9zrGxpG+VWMCfSxor6cOS5ktaIul7kjYHkHSxpAsk3SrpV5KmSrpI0t2SLu5pUNLjks4ubf5S0mskXV+OeWups3GpM1/SUkkfKeVTJc2V9CPgrvW4joiIiH4NOqDa3sr2RrY3tb11+Xvr9TjHblS3jfcGHgF6ZrsH2N4XuBuoDYrYDpgMfIxqMdQ5VOlHEyVNKnW2AK4tbT4GnAkcDrwd+EKp80Fgte0DgAOAD5cQCID9gI/aftV6XEdERES/Br3lK+ngvspt3zjEc9xve3HZXgiMByZIOhPYFtiSKjiix49tW9Iy4Pe2l5V+3FmOXQz8Cbi61F8GPG17bTlmfCl/A7CPpJ4VydtQDe5/Am63fX8/1zsDmAHQ1dU1xEuMiIjRbijPUD9Rs70Z8BqqgfHQIZ6jNu5vHTCW6n3Qo0oow3Rgah/1B4oKXFvzPPfP9Ww/K6mnjoCTbNcO1kiaSokt7IvtmcBMgO7u7hLVeY4AAB/6SURBVI56ZhwREY0z6IBq+y21f0vaGfjaBp53K+B3kjYBpgG/3cD2+vIz4HhJ15bZ66sadJ6IiIhhfb7tN8CeG3jezwK3ASvL71Yb2F5f/oXq9u8d5SPkK4GjGnCeiEFldWZE59Ngb8JI+gYldpBqEdMkYIXt9zS4b03X3d3tBQsWNLsbERHRIiQttN3d176hzFBrR5RngMtsJ4A+IiKixlAG1G1tn1tbIOmjvcsiIiJGs6EEO7yvj7Lpde7HepG0QtKOzexDRERErX5nqJLeDRwL7FJShXpsBTzU6I5F41157++a3YVR4692f0mzuxARDTbQLd+bgd8BOwK1QaSPAUsb2akeksZTBTgspEo3uhN4b9l9kqS3AJsA77R9j6TTgS7gFeX3a7a/Xtp6D3AysCnVyuITbLfMh9IjIqK99XvL1/avbV9ve7LtG2r+3THCgfK7A+fb3hN4FDihlK+yvR9wAXBqTf09gP9NFUDxeUmbSNoTOAY40PYkqoCJaSN1ARER0fkGfYYq6bUlYP5xSX+StG49w/E31AM1q4pnAQeV7SvLb0+cYY+rbD9texXwB+DFwOuB/YH5khaXv1/R18kkzZC0QNKClStX1vdKIiKiYw1lle95wLuovjjTTXXLdSRD5Xu/KNvzd08s4Tqefx29ow7HUMUQXmL77wc9WaIHIyJiGIayyhfb/wlsbHud7W8DRzS2W8/TJWly2T4WuGkYbVwDHC3pLwAkbS/p5fXqYERExFBmqE9K2hRYLOmrVAuVhjQQ18m9wImSLqL6fukFwEnr04DtuySdBvxc0kbAWuBE4Nf17mw7ycrTiIj6GUr04MuB31Otjv0Y1WfQzi+z1sZ2rlrl+xPbExp9rr4kejAiImptUPSg7V9LGgu8xPYZde9dREREBxjKKt+3UH3U++ry96ReQQ8NY3tFs2anERER62Moz0JPp3qn8xEA24uBXRrYp4aSNF3STs3uR0REdJahLEpaa3t19UnRP2vn10mmA8uBB5vcj6ZK7ODIygKwiM43lAH1TknHAhtL2o0qvu/mxnZrw5UFTT+les3mdcBvgUup3qWdLWkNMNn2mmb1MSIiOke/t3wlXVo2/wvYmyow4TKq+L9TGt+1utgN+KbtvaluWZvq+67TbE/KYBoREfUy0Ax1//Ks8RjgEJ4fkL858FQjO1Yn95dnvvDCiMI+SZoBzADo6upqXM8iIqKjDDSgXkiVMPQKqlldD1HN9PrMwm0xvWMIxw52QKIHIyJiOPodUMtnz74u6QLbx49gnxrtMapvuo5qWSQTEVFfg74202GDKcDFwIWSFpfAioiIiA02lFW+bcn2CmBCzd//WLP7eyPeoYiI6GgjGXIfERHRsTKgRkRE1MGoGVAlrZC0Y7P7ERERnaljn6HGwBI9OLKyqjqi83XcDFXSeEn3SJot6W5JcyRtXnafJOkOScsk7dHUjkZEREfpuAG12J3qI+h7UkUlnlDKV9neD7gAOLVZnYuIiM7TqQPqA7bnle1ZwEFl+8ry228MoaQZkhZIWrBy5crG9jIiIjpGpw6ovSMDe/7uiSJcRz/Pj23PtN1tu3vcuHGN6l9ERHSYTl2U1CVpsu1bgGOpPuH26ib3qaVkkUxERH116gz1XuBESXcD21E9M42IiGiYTp2hPmP7Pb3Kxvds2F4ATB3JDkVERGfr1BlqRETEiOq4GWrvUPyIiIiR0LIzVEn/LmnbOrSzR/lU2yJJ+0s6YfCjIiIi1k/LzlBtv6l3mSQBsv3sejR1FDDH9pmSxlOFPJxfl062qcQOjrysqo7ofC0xQ5X0A0kLJd0paUYpWyFpxxIleK+k7wDLgZ0lXSxpeYkQ/FipP0nSrZKWSvq+pO0kvQk4BThe0nXAV4BXlhnr2c263oiI6DytMkP9gO2HJI0F5kvq/QHw3YD32b5V0v7AS21PAKi5Lfwd4CTbN0j6AvB526dIuhB43PY/lhnqBNuT+utIGdBnAHR1ddXzGiMiooO1xAwVOFnSEuBWYGeqAbTWr23fWrZ/BbxC0jckHQE8KmkbYFvbN5Q6lwAHD6cjSUqKiIjhaPqAKmkqcBgw2fa+wCJgs17VnujZsP0wsC9wPXAc8C8j0tGIiIgBtMIt322Ah20/WT6p9tqBKpePhP/J9vck3QvMsr1a0sOSptieC/wNcEMfhz8GbFXvC2g3WSATEVF/rTCgXg0cV2IC76W67TuQlwLfltQzu/778vs+4MLy7dNfAe/vfaDtP0qaJ2k58FPbn6jLFURExKgnu/eHWaJHd3e3FyxY0OxuREREi5C00HZ3X/ua/gw1IiKiE2RAjYiIqIOWHVAlPT7I/usl9Tnt7qf+dEnnbXjPIiIiXqgVFiXFCEv04MjLyuqIztfQGWo/kYKPS/oHSUtKVOCLS/kukm4pcYJn9mrnk6V8iaSv1Ox6p6TbJd0naUqpu5mkb5f6iyQd0ke/3lzOtWMDLz8iIkaRRt/y/YDt/YFuqjSkHYAtgFtLiMONwIdL3XOBC2xPBP48hZL0RuBtwP8qx3y1pv0xtl9Dldf7+VJ2IuDSzruBSyRtVtPe24FPAW+yvap3hyXNkLRA0oKVK1fW4T9BRESMBo0eUPuKFPwT8JOyfyEwvmwfCFxWti+taeMw4Nu2nwSw/VDNviv7aOcgYFapew/wa+BVZd+hwCeBN5fEpRdI9GBERAxHwwbUASIF1/q5l1/X8fznuOv7UuzT/bTTn/+iSkp61WAVIyIi1kcjFyWtV6QgMA94F9XsclpN+S+Az0maXdravtcstbe55fhrJb0K6KJKYNqParb6CeBKSe+0feewrqzNZYFMRET9NfKW79XAmBIp+BUGjxT8KHCipGVU8YIA2L4a+BGwQNJi4NRB2jkf2Ki0czkw3XbPTLbnNvA04ApJr1zPa4qIiOhTogcHkOjBiIiolejBiIiIBhsVA6qk4yS9t2xPl7RTs/sUERGdZVQkJdm+sObP6cBy4MHm9KY5ko7UXFkIFtH52nZAlbQF8G/Ay4CNgS8CZ5WyNwJrgGNt/6ek04HHgRVUIROzJa2heqVnzcj3PiIiOk073/I9AnjQ9r62J1CtKgZYXVKSzgO+VnuA7TnAAmCa7UkZTCMiol7aeUBdBhwu6SxJU2yvLuWX1fxOXt9GEz0YERHD0bYDqu37qMIalgFnSvpcz67aasNoN9GDERGx3tp2QC0rdZ+0PQs4m2pwBTim5veWPg59jCp+MCIiom7adlESMBE4W9KzwFrgeGAOsJ2kpVQ5v+/u47iLgQtH26KkrDKNiGisjkpKkrQC6O7rs2zDkaSkiIiolaSkiIiIBmvnW74vYHt8s/sQERGjU9vNUCWdLukFX5yRNF7S8iEc/+nG9CwiIkazjpqhDtGngS81uxMjLdGDzZVFYRGdr+EzVEmfkHRy2T5H0rVl+1BJsyW9W9IyScslnVVz3OM120dLuriPtveXtETSEuDEmvLpkq6UdLWk/5D01VL+FWCspMWSZjfsoiMiYtQZiVu+c4EpZbsb2FLSJqXsPqr83UOBScABko5aj7a/DZxke98+9k2iehd1InCMpJ1tfwpYU2IHpw3vciIiIl5oJAbUhcD+kramejf0FqqBdQrwCHC97ZW2nwFmAwcPpVFJ2wLb2r6xFF3aq8o1tlfbfgq4C3j5ENtN9GBERKy3hg+ottcC91N9Nu1mqhnrIcCuVF9/6ffQmu3NhnHqp2u21zHE58WJHoyIiOEYqVW+c4FTgRvL9nHAIuB24C8l7ShpY6pkoxvKMb+XtKekjYC3927Q9iPAI5IOKkVDvYW7ttxyjoiIqJuRWuU7F/gMcIvtJyQ9Bcy1/TtJnwKuAwRcZfuH5ZhPAT8BVlJ9cm3LPtp9P3CRJAM/H2JfZgJLJd0xmp6jZpVpRERjdVT0YL0lejAiImolejAiIqLBMqBGRETUwagbUCVNlfS6ZvcjIiI6y2iMHpwKPE71Ck9HS9xg68iisIjO11YzVElbSLqqxA0ul3SMpBWSvlriC2+XtGup+xZJt0laJOmXkl4saTzVKzsfK/GDUwY6X0RExFC11YAKHAE8aHtf2xOAq0v5atsTgfOAr5Wym4DX2n418F3g72yvAC4Ezinxg3NHtvsREdGp2m1AXQYcLuksSVNsry7ll9X8Ti7bLwN+JmkZ8Alg76GcINGDERExHG01oNq+D9iPamA9U9LnenbVViu/3wDOKzPXjzDE+MJED0ZExHC01YAqaSfgSduzgLOpBleovirT83tL2d4G+G3Zfl9NM48BWzW4qxERMcq02yrficDZkp4F1gLHA3OA7SQtpQrEf3epezpwhaSHgWuBXUr5j4E5kt5G9em3jn2OmpWlEREjp+2jByWtALptr6p324kejIiIWokejIiIaLB2u+X7ArbHN7sPERERHT1DLaEPOza7HxER0fnaboYqaYztZ5rdj1aX2MHWkgViEZ2v5QZUSZ8F3kP1YfEHgIXAkcBi4CDgMkn3AacBmwJ/BKbZ/r2kHajCHV5K9fqMatp9D3ByOeY24ATb60bquiIiorO11C1fSQcA7wD2Bd4I1K6k2rQELvwTfcQKljqfB26yvTfwfaCrtLsn1TuqB9qeBKwDpo3AJUVExCjRajPUA4Ef2n4KeErSj2v2XV6z/TLgckkvoZpx3l/KDwb+CsD2VeUdVIDXA/sD8yUBjAX+0FcHJM0AZgB0dXXV45oiImIUaKkZ6iCeqNle31hBAZeUQPxJtne3fXpfFRM9GBERw9FqM9R5wD9L+jJV344EZvZRr79YwRuBY6lyft8IbFfKrwF+KOkc23+QtD2wle1fN+IiWkEWwUREjKyWmqHang/8CFgK/JQqBH91H1VPp4oVXAjUJiSdARws6U6qW7//Xdq9i2oR089LROEvgIw4ERFRNy0XPShpS9uPS9qcasY5w/YdzehLogcjIqLWQNGDrXbLF2CmpL2onote0qzBNCIiYn203IBq+9hm9yEiImJ9tdQz1IiIiHbVcjPU2DCJHGxNWXUd0flafoYqabyk5TV/nyrpdEknS7pL0lJJ3y37XiPpFkmLJN0safdSvrmkfyv1vy/pNkl9PlSOiIgYjnaeoX4K2MX205K2LWX3AFNsPyPpMOBLVFGGJwAP295L0gSqXOCIiIi6aecBdSkwW9IPgB+Usm2ASyTtBhjYpJQfBJwLYHt5eRe1T4kejIiI4Wj5W77AMzy/nz0xg28GvgnsR5XROwb4InCd7QnAWxg8kvAFEj0YERHD0Q4z1N8Df1E+zfY4VRzhz4GdbV8n6SbgXcCWPD+ScHpNG/OAvwauK++4Thyhvo+4LH6JiGiOlh9Qba+V9AXgdqrB8h5gY2CWpG2ogu+/bvsRSV+luuV7GnBVTTPnl/K7yvF30nekYURExLC0XPRgI0jaGNjE9lOSXgn8Etjd9p8GOi7RgxERUavdogcbYXOq272bUM1oTxhsMI2IiFgfo2JAtf0YkPdOIyKiYdphlS8Akm6uY1vdkr5er/YiIiLaZoZq+3X1aEfSGNsLgI58OJrowdaU1dcRna+dZqiPl9+pkq6XNEfSPZJmS1LZt0LSjmW7W9L1Zft0SZdKmgdcWtr4SbOuJSIiOk/bzFB7eTWwN/Ag1TumBwI3DXLMXsBBttdImtrY7kVExGjTNjPUXm63/Rvbz1Ll8o4fwjE/sr1msEqSZkhaIGnBypUrN7SfERExSrTrgPp0zfY6nptp18YU9o4dfGIoDSd6MCIihqNdb/n2ZwWwP/BTqq/MjDpZ/BIR0RztOkPtzxnAuZIWUM1cIyIiRsSoiB4crkQPRkRErYGiBztthhoREdEUGVAjIiLqYFQOqCUYItm+ERFRN522yndUS+xg68rq64jO1/IDqqQtgH8DXkb1YfEvArsDbwHGAjcDH7HtEjV4G3AIsC3wQdtzJY0Fvg3sS/WB8bEjfR0REdHZ2uGW7xHAg7b3tT0BuBo4z/YB5e+xwJE19cfYfg1wCvD5UnY88KTtPUvZ/v2dLElJERExHO0woC4DDpd0lqQptlcDh0i6TdIy4FCqXN8eV5bfhTwXSXgwMAvA9lJgaX8nS1JSREQMR8vf8rV9n6T9gDcBZ0q6BjgR6Lb9gKTTeX7MYE8sYW0kYUREREO1/IAjaSfgIduzJD0CfKjsWiVpS+BoYM4gzdwIHAtcK2kCsE/DOtxEWfgSEdE8LT+gAhOBsyU9C6yleh56FLAc+B9g/hDauAD4tqS7gbupbgdHRETUTaIHB5DowYiIqJXowYiIiAbLgBoREVEHo2pAlbStpBOa3Y+IiOg87bAoqZ62BU4Azm92R+otsYOtLSuwIzpfy81QJW0h6SpJSyQtl3SMpBWSvippmaTbJe1a6o6T9D1J88u/A0v56ZIuKiH4v5J0cmn+K8ArJS2WdHazrjEiIjpPK85Qe6IG3wwgaRvgLGC17YmS3gt8jSpu8FzgHNs3SeoCfgbsWdrZgyrTdyvgXkkXAJ8CJtie1N/JJc0AZgB0dXU14voiIqIDtdwMlb6jBgEuq/mdXLYPA86TtBj4EbB1CXsAuMr207ZXAX8AXjyUkyd6MCIihqPlZqj9RA0C1L4w27O9EfBa20/VtiEJnosghMQQRkREg7XcIDNA1OAxVM9AjwFuKWU/B04Czi7HTrK9eIDmH6O6BdxxsuglIqK5Wm5Ape+owTnAdpKWUs08313qngx8s5SPocrsPa6/hm3/UdI8ScuBn9r+RAOvIyIiRpG2iB6UtILq6zKrRvK8iR6MiIhaiR6MiIhosHYZUE8HNu35Q9K/SNprOA1JmirpdfXqWEREBLTmM9S+TKf6XNuDALY/NGDtgU0FHgdu3uBetZAkJbW2LBqL6HxNmaFKGi/pHkmzJd0taY6kzSV9riQeLZc0U5WjgW5gdkk4GlsSkLpLW2+QdIukOyRd0fMeaklXOqOUL5O0h6TxVIuWPlbamtKM64+IiM7TzFu+uwPn294TeJQqY/c82wfYngCMBY60PQdYAEyzPcn2mp4GJO0InAYcZnu/Uu/jNedYVcovAE61vQK4kCpdaZLtuY2/zIiIGA2aOaA+YHte2Z4FHAQcIuk2ScuAQ4G9B2njtcBewLySlvQ+4OU1+68svwuB8UPplKQZkhZIWrBy5cqhXUlERIx6zXyG2vt9HVN9Babb9gOSTgc2G6QNAb+w/e5+9vekJQ05Kcn2TGAmVK/NDOWYiIiIZs5QuyT1ZPIeC9xUtleV56BH19TtL+HoVuDAmq/PbCHpVYOct2PTkiIionmaOUO9FzhR0kXAXVTPObejWs37P8D8mroXAxdKWsNzwfjYXilpOnCZpBeV4tOA+wY474+BOZLeBpzUKc9Rs4o0IqK5mpKUVFbb/qQsPmpZSUqKiIhaSUqKiIhosKbc8i2vr7T07DQiImJ9ZIYaERFRB+0SPRiDSPRga8uisYjO17YzVEnvkXR7iRD8Z0kbS/qgpPtK+bcknVfqvlLSrSWC8ExJjze7/xER0VnackCVtCdwDHCg7UlUwQ3TgM9SpScdCOxRc8i5wLm2JwK/GeHuRkTEKNCWAyrwemB/YH6JHHw9VYbvDbYfsr0WuKKm/uSav/91oIYTPRgREcPRrgOqgEtKwP0k27tTfTN1g9meabvbdve4cePq0WRERIwC7TqgXgMcLekvACRtDywC/lLSdpLGAO+oqX9rzd/vGtGeRkTEqNCWq3xt3yXpNODnkjYC1gInAl8CbgceAu4BVpdDTgFmSfoMcHVNecfIKtKIiOZqywEVwPblwOW1ZZKW255ZZqjfB35Qdv0WeK1tS3oX1bdYIyIi6qZtB9R+nC7pMKrPvv2c5wbU/YHzJAl4BPhAk/oXEREdqqMGVNun9lM+F9h3hLsTERGjSLsuSoqIiGgpHTVDHW0SN9g+smgsovO13YAq6b3AqYCBpcC/UX1UfFPgj8A027+XdDqwC/AKoAv4GFWK0hupFim9pQRAREREbLC2uuUraW+qwfNQ2/sCHwVuolrB+2rgu8Df1RzySuBQ4K3ALOC6Ej+4BnjzSPY9IiI6W7vNUA8FrrC9CsD2Q5ImApdLegnVLPX+mvo/tb1W0jJgY6p3UAGWAeP7OoGkGcAMgK6uroZcREREdJ62mqH24xvAeWXm+RGqV2Z6PA1g+1lgrW2X8mfp538mEj0YERHD0W4D6rXAOyXtAH+OHNyG6pkowPua1bGIiBjd2uqWr+07Jf0DcIOkdVT5vacDV0h6mGrA3aWJXRxRWTkaEdE69Nxd0Oitu7vbCxYsaHY34v+1d/+hdtd1HMefr8rSmpnkUFBrpaYuC4dX2zTLwsKiMIvoB0mR/TB/TCP7AUFZUImCZc0ao6IgUSpTwzBLcix1/th0OXUKFoabUkqalpku3/1xPnO3u7ut7Z67c77nPh9w2Pd+zud8975ftr33OfdzXl9JGhJJVlbV2GTPde0tX0mShpINVZKkPuhcQ02yMMmaJOuSLGpjJ7fAh8295pgkV+64KiVJM02nNiU1pwDHtscYQFUtHmhFO5Bxg93kBjJp9HVqhZpkMb0owauA3ceNn53krHa8f5Jrkvwhya1J9ptwjsOT3DZxXJKkqehUQ62qk4EHgDcBj2xm2kXAhS2a8Ejg2SVdkiOBxcDxVfXHaS5XkjSDdPEt381Ksiuwd1VdBlBVT7ZxgIOBJcBbq+qBLZzD6EFJ0jbr1Ap1ih4EngTmbWmS0YOSpO0xUivUqno8ydok76qqy5O8gF4oPsCjwEnAb5P8s6qWDqzQKXBziyQNp1FcoZ4ILExyO3ADsNeGJ6rqL8A7gAuTvG5A9UmSRpDRg1tg9KAkaTyjByVJmmY2VEmS+mCoG2qSf0zTeZcmmXTJLknS9hipXb6jyrjB7nN3tjT6hmaFmuTyJCuT3NnCFTaMf63FCN6YZM82NjvJpUluaY+j2vgRSZa3aMEbkhzYxndJckkL1b8M2GUg36QkaWQNTUMFPlpVh9ELvF+Y5KXAi4AbW4zgMuDjbe4FwDer6nDgPcD32/jdwNFVNQ/4EvD1Nv4p4ImqOhj4MnDYjviGJEkzxzC95bswyQnteF/gAOApYMNt11YCb2nHxwJzW6QgwIuTzAJ2A36c5ACggJ3a828Avg1QVbe3z6hOyuhBSdL2GIqGmuQYek1yQVU9kWQpsDPwdG38oOx/2Fjvc4D5G7J6x51nEXBtVZ2QZA6wdFtrqaol9DJ/GRsb80O6kqT/y1A0VHory0daMz0ImL+V+b8BTgfOA0hyaFWtaudZ1+Z8ZNz8ZcAHgd8lOQR4bR9rn3ZuaJGk4TcsP0P9NfC8JGuAc4AbtzJ/ITCW5PYkdwEnt/FzgW8kuY3//c/C94BZ7fxfpff2sSRJfWP04BYYPShJGs/oQUmSppkNVZKkPpgRDTXJMUmu3PpMSZK2z7Ds8lVjzOBocqe2NPqGfoWaZE6Su5Nc1KIDf57khUnuS7JHmzPWPrtKkjcmWdUetyXZtZ1qVnvthnNlc7+nJEnbaugbanMg8N0WHfgYcMoW5p4FnFpVhwJHA/9q4/OAM4G5wCuBoyZ7cZJPJFmRZMVDDz3Ur/olSSOuKw31/qq6vh3/BHj9FuZeD5yfZCHwkqpa38Zvrqq1VfUMsAqYM9mLq2pJVY1V1djs2bP7VL4kadR1paFO/LBsAevZWP/Ozz5RdQ7wMXp3lLm+JS8B/Hvc68fHGEqSNGVdaSovS7KgqpbTixC8DtiV3l1jrqJ3xxkAkuxXVauB1UkOBw4CHh1AzdvFzSuS1E1dWaHeA5zaogN3pxcl+BXggiQr6K04NzgzyR3tjjJP02u4kiRNq66sUNdX1YcmjP0eeNXEiVV1+iSvX8q4O89U1Wn9LE6SpK6sUCVJGmpDv0KtqvuAQwZdhyRJW+IKVZKkPhj6FWrXGSUocPe2NBN0doW6lUjCc5OsTnJzkv3b/HcmuanFEV6TZM9Bfw+SpNHR2YbabC6S8O9V9RpgEfCtNnYdML+q5gGXAJ+b7IRGD0qStkfXG+rmIgkvHvfrgna8D3B1ktXAZ4FXT3ZCowclSduj6w11skjCieMbjr8DLGor108yLq5QkqSp6vqmpMkiCecB7wPOab8ub3N3A9a14w/vqALdjCJJM0PXV6iTRRIC7N6iB88APt3GzgZ+lmQl8PCOLlSSNNq6vkLdJJKw3Tf8vKr6/PjxqroCuGIH1iZJmkG63lCn1cqVKx9O8udB17GD7YEr+Ongde0/r2n/eU237uWbeyJVE/f1aCZLsqKqxgZdx6jxuvaf17T/vKZT0/WfoUqSNBRsqJIk9YENVRMtGXQBI8rr2n9e0/7zmk6BP0OVJKkPXKFKktQHNlRtIsl7k9yZ5Jkk7vibgiTHJbknyb1JvjDoekZBkh8m+WuSOwZdy6hIsm+Sa5Pc1f7unzHomrrIhqrJ3AG8G1g26EK6LMlzgQuBtwFzgQ8kmTvYqkbCj4DjBl3EiFkPfKaq5gLz6SXQ+Wd1G9lQtYmqWlNV9wy6jhFwBHBvVf2pqp6id9vA4wdcU+dV1TLgb4OuY5RU1YNVdWs7fhxYA+w92Kq6x4YqTZ+9gfvHfb0W/5HSkEsyh95NRm4abCXdY/TgDJXkGmCvSZ76Yss9ljTDJJkFXAqcWVWPDbqerrGhzlBVdeyga5gB1gH7jvt6HzbeQlAaKkl2otdML6qqXwy6ni7yLV9p+twCHJDkFUmeD7wf+OWAa5I2kd5tun4ArKmq8wddT1fZULWJJCckWQssAH6V5OpB19RFVbUeOA24mt4mj59W1Z2Drar7klwMLAcOTLI2yUmDrmkEHAWcCLw5yar2ePugi+oak5IkSeoDV6iSJPWBDVWSpD6woUqS1Ac2VEmS+sCGKklSH9hQJUnqAxuqJEl9YEOVJKkP/gv+J1euAgH9CwAAAABJRU5ErkJggg==
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lots of interesting stuff in there!</p>
<ul>
<li>Does it sound reasonable which terms imply aggravated vs simple assault?</li>
<li>Which ones are misspellings? Does that worry you?</li>
<li>Are there any terms in there you don't quite get?</li>
</ul>
<p>There's another notebook - "Inspecting misclassifications" - that goes a bit deeper into these terms and what they may (or may not) mean.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Making-predictions">Making predictions<a class="anchor-link" href="#Making-predictions">#</a></h2><p>No matter what the terms are that point to a report being filed as Part I or Part II, at the end of the day we're interested in seeing <strong>how good is our model as making predictions?</strong> To test it out, we'll need to perform some predictions on content we know the answer to. Let's start by seeing how it does on some sample sentences.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">([</span><span class="s1">&#39;SWUNG A MACHETE AND CUT VIC HAND&#39;</span><span class="p">])</span>
<span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">sample_X</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([1])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this case <code>1</code> means that yes, it was a serious assault. Let's try a few more.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">examples</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span> 
    <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;SWUNG A MACHETE AND CUT VIC HAND&#39;</span><span class="p">,</span>
        <span class="s1">&#39;GRABBED VIC AND SHOOK VERY HARD&#39;</span><span class="p">,</span>
        <span class="s1">&#39;SHOT VIC ONE TIME IN LEFT LEG&#39;</span><span class="p">,</span>
        <span class="s1">&#39;PUNCHED VIC IN FACE&#39;</span><span class="p">,</span>
        <span class="s1">&#39;SLAPPED VIC AND BROKE NOSE&#39;</span><span class="p">,</span>
        <span class="s1">&#39;BURNED VIC WITH HOT IRON&#39;</span>
    <span class="p">]</span>
<span class="p">})</span>

<span class="n">examples_X</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="n">examples</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">examples_X</span><span class="p">)</span>
<span class="n">examples</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>content</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SWUNG A MACHETE AND CUT VIC HAND</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GRABBED VIC AND SHOOK VERY HARD</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SHOT VIC ONE TIME IN LEFT LEG</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PUNCHED VIC IN FACE</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SLAPPED VIC AND BROKE NOSE</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>BURNED VIC WITH HOT IRON</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see that offenses that include weapons tend to be predicted as serious offenses, while ones involving punching or other direct physical contact are classified as simple assault.</p>
<p>Instead of just looking at which category a report was put in, we can also look at <strong>the score the classifier used for the prediction.</strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">examples</span><span class="p">[</span><span class="s1">&#39;prediction_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">examples_X</span><span class="p">)</span>
<span class="n">examples</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>content</th>
      <th>prediction</th>
      <th>prediction_dist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>SWUNG A MACHETE AND CUT VIC HAND</td>
      <td>1</td>
      <td>0.988718</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GRABBED VIC AND SHOOK VERY HARD</td>
      <td>0</td>
      <td>-0.699699</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SHOT VIC ONE TIME IN LEFT LEG</td>
      <td>1</td>
      <td>0.114073</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PUNCHED VIC IN FACE</td>
      <td>0</td>
      <td>-1.211098</td>
    </tr>
    <tr>
      <th>4</th>
      <td>SLAPPED VIC AND BROKE NOSE</td>
      <td>0</td>
      <td>-1.236884</td>
    </tr>
    <tr>
      <th>5</th>
      <td>BURNED VIC WITH HOT IRON</td>
      <td>1</td>
      <td>0.475308</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The further away from zero, more certain the algorithm is in its prediction.</p>
<ul>
<li><strong>SHOT VIC ONE TIME IN LEFT LEG</strong> scores <code>0.221241</code>, so it isn't very sure that it's serious</li>
<li><strong>SLAPPED VIC AND BROKE NOSE</strong> sounds violent, but it scores <code>-1.254914</code> so the algorithm is pretty certain it's not a serious offense.</li>
</ul>
<p>Now we can move on to making comparisons with our actual dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Making-predictions-to-find-downgraded-crimes">Making predictions to find downgraded crimes<a class="anchor-link" href="#Making-predictions-to-find-downgraded-crimes">#</a></h1><p>To see if our algorithm can find downgraded reports, we'll first ask it to make predictions on each of the descriptions we have. If a report is listed as not serious, but the algorithm thinks it should be serious, we should examine the report further.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Feed the classifier the word counts (X) to have it make the prediction</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;prediction&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Let&#39;s also how certain the classifier is</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;prediction_dist&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CCDESC</th>
      <th>DO_NARRATIVE</th>
      <th>serious</th>
      <th>downgraded</th>
      <th>prediction</th>
      <th>prediction_dist</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2</th>
      <td>ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT</td>
      <td>DO-S APPRCHED V AND STATED ARE YOU GOING TO FCK ME V REPLIED NO SUSP PULL ED OUT A KNIFE AND STATED IM HERE TO HURT YOU BTCH S USED PROFANITIES</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0.039799</td>
    </tr>
    <tr>
      <th>4</th>
      <td>BATTERY - SIMPLE ASSAULT</td>
      <td>DO-SUSP USED RIGHT FIST TO PUNCH VICT IN THE HEAD ONCE N PULL VICT HAIR   FOR APPRX 15 SECONDS</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-1.049685</td>
    </tr>
    <tr>
      <th>9</th>
      <td>BATTERY - SIMPLE ASSAULT</td>
      <td>DO-S APPROACHED V IN VEH S SLAPPED AND LUNGGED AT V</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.267440</td>
    </tr>
    <tr>
      <th>11</th>
      <td>BATTERY - SIMPLE ASSAULT</td>
      <td>DO-V STATED THAT SUSP CONFRT HER WHEN SHE TRIED TO APPR HER HUSBAND SUSP  AND V HUSBAND ARE FRNDS SUSP YELLED STAY AWAY FROM HIM AND PUSHED V</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-1.165267</td>
    </tr>
    <tr>
      <th>16</th>
      <td>BATTERY - SIMPLE ASSAULT</td>
      <td>DO-SUSPS WERE VERBALLY ABUSING VICT DURING WHICH TIME S1 STRUCK VICT THREETIMES ON THE BACK OF HIS LEFT SHOULDER</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>-0.924740</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Crimes with a <code>1</code> in <strong>serious</strong> are serious, and ones with a <code>1</code> in <strong>downgraded</strong> were downgraded. If either of those columns is <code>1</code>, then <strong>prediction</strong> would also be <code>1</code> for a correct prediction.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Let's-evaluate-our-classifier">Let's evaluate our classifier<a class="anchor-link" href="#Let's-evaluate-our-classifier">#</a></h1><p>When you build a classifier, you'll talk about your <strong>evaluation metric</strong>, what you use to judge how well your algorithm performed. Typically this is <strong>accuracy</strong> - how often was your prediction correct?</p>
<h2 id="How-often-did-our-prediction-match-whether-a-crime-was-listed-as-serious?">How often did our prediction match whether a crime was listed as serious?<a class="anchor-link" href="#How-often-did-our-prediction-match-whether-a-crime-was-listed-as-serious?">#</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">prediction</span> <span class="o">==</span> <span class="n">df</span><span class="o">.</span><span class="n">serious</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True     0.879258
False    0.120742
dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>88% doesn't seem that bad!</p>
<p>Remember, though, <strong>15% of the serious crimes have been downgraded</strong>. We don't actually care whether the prediction matches <strong>if the crime has been downgraded</strong>. We need to see whether we correctly predicted reports marked as serious <em>or</em> downgraded reports.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-often-did-we-match-the-true-serious/not-serious-value?">How often did we match the true serious/not serious value?<a class="anchor-link" href="#How-often-did-we-match-the-true-serious/not-serious-value?">#</a></h2><p>Since we're interested in uncovering the secretly-serious reports, we want to see whether it's serious <em>or</em> downgraded.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">prediction</span> <span class="o">==</span> <span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">serious</span> <span class="o">|</span> <span class="n">df</span><span class="o">.</span><span class="n">downgraded</span><span class="p">))</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True     0.891905
False    0.108095
dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We actually did better when including the secrets! 89%!</p>
<p>While this seems good, <strong>it isn't what we're actually after.</strong> We're specifically doing research on <strong>finding downgraded reports,</strong> so what we're interested in is <strong>how often we found reports marked as non-serious that were downgraded from serious</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="How-often-did-we-catch-downgrades?">How often did we catch downgrades?<a class="anchor-link" href="#How-often-did-we-catch-downgrades?">#</a></h2><p>To figure this out, we'll first make sure we're only looking at downgraded reports, and then see how many of them we predicted as being serious assault.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Only select downgraded reports</span>
<span class="n">downgraded_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">downgraded</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>

<span class="c1"># How often did we predict they were serious?</span>
<span class="p">(</span><span class="n">downgraded_df</span><span class="o">.</span><span class="n">prediction</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True     0.648172
False    0.351828
Name: prediction, dtype: float64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># And again, without the percentage, in case you&#39;re curious</span>
<span class="p">(</span><span class="n">downgraded_df</span><span class="o">.</span><span class="n">prediction</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True     4591
False    2492
Name: prediction, dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We were able to find around 4,500 of our 7,000 downgraded offenses. <strong>That's about 65% of them.</strong></p>
<p>Let's finish up for now and discuss what we think about our techniques and scoring methods. If you're interested in picking apart the ones we got wrong and investigating the algorithm a little further, I recommend the <strong>Inspecting misclassifications</strong> notebook.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Review">Review<a class="anchor-link" href="#Review">#</a></h2><p>We reproduced an ersatz version of a Los Angeles Times piece where they uncovered <strong>serious assaults that had been downgraded by the LAPD</strong> to simple assault. We don't have access to the original classifications, so we used a dataset of assaults between 2008 and 2012 and downgraded a random 15% of the serious assaults.</p>
<p>Using <strong>text analysis</strong>, we first analyzed the words used in a description of assault - less common words were given more weight, and incredibly common words were left out altogether. Using these results, we then created a <strong>classifier</strong>, teaching the classifier which words were associated with simple assault compared to aggravated assault.</p>
<p>Finally, we used the classifier to <strong>predict whether each assault was aggravated or simple assault</strong>. If a crime was predicted as serious but marked as non-serious, it needed to be examined as a possible downgrade. Our algorithm correctly pointed out around <strong>65%</strong> of the randomly downgraded crimes.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Discussion-topics">Discussion topics<a class="anchor-link" href="#Discussion-topics">#</a></h2><ul>
<li>Our algorithm had 88% accuracy overall, but only 65% in detecting downgraded crimes. What's the difference here? How important is one score compared to the other?</li>
<li>We only hit around 65% accuracy in finding downgraded crimes. Is this a useful score? How does it compare to random guessing, or going one-by-one through the crimes marked as non-serious?</li>
<li>What techniques could we have used to find downgraded crimes if we didn't use machine learning?</li>
<li>Is there a difference between looking at the prediction - the 0 or 1 - and looking at the output of <code>decision_function</code>?</li>
<li>What happens if our algorithm errs on the side of calling non-serious crimes serious crimes? What if it errs on the side of calling serious crimes non-serious crimes?</li>
<li>If we want to find more downgraded cases (but do more work), we'll want to err on the side of examining more potentially-serious cases. Is there a better method than picking random cases?</li>
<li>One of our first steps was to eliminate all crimes that weren't assaults. How do you think this helped or hindered our analysis?</li>
<li>Why did we use LinearSVC instead of another classifier such as LogisticRegression, RandomForest or Naive Bayes (MultinomialNB)? Why might we try or not try those?</li>
<li>You don't work for the LAPD, so you can only be so sure what should and shouldn't be a serious crime. What can you do to help feel confident that a case should be one or the other, or that our algorithm is working as promised?</li>
<li>In this case, we randomly picked serious crimes to downgrade. Would it be easier or more difficult if the LAPD was systematically downgrading certain types of serious crimes? Can you think of a way to around that sort of trickery?</li>
<li>Many people say you need to release your data and analysis in order to have people trust what you've done. With something like this dataset, however, you're dealing with real things that happened to real people, many of whom would probably prefer to keep these things private. Is that a reasonable expectation? If it is, what can be done to bridge the gap between releasing all of the original data and keeping our process secret?</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 


    </div>
  </div>
</div>

<script>
  [...document.querySelectorAll(".code_cell")].filter(cell => cell.innerText.trim().length === 0).forEach(cell => cell.remove())
</script>

  <div class="footer bg-secondary">
  <div class="content">
    <div class="columns">
      <div class="column col-6 col-sm-12">
        <p><strong>Hi, welcome to Data Science for Journalism!</strong></p>
        <p>There's been a lot of buzz about machine learning and "artificial intelligence" being used in stories over
          the past few years. It's mostly not that complicated - a little stats, a classifier here or there - but it's
          hard to know where to start without a little help.</p>
        <p>Hopefully this site can be that help! <a href="/ds4j/about">Learn more about this project here.</a></p>
      </div>
      <div class="column col-3 col-sm-6">
        <p><strong>Quick links</strong></p>
        <!-- <p><a href="#">Something here</a></p>
        <p><a href="#">Something here</a></p>
        <p><a href="#">Something here</a></p> -->
      </div>
      <div class="column col-3 col-sm6">
        <p><strong>Contact</strong></p>
        <p><a href="mailto:hello@littlecolumns.com">hello@littlecolumns.com</a></p>
      </div>
    </div>
  </div>
</div>
  <script src="/ds4j/js/tocbot.js"></script>

  <script>
    try {
      let toc = document.createElement("div")
      toc.setAttribute('class', 'js-toc')
      document.querySelector(".reading-options").parentNode.appendChild(toc)
    } catch (err) {

    }

    tocbot.init({
      // Where to render the table of contents.
      tocSelector: '.js-toc',
      // Where to grab the headings to build the table of contents.
      contentSelector: '.notebook',
      // Which headings to grab inside of the contentSelector element.
      headingSelector: 'h1, h2, h3, h4',
      activeLinkClass: 'active',
      listClass: 'nav',
      listItemClass: 'nav-item',
      headingLabelCallback: function (label) {
        return label.replace("#", "")
      }
    });
  </script>

</body>

</html>