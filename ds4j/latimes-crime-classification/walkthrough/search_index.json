[
["index.html", "1 Introduction", " 1 Introduction "],
["introduction.html", "2 Introduction ", " 2 Introduction "],
["the-original-story.html", "2.1 The original story", " 2.1 The original story Add a link here "],
["more-stuff-here.html", "2.2 More stuff here?", " 2.2 More stuff here? I don’t know "],
["reading-in-and-preparing-our-data.html", "3 Reading in and preparing our data", " 3 Reading in and preparing our data While the LA Times analyzed all crimes between October 2012 and September 2013 (and later 2005-2012), we’re going to simplify things a bit and only look at assaults in 2012. from tabulate import tabulate import pandas as pd pd.set_option(&quot;display.max_columns&quot;, 20) pd.set_option(&quot;display.max_colwidth&quot;, 200) df = pd.read_csv(&quot;data/2012_assaults.csv&quot;) df.shape ## (31452, 2) Overall it will be about 39 thousand cases to analyze, which isn’t too bad! The data itself isn’t too crazy, either: df.head(2) CCDESC DO_NARRATIVE ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS PULL UP NEXT TO VICT IN VEH SUSP1 SUSP2 SUSP3 EXIT VEH RUSH VICTSUSP1 PRODUCED FOLDING KNIFE AND STABBED VICT IN STOMACH SUSPS FLEE IN VEH INTIMATE PARTNER - SIMPLE ASSAULT DO-VICT AND SUSP HAVE 2 CHILDREN IN COMMON BOTH INV IN A VEBAL ARGUMENT SUSP BECOMES IRATE AND HITS VICT Our dataset has a lot of columns in it, including the date and time of the crime, some classification codes, as well as a brief description. It’s these last few categories that we’ll be most interested in, so we’ll remove the columns we don’t need to keep things a little cleaner. df = df[[&#39;CCDESC&#39;,&#39;DO_NARRATIVE&#39;]].copy() df.head() CCDESC DO_NARRATIVE ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS PULL UP NEXT TO VICT IN VEH SUSP1 SUSP2 SUSP3 EXIT VEH RUSH VICTSUSP1 PRODUCED FOLDING KNIFE AND STABBED VICT IN STOMACH SUSPS FLEE IN VEH INTIMATE PARTNER - SIMPLE ASSAULT DO-VICT AND SUSP HAVE 2 CHILDREN IN COMMON BOTH INV IN A VEBAL ARGUMENT SUSP BECOMES IRATE AND HITS VICT INTIMATE PARTNER - SIMPLE ASSAULT DO-SUSP PUSHED THE VICT AND SPANKED VICTIM APPROX THREE TIMES NOT CAUSING VISIBLE INJURY BATTERY - SIMPLE ASSAULT DO-S1 V1 HAVE AND ALTERCATION OVER MONEY S1 BECAME ANGRY WITH V1 FOR NOT GIVING HER MONEY S1 THEN GOT ON TOP OF V1 AND ATTEMP TO WRESTLE THE MONEY AWAY BATTERY - SIMPLE ASSAULT DO-S WAS VERBALLY CONFRONTED BY V WHO WAS ACCROSS THE STREET AFTER S DOG DEFACATED S APPROACHED V AND HIT PR HAND "],
["defining-our-terms.html", "4 Defining our terms", " 4 Defining our terms Assaults come in two major categories: Aggravated assault, a more serious Part I crime Simple assault, a less serious Part II crime While there are subsets of each - children and partners get different classifications, for example - we’ll group all aggravated assaults as Part I and all simple assaults as Part II. df.CCDESC.value_counts() ## BATTERY - SIMPLE ASSAULT 14483 ## INTIMATE PARTNER - SIMPLE ASSAULT 8143 ## ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT 7352 ## CHILD ABUSE (PHYSICAL) - SIMPLE ASSAULT 822 ## INTIMATE PARTNER - AGGRAVATED ASSAULT 247 ## CHILD ABUSE (PHYSICAL) - AGGRAVATED ASSAULT 178 ## ASSAULT WITH DEADLY WEAPON ON POLICE OFFICER 116 ## OTHER ASSAULT 111 ## Name: CCDESC, dtype: int64 After we categorize them as Part I or Part II (aka “not Part I”), we see only about 20% of our cases are the more violent aggravated assault. df[&#39;is_part_i&#39;] = df.CCDESC.str.contains(&quot;AGGRAVATED&quot;).astype(int) df.is_part_i.value_counts() ## 0 23675 ## 1 7777 ## Name: is_part_i, dtype: int64 "],
["manually-downgrading-part-i-offenses.html", "4.1 Manually downgrading Part I offenses", " 4.1 Manually downgrading Part I offenses The investigation by The Los Angeles Times uncovered Part I crimes that were being downgraded, and misclassified as Part II crimes. Since we don’t have the original, incorrect classifications to work off of, we’re going to have to cheat a little! To reproduce a situation similar to the LA Times, let’s take about 20% of our aggravated assaults and reclassify them as simple assaults. # Copy the official classification into a new column # We&#39;ll pretend this is what was reported by the police df[&#39;reported&#39;] = df[&#39;is_part_i&#39;] # Now we&#39;ll downgrade a random 15% of the Part I crimes, # changing their reported &quot;1&quot; (YES a Part I crime) status # to a 0 (NOPE not a Part I crime) downgraded_indices = df[df.is_part_i == 1].sample(frac=0.25).index df.loc[downgraded_indices, &#39;reported&#39;] = 0 Let’s check what our original Part I vs Part II counts were df.is_part_i.value_counts() ## 0 23675 ## 1 7777 ## Name: is_part_i, dtype: int64 How does it look now that we downgraded them? df.reported.value_counts() ## 0 25619 ## 1 5833 ## Name: reported, dtype: int64 What a decrease, we must be the best cops! …and we didn’t even have to do any police work at all. Now it’s time for the fun part. "],
["teaching-computers-to-read.html", "5 Teaching computers to read", " 5 Teaching computers to read Last time we did text analysis, we picked a custom list of words that, if found, might imply sexual assault. We could do the same thing here, trying to find crimes with especially violent words that were classified as Part II “simple” assault. That’s actually exactly how The LA Times did their original research! I n their published piece they say: Reporters searched the summaries for terms such as “stab” and “knife” to flag incidents that might meet the FBI criteria for serious offenses. They then read thousands of the summaries, which are typically two or three sentences long. They also reviewed court and police records for dozens of cases. The problem with this is that we would have to guess useful words - like “stab,” “knife,” “gun,” “shot” - and then read through all of the results that come up. But what about other situations, ones that might be less clear-cut to non-experts, or assaults that involved less nontraditional weapons? For example, machetes make appearances in plenty of aggravated assaults: df[df.DO_NARRATIVE.str.contains(&quot;MACHETE&quot;, na=False)].head(5) CCDESC DO_NARRATIVE is_part_i reported 1469 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSP STRUCK VICTS NOSE W/MACHETE 1 1 1752 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSP HELD MACHETE HANDLE AT SHOULDER HEIGHT AND CHARGED AT VICTIM CLOSING THE DISTANCE 1 1 2339 INTIMATE PARTNER - SIMPLE ASSAULT DO-S ENGAGED V IN A VERBAL ARGUMENT S CHOKED THE V UNTIL SHE LOST CONSCIOUSNESS ONCE V REGAINED CONSCIOUSNESS THE S PUT A MACHETE TO THE V NECK 0 0 2416 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSP CONCEALED VICT AND SWUNG A MACHETE A VICT SUSP CHASED VICT UNTIL VICT FLAGGED DOWN PD SUSP WAS ARRESTED FOR ADW 1 1 2805 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSP AND VICT WERE WERE INVOLVED IN ARGUMENT SUSP TOLD VICT HE WAS GOING TO KILL HIM AND STRUCK HIM W A MACHETE 1 0 One thing we could do is talk to experts, and see what words might be useful to search for. We could also read many many many narratives, and eventually learn some of the more obscure weapons and techniques that might make something more serious Part I offense. Once we had our more complete list, we could then search the documents those words and review the cases. Both of those sound like a lot of work - this is what machine learning was invented for! Instead of reading thousands of narratives and learning what words are important, we could just have the computer read the narratives for us. The computer can go case-by-case, reading documents, finding the words for each of them, and then figure out which words are more likely to imply a Part I vs. Part II crime. When we start, the computer won’t know the difference between “stab” and “punch.” After some training, though, it will actually notice that “stab” appears more often with aggravated assaults, while “punch” is typically for simple assaults. Once we’ve told it to read enough cases, we can give the computer a description of a crime it’ll be able to guess which type the crime should be classified as! 5.0.1 Data cleaning Some of our offenses are missing a description, though. Since we can’t judge the crime classification if there isn’t a description of what happened, we’ll toss those out. df = df.dropna(subset=[&#39;DO_NARRATIVE&#39;]) "],
["tokenizing.html", "5.1 Tokenizing", " 5.1 Tokenizing The first thing we’ll need to do is split each narrative into words so we can keep track of which words appear in which situations. Instead of \"SUSP SWUNG UMBRELLA WITH METAL TIP AT V2\" we’ll make a list of the words it contains: SUSP SWUNG UMBRELLA WITH METAL TIP AT V2 This process is called tokenization. "],
["vectorizing.html", "5.2 Vectorizing", " 5.2 Vectorizing At the same time we tokenize, we’re probably also counting how many times each word appears. The process of turning text into numbers is called vectorization, and it’s an important and necessary step in helping computers understand text. Every single time you deal with text you’ll need to vectorize it, otherwise the computer won’t know what’s going on! Before we vectorize, let’s take a look at the first few cases to see what kinds of words might be working with. Lots of arguments and pushing, along with a couple appearances of handguns and knives. df[[&#39;DO_NARRATIVE&#39;]].head() DO_NARRATIVE 0 DO-SUSPS PULL UP NEXT TO VICT IN VEH SUSP1 SUSP2 SUSP3 EXIT VEH RUSH VICTSUSP1 PRODUCED FOLDING KNIFE AND STABBED VICT IN STOMACH SUSPS FLEE IN VEH 1 DO-VICT AND SUSP HAVE 2 CHILDREN IN COMMON BOTH INV IN A VEBAL ARGUMENT SUSP BECOMES IRATE AND HITS VICT 2 DO-SUSP PUSHED THE VICT AND SPANKED VICTIM APPROX THREE TIMES NOT CAUSING VISIBLE INJURY 3 DO-S1 V1 HAVE AND ALTERCATION OVER MONEY S1 BECAME ANGRY WITH V1 FOR NOT GIVING HER MONEY S1 THEN GOT ON TOP OF V1 AND ATTEMP TO WRESTLE THE MONEY AWAY 4 DO-S WAS VERBALLY CONFRONTED BY V WHO WAS ACCROSS THE STREET AFTER S DOG DEFACATED S APPROACHED V AND HIT PR HAND When we vectorize these descriptions, we get a new dataset. It’s formatted in a pretty technical way, but if you massage the results a little, you can get a nice dataframe to show you which words appear in which sentences. Every column is a single word that the computer found somewhere in the descriptions: from sklearn.feature_extraction.text import CountVectorizer vec = CountVectorizer(binary=True) X = vec.fit_transform(df.DO_NARRATIVE) word_appearances = pd.DataFrame(X.toarray(), columns=vec.get_feature_names()) word_appearances[[&#39;knife&#39;, &#39;argument&#39;, &#39;handgun&#39;, &#39;wrestle&#39;, &#39;pushed&#39;, &#39;injuries&#39;, &#39;fired&#39;, &#39;irate&#39;, &#39;umbrella&#39;]].head(10) knife argument handgun wrestle pushed injuries fired irate umbrella 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 means the word wasn’t found in that sentence, while 1 means it was. Compare each row with the sentences up above to see that yes, it worked! I only picked a few words here because as a lot of the words are pretty much garbage, and might be misspellings or only appear in one or two narratives. Even though I cleaned up the results a little bit, looking at them with our nice human brains is an exercise in getting a headache: word_appearances.columns[30:60] ## Index([&#39;09083&#39;, &#39;09084&#39;, &#39;092312&#39;, &#39;10&#39;, &#39;100&#39;, &#39;1000&#39;, &#39;100ft&#39;, &#39;100yrs&#39;, ## &#39;101&#39;, &#39;101st&#39;, &#39;102212&#39;, &#39;102nd&#39;, &#39;103rd&#39;, &#39;105&#39;, &#39;105th&#39;, &#39;106th&#39;, ## &#39;107th&#39;, &#39;10860&#39;, &#39;10861&#39;, &#39;108th&#39;, &#39;109th&#39;, &#39;10feet&#39;, &#39;10ft&#39;, &#39;10inch&#39;, ## &#39;10mos&#39;, &#39;10mths&#39;, &#39;10th&#39;, &#39;10times&#39;, &#39;10x&#39;, &#39;10xs&#39;], ## dtype=&#39;object&#39;) Luckily computers don’t mind sorting the useful words from the useless words, so we don’t need to feel too guilty about the next steps. "],
["classification.html", "6 Classification ", " 6 Classification "],
["what-is-a-classifier.html", "6.1 What is a classifier?", " 6.1 What is a classifier? Now that we have the narratives vectorized - turned into numbers, something a computer can understand - we can teach our machine which words to associate with which kinds of crimes. Just like a human being, the computer will go through each sentence, seeing which words are usually found in a Part I crime and which are found in a Part II crime. Instead of just remembering them, though, it will use the data we creatd - every row is a sentence, every row is a word, and 0, 1, 2, etc are how many times the word appeared. We’ll start by using a Random Forest, which is just one among many different machine learning techniques. from sklearn.ensemble import RandomForestClassifier clf = RandomForestClassifier(n_estimators=100) "],
["training-our-classifier.html", "6.2 Training our classifier", " 6.2 Training our classifier Technically speaking, is called a model, because it mathematically models the way our words reflect our categories. The first thing we need to do with our model is feed it our data so it can learn. It needs two things: The word frequencies (we saved them as X before) The categories (whether it’s Part I or Part II - 1 or 0) It’s probably a waste of time to teach it using every single offense, so we’ll just use the first 10,000. That should give it a pretty good idea of what is a Part I crime and what is a Part II crime. It’d probably be better to train it with more, but I’m more than a little impatient. training = df # We call these X and y because everyone else on earth does # .fit_transform learns the words AND counts them X = vec.fit_transform(training.DO_NARRATIVE) y = training.reported clf.fit(X, y) ## RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;, ## max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, ## min_impurity_decrease=0.0, min_impurity_split=None, ## min_samples_leaf=1, min_samples_split=2, ## min_weight_fraction_leaf=0.0, n_estimators=100, ## n_jobs=None, oob_score=False, random_state=None, ## verbose=0, warm_start=False) Notice that we’re teaching our model with the “fake” categories, the one where we have downgraded 15% of the Part I offenses. That’s because in the real world we wouldn’t know which ones are accurately reported and which ones aren’t. We can only hope that enough are correctly reported for our model to learn well! "],
["making-predictions-with-our-model.html", "6.3 Making predictions with our model", " 6.3 Making predictions with our model Now that our model has read through almost 40,000 narratives, it should have a decent idea of what aggravated assault vs. simple assault is. We can test how good it is with a couple fake sentences: # we already learned the words above, so we just use .transform to count them sample_X = vec.transform([ &quot;S SHOT AND STABBED V WITH A GUN AND THE GUN HAD A KNIFE ON IT&quot;, &quot;S PUNCHED THEIR NEIGHBOR&quot; ]) clf.predict(sample_X) ## array([1, 0]) For the first one our model saw words associated with Part I crimes, so it predicted 1 - an aggravated assault - and for the second one it saw less serious words, so it predicted 0 - a sample assault. Seems reasonable to me! "],
["finding-misclassified-offenses.html", "7 Finding misclassified offenses", " 7 Finding misclassified offenses But how will we use this to find potentially misclassified cases? First, we’ll show our model all of our case narratives, and it will predict whether each one should be Part I or Part II. More violent ones should be predicted as 1, and less violent ones will be predicted as 0. X = vec.transform(df.DO_NARRATIVE) df[&#39;prediction&#39;] = clf.predict(X) df.prediction.value_counts() ## 0 25585 ## 1 5867 ## Name: prediction, dtype: int64 Now that we have a prediction for each offense, we’ll then compare those predictions to the actual classification. If a report is classified as simple assault but the classifier thinks it should be aggravated assault, it’s probably worth investigating! df[(df.reported == 0) &amp; (df.prediction == 1)].head() CCDESC DO_NARRATIVE is_part_i reported prediction 252 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S YELLED AT VS TO LEAVE AND IMMEADIATLY BEGAN HITTING THEM WITH METAL ROD 1 0 1 277 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-DURING A DISPUTE ON THE CAMPUS OF USC SUSP PRODUCED FIREARM AND FIRED SEVERAL GUNSHOTS STRIKING FOUR VICTS 1 0 1 290 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S USED A SCOOTER AND SMASHED VEH WINDOW NEST TO SEATED VICTS 1 AND 2 SUSP IS HARBOR CITY CRIP 1 0 1 408 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUS PULLED UP IN VEH NEXT TO VIC POINTED GUN AT VIC THEN FLED TO UNK LOCATION 1 0 1 504 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSP 1 AND 2 BLOCKED VICTS VEH PATH SUSP 1 FIRED 1-4 TIMES AT VICTS SUSP FLED IN VEH 1 0 1 How many of our misclassified crimes did we catch? Let’s see what was predicted for the ones that started off as Part I, that we then downgraded to Part II. df[(df.is_part_i == 1) &amp; (df.reported == 0)].prediction.value_counts() ## 0 1831 ## 1 113 ## Name: prediction, dtype: int64 …well, that was pretty terrible. From the Part I crimes that we downgraded to Part II, only about 8% were correctly identified as Part I. "],
["trying-other-classifiers.html", "7.1 Trying other classifiers", " 7.1 Trying other classifiers But now we get to do one of the most exciting and absurd parts of machine learning: replace our classifier! One of the magic parts of machine learning is that there are dozens of techniques - different types of regression, decision trees, random forests, etc - and they all operate the same way when you’re programming with them. You give them your data, they learn, you ask for a prediction - you usually only have to change one line to change the type of classifier you’re using! Most of the time different techniques perform roughly the same. It’s kind of like driving an SUV vs a sedan vs a sports car - if you’re driving around the suburbs in normal weather, there isn’t a big difference between all of them. Every once in a while one does a better job because of pecularities in your data, but you don’t always know ahead of time which one that will be. 7.1.1 Trying: LogisticRegression Since our random forest did a terrible job, let’s try a one called a logistic regression classifier. Don’t get scared because the name sounds fancy and mathematical! At this point we don’t care about how these things work or even what they are: we’re just swapping code in and out to see how it performs. We’re using this one because the LA Times used one for their piece, although they referred to it as a “maximum entropy classifier,” which is definitely a cooler name. As we change the classifier, compare our new code to the code above. Notice how we only change the clf = line where we create the classifier: from sklearn.linear_model import LogisticRegression # Create a new classifier clf = LogisticRegression(C=1e9) # Teach the classifier how the words (X) relate to the categories (y) clf.fit(X, y) # Make our predictions and see how it looks ## LogisticRegression(C=1000000000.0, class_weight=None, dual=False, ## fit_intercept=True, intercept_scaling=1, l1_ratio=None, ## max_iter=100, multi_class=&#39;warn&#39;, n_jobs=None, penalty=&#39;l2&#39;, ## random_state=None, solver=&#39;warn&#39;, tol=0.0001, verbose=0, ## warm_start=False) ## ## /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning. ## FutureWarning) ## /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations. ## &quot;the number of iterations.&quot;, ConvergenceWarning) df[&#39;prediction&#39;] = clf.predict(X) df[(df.is_part_i == 1) &amp; (df.reported == 0)].prediction.value_counts() ## 0 1508 ## 1 436 ## Name: prediction, dtype: int64 Wow, that’s a huge improvement! Instead of 8% correctly marked as Part I, we’re up to about 45%! 7.1.2 Trying: LinearSVC And how about a linear support vector machine? Again, you don’t need to know what it is, and again, we’ll only change the clf = line where we create the classifier: from sklearn.svm import LinearSVC # Create a new classifier clf = LinearSVC() # Teach the classifier how the words (X) relate to the categories (y) clf.fit(X, y) # Make our predictions and see how it looks ## LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True, ## intercept_scaling=1, loss=&#39;squared_hinge&#39;, max_iter=1000, ## multi_class=&#39;ovr&#39;, penalty=&#39;l2&#39;, random_state=None, tol=0.0001, ## verbose=0) df[&#39;prediction&#39;] = clf.predict(X) df[(df.is_part_i == 1) &amp; (df.reported == 0)].prediction.value_counts() ## 0 1410 ## 1 534 ## Name: prediction, dtype: int64 The huge improvement we saw with the logistic regression is also here with LinearSVC, the support vector machine. "],
["sparse-vs-dense-data.html", "7.2 Sparse vs dense data", " 7.2 Sparse vs dense data Why the big difference? Some of it has to do with the difference between sparse vs. dense data. LinearSVC works really well with something called “sparse data,” which is a dataset that has a lot of zeros in it. Let’s start by explaining the opposite of it, “dense data” - most of the time when we’re dealing with data, every single column and every single row has something in it. For example, if we’re doing something about cars, every car might have a manufacturer, a model, a year it was made, a weight and an estimate of miles per gallon. manufacturer model year weight miles Ford F150 1980 2500 36 Ford F150 1980 2500 36 Ford F150 1980 2500 36 Ford F150 1980 2500 36 This dataset is is “dense” because almost everything is filled in, and there isn’t missing data or zeroes. Sparse data, on the other hand, only has some of the columns filled in. For example, if we’re counting the words we find in a sentence, most sentences only have a few words in them. Example sentence Suspect Victim baseball bat shot car fled blah blah 1 1 0 0 1 1 0 blah blah 1 1 0 0 1 1 0 blah blah 1 1 0 0 1 1 0 blah blah 1 1 0 0 1 1 0 We might be looking at a few hundred or thousand different words, but sentences aren’t that long, and most words will be marked as ‘0’ in the row. This is sparse data. Support vector machines work well with sparse data, while random forests can be hit or miss. The reasons why one or another kind of classifier might work better has to do with the technical details of how the classifier works, which I’m actually not terribly worried about! While that sounds like a terrible thing to say, it’s honestly more valuable to spend time thinking about what happens when our predictions are right or wrong - what it means if we misclassify, what it means if the LAPD misclassifies. That way instead of just arbitrarily shooting for a certain kind of number or accuracy with our machine learning, we can understand the tradeoffs about the fact that sometimes we will be wrong. If you do remember the kinds of data different classifiers work better with, great work! You’ll be able to save a little bit of time. If not, no big deal, you’ll do the same thing many data science professionals do - semi-randomly trying things and tweaking options until you get a result you’re satisfied with. No harm in that! "],
["improving-our-classifier.html", "8 Improving our classifier ", " 8 Improving our classifier "],
["predictions-vs-probabilities.html", "8.1 Predictions vs probabilities", " 8.1 Predictions vs probabilities So far we’ve been looking at predictions, with a straight 0 or 1. Many classifiers can give you a probability measurement instead of a straight prediction, which can be useful if you’d like to take the top 500 “most-likely” items to review instead of just the ones predicted as category 1. In the case below, we’re using the LogisticRegression classifier to assign not only a prediction column, but also a predict_proba column. This column is the chance that the given row is in category 1. # Create a new classifier - LogisticRegression can use probabilities clf = LogisticRegression(C=1e9) # Teach the classifier how the words (X) relate to the categories (y) clf.fit(X, y) # Make our predictions and see how it looks ## LogisticRegression(C=1000000000.0, class_weight=None, dual=False, ## fit_intercept=True, intercept_scaling=1, l1_ratio=None, ## max_iter=100, multi_class=&#39;warn&#39;, n_jobs=None, penalty=&#39;l2&#39;, ## random_state=None, solver=&#39;warn&#39;, tol=0.0001, verbose=0, ## warm_start=False) df[&#39;prediction&#39;] = clf.predict(X) df[&#39;predict_proba&#39;] = clf.predict_proba(X)[:,1] We can take a look at the top 20 reports most likely to be serious assaults. df.sort_values(by=&#39;predict_proba&#39;, ascending=False).head(20) CCDESC DO_NARRATIVE is_part_i reported prediction predict_proba 8967 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO- SUSPS DROVE PASS VICT AS HE WAS PUMPING GAS INTO HIS VEH AND THE REAR PASSGR S1 FIRED ON SHOT IN VICT DIR STRIKING V VEH SUSP FLED SB. INHERENT GANG 1 1 1 1 17088 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V DRIVING WB 105 FWY WAS SHOT AT BY S1 WIT UNK CAL HANDGUN V VEH WAS STRUCK FOUR TIMES THERE WAS NO INJ TO V S FLED WB 105 FWY 1 1 1 1 20140 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS DROVE INTO RIVAL GANG NEIGHBORHOOD CONFRONT V STATING WHERE YOU FROM S1 STATED WE RE RASCALS AND SHOT V MULTIPLE TIMES SUSPS FLED IN VEH 1 1 1 1 19361 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S CONFRONTED VS AS THEY EXITED DONUT SHOP ACCUSED THEM OF VANDALIZING JIS TRUCK S PEPPERSPRAYED V1S FACE AND POINTED KNIFE AT BOTH VS RLTD 121507711 1 1 1 1 11266 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S POINTED UNK TYPE OF HANDGUN AT V AND FIRED FIVE ROUNDS RESULTING IN THE V TO SUSTAINED A SINGLE GUNSHOT WOOD TO THE RIGHT FOOT S FLED EB ON 54TH 1 1 1 1 13355 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S1 POINTED HANDGUN AT VICT MADE GESTURE AS IF SHOOTING GUN AND STATED POW S1 THREW GLASS BOTTLE AT VICT VEH S2 DROVE THE VEH 1 1 1 1 12409 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-VICT DRINKING AT PATS BAR W FRIENDS. SUSP ASKED WHERE YOU FROM. VICT DENIED GANG. SUSP HIT VICT W POOLSTICK, STATED IM FROM EIGHTEEN STREET GANG. 1 1 1 1 11528 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS DROVE BY LOC AND FIRED APPROX 8-9 ROUNDS AT VICT WHO WAS SEATED AT UPSTAIRS BALCONY SUSPS FLED LOC IN A NEWER 4DR GOLD SEDAN EB 37TH 1 1 1 1 17880 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS DROVE BY LOC AND FIRED APPROX 8-9 ROUNDS AT VICT WHO WAS SEATED AT UPSTAIRS BALCONY SUSPS FLED LOC IN A NEWER 4DR GOLD SEDAN EB 37TH 1 1 1 1 18719 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S USED VEH AS WEAPON AND INTENTIONALLY RAMMED V VEH W OCCUPANTS INSIDE V VEH 1 1 1 1 17940 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S1 DEMANDS HE WANDTED ICE CREAM JUST REFUSES TELL HIM TO GET A CART ANDWORK S1 ARMS HIMSELF WITH STICK CHASES V1 V1 RUNS IN FEAR OF HIS LIFE 1 1 1 1 13480 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V TRAVELLED NB 170 FWY SVEH PULLED NEXT TO HIM AND FIRED 3-4 TIMES SVEH-NEWER MODEL SIL CADI OR CHRY 300 FRONT PASS WINDOW TINTED V NOT INJURED 1 1 1 1 1239 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V WAS STOPPED FACING EB 79TH ST AND CENTRAL S EXITED HIS VEH AND APPROCHED V A PHYSICAL ALTERCATION ENSUED S PRODUCED A HANDGUN AND SHOT V 1 1 1 1 7559 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-VICT EXIT LIQUOR STR AND OBSVD VEH STOP VICT THEN HEARD GUNFIRE AND RANBACK INSIDE LIQUOR STR VICT THEN REALIZED HE WAS SHOOT ON LEG DRIVEBY 1 1 1 1 25627 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SS IN VEH S1 POINTED HANDGUN OUT OF WINDOW AT V PUSHING STROLLER W CHILD S1 ATTEMPT TO FIRE GUN NO SHOTS FIRED SVEH FLED SB LANKERSHIM 1 1 1 1 233 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V OBSD S2 IN ATT BFMV V APPRO S1 APPEARED FROM BEHIND PILLAR STRUCK V W BRASS KNUCKLES ATTACHED TO 5-6\" KNIFE SS FLED IN WAITING VEH EB DRIVEN BY S3 1 1 1 1 4145 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-UNK SUSP FIRED APPROX 3 GNSHOTS AT VICT STRIKING VICT IN THE BANK UNK SUSP FLED WESTBOUND IN GRN FORD F150 OUT OF SIGHT WITH THE WEAPON 1 1 1 1 7312 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSP APPROCHED V ON FOOT AND S1 SHOT MYLTI ROUND STRIKING BOTH VICTS SUSPS FLED ON FOOT SB S2 WAS STRUCK BY UNK GUNFIRE VIC BROWN DIED 1 1 1 1 9162 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-MALES EXIT UNK VEH S APPRO V STATED F-CK RATTAS THREW AND STRUCK V W UNK OBJ S N V FOUGHT V OBSD BLOOD S HAD STABBED V V IS DOCUMENTED RADFORD ST GM 1 1 1 1 4381 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S DROVE UP FIRED SHOTS V WAS STRUCK BY GUNFIRE AND TRANSPORTED TO HOSPITAL FROM DR 121213073 DIED FROM THE INJURIES HES SUSTAINED 1 1 1 1 As well as the top 20 assaults least likely to be serious assault. df.sort_values(by=&#39;predict_proba&#39;, ascending=False).head(20) CCDESC DO_NARRATIVE is_part_i reported prediction predict_proba 8967 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO- SUSPS DROVE PASS VICT AS HE WAS PUMPING GAS INTO HIS VEH AND THE REAR PASSGR S1 FIRED ON SHOT IN VICT DIR STRIKING V VEH SUSP FLED SB. INHERENT GANG 1 1 1 1 17088 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V DRIVING WB 105 FWY WAS SHOT AT BY S1 WIT UNK CAL HANDGUN V VEH WAS STRUCK FOUR TIMES THERE WAS NO INJ TO V S FLED WB 105 FWY 1 1 1 1 20140 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS DROVE INTO RIVAL GANG NEIGHBORHOOD CONFRONT V STATING WHERE YOU FROM S1 STATED WE RE RASCALS AND SHOT V MULTIPLE TIMES SUSPS FLED IN VEH 1 1 1 1 19361 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S CONFRONTED VS AS THEY EXITED DONUT SHOP ACCUSED THEM OF VANDALIZING JIS TRUCK S PEPPERSPRAYED V1S FACE AND POINTED KNIFE AT BOTH VS RLTD 121507711 1 1 1 1 11266 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S POINTED UNK TYPE OF HANDGUN AT V AND FIRED FIVE ROUNDS RESULTING IN THE V TO SUSTAINED A SINGLE GUNSHOT WOOD TO THE RIGHT FOOT S FLED EB ON 54TH 1 1 1 1 13355 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S1 POINTED HANDGUN AT VICT MADE GESTURE AS IF SHOOTING GUN AND STATED POW S1 THREW GLASS BOTTLE AT VICT VEH S2 DROVE THE VEH 1 1 1 1 12409 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-VICT DRINKING AT PATS BAR W FRIENDS. SUSP ASKED WHERE YOU FROM. VICT DENIED GANG. SUSP HIT VICT W POOLSTICK, STATED IM FROM EIGHTEEN STREET GANG. 1 1 1 1 11528 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS DROVE BY LOC AND FIRED APPROX 8-9 ROUNDS AT VICT WHO WAS SEATED AT UPSTAIRS BALCONY SUSPS FLED LOC IN A NEWER 4DR GOLD SEDAN EB 37TH 1 1 1 1 17880 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSPS DROVE BY LOC AND FIRED APPROX 8-9 ROUNDS AT VICT WHO WAS SEATED AT UPSTAIRS BALCONY SUSPS FLED LOC IN A NEWER 4DR GOLD SEDAN EB 37TH 1 1 1 1 18719 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S USED VEH AS WEAPON AND INTENTIONALLY RAMMED V VEH W OCCUPANTS INSIDE V VEH 1 1 1 1 17940 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S1 DEMANDS HE WANDTED ICE CREAM JUST REFUSES TELL HIM TO GET A CART ANDWORK S1 ARMS HIMSELF WITH STICK CHASES V1 V1 RUNS IN FEAR OF HIS LIFE 1 1 1 1 13480 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V TRAVELLED NB 170 FWY SVEH PULLED NEXT TO HIM AND FIRED 3-4 TIMES SVEH-NEWER MODEL SIL CADI OR CHRY 300 FRONT PASS WINDOW TINTED V NOT INJURED 1 1 1 1 1239 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V WAS STOPPED FACING EB 79TH ST AND CENTRAL S EXITED HIS VEH AND APPROCHED V A PHYSICAL ALTERCATION ENSUED S PRODUCED A HANDGUN AND SHOT V 1 1 1 1 7559 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-VICT EXIT LIQUOR STR AND OBSVD VEH STOP VICT THEN HEARD GUNFIRE AND RANBACK INSIDE LIQUOR STR VICT THEN REALIZED HE WAS SHOOT ON LEG DRIVEBY 1 1 1 1 25627 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SS IN VEH S1 POINTED HANDGUN OUT OF WINDOW AT V PUSHING STROLLER W CHILD S1 ATTEMPT TO FIRE GUN NO SHOTS FIRED SVEH FLED SB LANKERSHIM 1 1 1 1 233 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-V OBSD S2 IN ATT BFMV V APPRO S1 APPEARED FROM BEHIND PILLAR STRUCK V W BRASS KNUCKLES ATTACHED TO 5-6\" KNIFE SS FLED IN WAITING VEH EB DRIVEN BY S3 1 1 1 1 4145 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-UNK SUSP FIRED APPROX 3 GNSHOTS AT VICT STRIKING VICT IN THE BANK UNK SUSP FLED WESTBOUND IN GRN FORD F150 OUT OF SIGHT WITH THE WEAPON 1 1 1 1 7312 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-SUSP APPROCHED V ON FOOT AND S1 SHOT MYLTI ROUND STRIKING BOTH VICTS SUSPS FLED ON FOOT SB S2 WAS STRUCK BY UNK GUNFIRE VIC BROWN DIED 1 1 1 1 9162 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-MALES EXIT UNK VEH S APPRO V STATED F-CK RATTAS THREW AND STRUCK V W UNK OBJ S N V FOUGHT V OBSD BLOOD S HAD STABBED V V IS DOCUMENTED RADFORD ST GM 1 1 1 1 4381 ASSAULT WITH DEADLY WEAPON, AGGRAVATED ASSAULT DO-S DROVE UP FIRED SHOTS V WAS STRUCK BY GUNFIRE AND TRANSPORTED TO HOSPITAL FROM DR 121213073 DIED FROM THE INJURIES HES SUSTAINED 1 1 1 1 Using this technique we can easily expand out net to handle as many cases as we feel we can process, without the arbitrary boundary of an algorithm scoring a 0 or 1. "],
["improving-our-vectorizer.html", "8.2 Improving our vectorizer", " 8.2 Improving our vectorizer If we want to make our classifier work a bit better, one technique we can use is stemming. Stemming is the process of chopping ends off of similar words so they show up as being the “same.” For example: fish, fishes, fishing and fished. Stemming is the process of removing the endings to turn them all into a simple fish. That way every single sentence that is about fish or fishing at can have that word in common! To stem with your TfidfVectorizer, you need to jump through a few hoops. It might end up looking like this: from sklearn.feature_extraction.text import TfidfVectorizer from nltk.stem import SnowballStemmer stemmer = SnowballStemmer(&#39;english&#39;) class StemmedTfidfVectorizer(TfidfVectorizer): def build_analyzer(self): analyzer = super(StemmedTfidfVectorizer,self).build_analyzer() return lambda doc:(stemmer.stem(word) for word in analyzer(doc)) vec = StemmedTfidfVectorizer(stop_words=&#39;english&#39;, min_df=5, max_df=0.5) X = vec.fit_transform(df.DO_NARRATIVE) print(vec.get_feature_names()[100:200]) ## [&#39;accus&#39;, &#39;acquaint&#39;, &#39;act&#39;, &#39;action&#39;, &#39;activ&#39;, &#39;adam&#39;, &#39;addit&#39;, &#39;address&#39;, &#39;adjac&#39;, &#39;administr&#39;, &#39;admit&#39;, &#39;adn&#39;, &#39;adult&#39;, &#39;adv&#39;, &#39;advanc&#39;, &#39;advd&#39;, &#39;advis&#39;, &#39;adw&#39;, &#39;affair&#39;, &#39;affili&#39;, &#39;afraid&#39;, &#39;aft&#39;, &#39;again&#39;, &#39;aggit&#39;, &#39;aggress&#39;, &#39;aggressor&#39;, &#39;agit&#39;, &#39;ago&#39;, &#39;agre&#39;, &#39;agress&#39;, &#39;agrument&#39;, &#39;aid&#39;, &#39;aim&#39;, &#39;aint&#39;, &#39;air&#39;, &#39;airsoft&#39;, &#39;aknif&#39;, &#39;alcohol&#39;, &#39;alleg&#39;, &#39;alley&#39;, &#39;allow&#39;, &#39;alongsid&#39;, &#39;alt&#39;, &#39;alter&#39;, &#39;alterc&#39;, &#39;altercatin&#39;, &#39;altercaton&#39;, &#39;alterct&#39;, &#39;aluminum&#39;, &#39;alvarado&#39;, &#39;ambul&#39;, &#39;amd&#39;, &#39;amt&#39;, &#39;an&#39;, &#39;anargu&#39;, &#39;and&#39;, &#39;and2&#39;, &#39;andbegan&#39;, &#39;andbit&#39;, &#39;andchok&#39;, &#39;andgrab&#39;, &#39;andhit&#39;, &#39;andkick&#39;, &#39;andpul&#39;, &#39;andpunch&#39;, &#39;andpush&#39;, &#39;andrew&#39;, &#39;andscratch&#39;, &#39;andstruck&#39;, &#39;andsusp&#39;, &#39;andthen&#39;, &#39;andthrew&#39;, &#39;andv&#39;, &#39;andvict&#39;, &#39;anger&#39;, &#39;angri&#39;, &#39;angrier&#39;, &#39;angryand&#39;, &#39;ankl&#39;, &#39;annoy&#39;, &#39;answer&#39;, &#39;anv&#39;, &#39;anymor&#39;, &#39;apart&#39;, &#39;app&#39;, &#39;appar&#39;, &#39;appear&#39;, &#39;appli&#39;, &#39;appox&#39;, &#39;appr&#39;, &#39;apprach&#39;, &#39;appraoch&#39;, &#39;apprch&#39;, &#39;apprchd&#39;, &#39;apprd&#39;, &#39;appro&#39;, &#39;approach&#39;, &#39;approachd&#39;, &#39;approahc&#39;, &#39;approch&#39;] Stemming can be kind of slow, however! The stemmer built in to NLTK is actually notoriously bad, so you might want to upgrade to PyStemmer. Using PyStemmer in a similar way looks like this: from sklearn.feature_extraction.text import TfidfVectorizer import Stemmer stemmer = Stemmer.Stemmer(&#39;en&#39;) analyzer = TfidfVectorizer().build_analyzer() class StemmedTfidfVectorizer(TfidfVectorizer): def build_analyzer(self): analyzer = super(TfidfVectorizer, self).build_analyzer() return lambda doc: stemmer.stemWords(analyzer(doc)) vec = StemmedTfidfVectorizer(stop_words=&#39;english&#39;, min_df=5, max_df=0.5) X = vec.fit_transform(df.DO_NARRATIVE) It’s an extra install, however, so I thought I’d give you the option to just move ahead with NLTK if you wanted. "],
["shortcomings.html", "9 Shortcomings", " 9 Shortcomings This isn’t actually the best way to reproduce this one! If the LAPD was systematically downgrading certain types of attacks - maybe all knife attacks, or chains, or something - our machine learning would be much much less useful. "],
["ethics.html", "10 Ethics", " 10 Ethics Something something "],
["something-else.html", "11 Something else", " 11 Something else Blah blah blah "]
]
