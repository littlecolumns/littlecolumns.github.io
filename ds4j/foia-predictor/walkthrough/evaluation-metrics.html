<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.4 Evaluation metrics | _main.utf8.md</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="4.4 Evaluation metrics | _main.utf8.md" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.4 Evaluation metrics | _main.utf8.md" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="training-our-algorithm.html"/>
<link rel="next" href="other-classifiers.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  { color: #cccccc; background-color: #303030; }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ffcfaf; } /* Alert */
code span.an { color: #7f9f7f; font-weight: bold; } /* Annotation */
code span.at { } /* Attribute */
code span.bn { color: #dca3a3; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #f0dfaf; } /* ControlFlow */
code span.ch { color: #dca3a3; } /* Char */
code span.cn { color: #dca3a3; font-weight: bold; } /* Constant */
code span.co { color: #7f9f7f; } /* Comment */
code span.cv { color: #7f9f7f; font-weight: bold; } /* CommentVar */
code span.do { color: #7f9f7f; } /* Documentation */
code span.dt { color: #dfdfbf; } /* DataType */
code span.dv { color: #dcdccc; } /* DecVal */
code span.er { color: #c3bf9f; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #c0bed1; } /* Float */
code span.fu { color: #efef8f; } /* Function */
code span.im { } /* Import */
code span.in { color: #7f9f7f; font-weight: bold; } /* Information */
code span.kw { color: #f0dfaf; } /* Keyword */
code span.op { color: #f0efd0; } /* Operator */
code span.ot { color: #efef8f; } /* Other */
code span.pp { color: #ffcfaf; font-weight: bold; } /* Preprocessor */
code span.sc { color: #dca3a3; } /* SpecialChar */
code span.ss { color: #cc9393; } /* SpecialString */
code span.st { color: #cc9393; } /* String */
code span.va { } /* Variable */
code span.vs { color: #cc9393; } /* VerbatimString */
code span.wa { color: #7f9f7f; font-weight: bold; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i><b>2</b> Preface</a><ul>
<li class="chapter" data-level="2.1" data-path="the-original-story.html"><a href="the-original-story.html"><i class="fa fa-check"></i><b>2.1</b> The original story</a></li>
<li class="chapter" data-level="2.2" data-path="what-it-does.html"><a href="what-it-does.html"><i class="fa fa-check"></i><b>2.2</b> What it does</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="our-data.html"><a href="our-data.html"><i class="fa fa-check"></i><b>3</b> Our data</a><ul>
<li class="chapter" data-level="3.1" data-path="data-foia-requests.html"><a href="data-foia-requests.html"><i class="fa fa-check"></i><b>3.1</b> Data: FOIA Requests</a></li>
<li class="chapter" data-level="3.2" data-path="success-metrics-editorial-choice.html"><a href="success-metrics-editorial-choice.html"><i class="fa fa-check"></i><b>3.2</b> Success metrics (editorial choice)</a></li>
<li class="chapter" data-level="3.3" data-path="features-editorial-choice.html"><a href="features-editorial-choice.html"><i class="fa fa-check"></i><b>3.3</b> Features (editorial choice)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="analysis.html"><a href="analysis.html"><i class="fa fa-check"></i><b>4</b> Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="designing-our-model.html"><a href="designing-our-model.html"><i class="fa fa-check"></i><b>4.1</b> Designing our model</a><ul>
<li class="chapter" data-level="4.1.1" data-path="designing-our-model.html"><a href="designing-our-model.html#classification-problems"><i class="fa fa-check"></i><b>4.1.1</b> Classification problems</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="selecting-an-algorithm.html"><a href="selecting-an-algorithm.html"><i class="fa fa-check"></i><b>4.2</b> Selecting an algorithm</a></li>
<li class="chapter" data-level="4.3" data-path="training-our-algorithm.html"><a href="training-our-algorithm.html"><i class="fa fa-check"></i><b>4.3</b> Training our algorithm</a></li>
<li class="chapter" data-level="4.4" data-path="evaluation-metrics.html"><a href="evaluation-metrics.html"><i class="fa fa-check"></i><b>4.4</b> Evaluation metrics</a><ul>
<li class="chapter" data-level="4.4.1" data-path="evaluation-metrics.html"><a href="evaluation-metrics.html#accuracy"><i class="fa fa-check"></i><b>4.4.1</b> Accuracy</a></li>
<li class="chapter" data-level="4.4.2" data-path="evaluation-metrics.html"><a href="evaluation-metrics.html#dummy-classifier"><i class="fa fa-check"></i><b>4.4.2</b> Dummy classifier</a></li>
<li class="chapter" data-level="4.4.3" data-path="evaluation-metrics.html"><a href="evaluation-metrics.html#confusion-matrix"><i class="fa fa-check"></i><b>4.4.3</b> Confusion matrix</a></li>
<li class="chapter" data-level="4.4.4" data-path="evaluation-metrics.html"><a href="evaluation-metrics.html#explainability"><i class="fa fa-check"></i><b>4.4.4</b> Explainability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="other-classifiers.html"><a href="other-classifiers.html"><i class="fa fa-check"></i><b>5</b> Other classifiers</a><ul>
<li class="chapter" data-level="5.1" data-path="logisic-regression.html"><a href="logisic-regression.html"><i class="fa fa-check"></i><b>5.1</b> Logisic Regression</a></li>
<li class="chapter" data-level="5.2" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>5.2</b> Decision Trees</a></li>
<li class="chapter" data-level="5.3" data-path="random-forest.html"><a href="random-forest.html"><i class="fa fa-check"></i><b>5.3</b> Random Forest</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="feature-selection-and-engineering.html"><a href="feature-selection-and-engineering.html"><i class="fa fa-check"></i><b>6</b> Feature selection and engineering</a><ul>
<li class="chapter" data-level="6.1" data-path="leaving-out-our-best-feature.html"><a href="leaving-out-our-best-feature.html"><i class="fa fa-check"></i><b>6.1</b> Leaving out our best feature</a><ul>
<li class="chapter" data-level="6.1.1" data-path="leaving-out-our-best-feature.html"><a href="leaving-out-our-best-feature.html#setting-up-our-features"><i class="fa fa-check"></i><b>6.1.1</b> Setting up our features</a></li>
<li class="chapter" data-level="6.1.2" data-path="leaving-out-our-best-feature.html"><a href="leaving-out-our-best-feature.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>6.1.2</b> K-nearest neighbors</a></li>
<li class="chapter" data-level="6.1.3" data-path="leaving-out-our-best-feature.html"><a href="leaving-out-our-best-feature.html#logistic-regression"><i class="fa fa-check"></i><b>6.1.3</b> Logistic Regression</a></li>
<li class="chapter" data-level="6.1.4" data-path="leaving-out-our-best-feature.html"><a href="leaving-out-our-best-feature.html#decision-tree"><i class="fa fa-check"></i><b>6.1.4</b> Decision tree</a></li>
<li class="chapter" data-level="6.1.5" data-path="leaving-out-our-best-feature.html"><a href="leaving-out-our-best-feature.html#random-forest-1"><i class="fa fa-check"></i><b>6.1.5</b> Random forest</a></li>
<li class="chapter" data-level="6.1.6" data-path="leaving-out-our-best-feature.html"><a href="leaving-out-our-best-feature.html#summary"><i class="fa fa-check"></i><b>6.1.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="explaining-predictions.html"><a href="explaining-predictions.html"><i class="fa fa-check"></i><b>7</b> Explaining predictions</a></li>
<li class="chapter" data-level="8" data-path="percent-probability.html"><a href="percent-probability.html"><i class="fa fa-check"></i><b>8</b> Percent probability</a></li>
<li class="chapter" data-level="9" data-path="review.html"><a href="review.html"><i class="fa fa-check"></i><b>9</b> Review</a></li>
<li class="chapter" data-level="10" data-path="discussion-topics.html"><a href="discussion-topics.html"><i class="fa fa-check"></i><b>10</b> Discussion topics</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="evaluation-metrics" class="section level2">
<h2><span class="header-section-number">4.4</span> Evaluation metrics</h2>
<p>When you’ve put together a machine learning algorithm, you need some way to test its performance. This is called an <strong>evaluation metric</strong>. It seems like it would be as easy as your teacher scoring a test, but it gets more complicated pretty quickly.</p>
<div id="accuracy" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Accuracy</h3>
<p>The most basic way we can judge its performance is to ask: what percent did you predict correctly? We’ll check by comparing the right answers to what the classifier predicted.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="evaluation-metrics.html#cb12-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb12-2"><a href="evaluation-metrics.html#cb12-2"></a></span>
<span id="cb12-3"><a href="evaluation-metrics.html#cb12-3"></a>accuracy_score(y_test, y_pred)</span></code></pre></div>
<pre><code>## 0.7484608619173263</code></pre>
<p>Around 75% percent, not so bad!</p>
<p><strong>Unfortunately, there’s a little issue with accuracy that makes it almost useless as a metric.</strong></p>
<p>Important question: How often is a request denied, and how often is it accepted?</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="evaluation-metrics.html#cb14-1"></a>df.successful.value_counts()</span></code></pre></div>
<pre><code>## 0    6345
## 1    2749
## Name: successful, dtype: int64</code></pre>
<p>6,345 denied requests, 2,749 requests fulfilled. If we take one more step convert that to percentages, our crisis might be a little more clear.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="evaluation-metrics.html#cb16-1"></a>df.successful.value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<pre><code>## 0    0.697713
## 1    0.302287
## Name: successful, dtype: float64</code></pre>
<p>Yes, we have around 70% denied. So what? We didn’t think it was a bad split before - 30% success rate, not so tough.</p>
<p>Here’s the problem: <strong>if our classifier just guessed “it’s gonna get rejected” every single time, we’d be 70% accurate!</strong></p>
<p>Even though we’d be throwing out <em>every single successful request</em>, it wouldn’t matter. <strong>If we’re accuracy as our evaluation metric, it doesn’t matter <em>what</em> we got right and <em>what</em> we got wrong, it only counts the number of correct predictions.</strong></p>
</div>
<div id="dummy-classifier" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Dummy classifier</h3>
<p>You can also do this with code, too, using a hilarious classifier called a <code>DummyClassifier</code>. It isn’t a real classifier, but you can tell it to just guess the most popular thing! The code works just like a ‘normal’ classifier, which I find incredibly amusing.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="evaluation-metrics.html#cb18-1"></a><span class="im">from</span> sklearn.dummy <span class="im">import</span> DummyClassifier</span>
<span id="cb18-2"><a href="evaluation-metrics.html#cb18-2"></a></span>
<span id="cb18-3"><a href="evaluation-metrics.html#cb18-3"></a>dummy <span class="op">=</span> DummyClassifier(strategy<span class="op">=</span><span class="st">&#39;most_frequent&#39;</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb18-4"><a href="evaluation-metrics.html#cb18-4"></a>dummy.fit(X_train, y_train)</span></code></pre></div>
<pre><code>## DummyClassifier(constant=None, random_state=42, strategy=&#39;most_frequent&#39;)</code></pre>
<p>So let’s say we use the dummy classifier. How does it do just guessing the most popular thing, no machine learning in sight?</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="evaluation-metrics.html#cb20-1"></a>accuracy_score(y_test, dummy.predict(X_test))</span></code></pre></div>
<pre><code>## 0.7036059806508356</code></pre>
<p>Just like we predicted, right around 70%. Not feeling so good about our 75%ish performance now, are we?</p>
</div>
<div id="confusion-matrix" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Confusion matrix</h3>
<p>It’s turned out that what we’re interested in isn’t just “did you get it right?” What we’re interested in is somehow looking at acceptances and denials and making sure we didn’t just throw everything into one bucket or the other.</p>
<p>To look at how we peformed on different aspects of our classification ask, we can use a <strong>confusion matrix</strong>. Let’s see how our k-nearest neighbors classifier performed.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="evaluation-metrics.html#cb22-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb22-2"><a href="evaluation-metrics.html#cb22-2"></a></span>
<span id="cb22-3"><a href="evaluation-metrics.html#cb22-3"></a>y_true <span class="op">=</span> y_test</span>
<span id="cb22-4"><a href="evaluation-metrics.html#cb22-4"></a>y_pred <span class="op">=</span> knn.predict(X_test)</span>
<span id="cb22-5"><a href="evaluation-metrics.html#cb22-5"></a>matrix <span class="op">=</span> confusion_matrix(y_true, y_pred)</span>
<span id="cb22-6"><a href="evaluation-metrics.html#cb22-6"></a></span>
<span id="cb22-7"><a href="evaluation-metrics.html#cb22-7"></a>label_names <span class="op">=</span> pd.Series([<span class="st">&#39;unsuccessful&#39;</span>, <span class="st">&#39;successful&#39;</span>])</span>
<span id="cb22-8"><a href="evaluation-metrics.html#cb22-8"></a>pd.DataFrame(matrix,</span>
<span id="cb22-9"><a href="evaluation-metrics.html#cb22-9"></a>     columns<span class="op">=</span><span class="st">&#39;Predicted &#39;</span> <span class="op">+</span> label_names,</span>
<span id="cb22-10"><a href="evaluation-metrics.html#cb22-10"></a>     index<span class="op">=</span><span class="st">&#39;Is &#39;</span> <span class="op">+</span> label_names)</span></code></pre></div>
<div class='table-wrapper'>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Predicted unsuccessful
</th>
<th style="text-align:right;">
Predicted successful
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Is unsuccessful
</td>
<td style="text-align:right;">
1506
</td>
<td style="text-align:right;">
94
</td>
</tr>
<tr>
<td style="text-align:left;">
Is successful
</td>
<td style="text-align:right;">
478
</td>
<td style="text-align:right;">
196
</td>
</tr>
</tbody>
</table>
</div>
<p>A confusion matrix can put into context where we’re making our mistakes.</p>
<p>And here’s the confusion matrix for the dummy classifier.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="evaluation-metrics.html#cb23-1"></a>y_true <span class="op">=</span> y_test</span>
<span id="cb23-2"><a href="evaluation-metrics.html#cb23-2"></a>y_pred <span class="op">=</span> dummy.predict(X_test)</span>
<span id="cb23-3"><a href="evaluation-metrics.html#cb23-3"></a>matrix <span class="op">=</span> confusion_matrix(y_true, y_pred)</span>
<span id="cb23-4"><a href="evaluation-metrics.html#cb23-4"></a></span>
<span id="cb23-5"><a href="evaluation-metrics.html#cb23-5"></a>label_names <span class="op">=</span> pd.Series([<span class="st">&#39;unsuccessful&#39;</span>, <span class="st">&#39;successful&#39;</span>])</span>
<span id="cb23-6"><a href="evaluation-metrics.html#cb23-6"></a>pd.DataFrame(matrix,</span>
<span id="cb23-7"><a href="evaluation-metrics.html#cb23-7"></a>     columns<span class="op">=</span><span class="st">&#39;Predicted &#39;</span> <span class="op">+</span> label_names,</span>
<span id="cb23-8"><a href="evaluation-metrics.html#cb23-8"></a>     index<span class="op">=</span><span class="st">&#39;Is &#39;</span> <span class="op">+</span> label_names)</span></code></pre></div>
<div class='table-wrapper'>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Predicted unsuccessful
</th>
<th style="text-align:right;">
Predicted successful
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Is unsuccessful
</td>
<td style="text-align:right;">
1600
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
Is successful
</td>
<td style="text-align:right;">
674
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
</div>
<p>Unlike the accuracy score, we have a <strong>clear distinction between the two!</strong> It’s easy to see that the dummy classifier doesn’t predict anything as successful, while the k-nearest neighbors classifier is a bit more mixed.</p>
<p>A confusion matrix is a great way to see how your classifier performs across your classes separately. Successful, unsuccessful, all broken out. It’s really really easy to see how different they are when viewed this way.</p>
<p>Each one of those boxes has a name.</p>
<table>
<thead>
<tr class="header">
<th>term</th>
<th>meaning</th>
<th>where</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>True Positive</td>
<td>is successful, predicted successful</td>
<td>top left</td>
</tr>
<tr class="even">
<td>False Negative</td>
<td>is successful, predicted unsuccessful</td>
<td>top right</td>
</tr>
<tr class="odd">
<td>False Positive</td>
<td>is unsuccessful, predicted successful</td>
<td>bottom left</td>
</tr>
<tr class="even">
<td>True Negative</td>
<td>is unsuccessful, predicted unsuccessful</td>
<td>bottom right</td>
</tr>
</tbody>
</table>
<p>If we’re being frank, though: <strong>I really dislike using those names.</strong> I can barely remember which is which, and I think using sterile names like that makes you forget what you’re actually working on.</p>
<p>For example, “minimize false negatives.” In normal words, you might say someting like “be really sure someone’s reject is going to be rejected before you tell them that, because they might not submit it.” I think keeping the language related to the topic helps us understand what we’re really doing, and what impact we’re really having.</p>
<p>But either way, our K-Nearest Neighbors seems to be working pretty well. Or at least, it goes a bit better than always guessing ‘denied.’</p>
</div>
<div id="explainability" class="section level3">
<h3><span class="header-section-number">4.4.4</span> Explainability</h3>
<p>Hand-in-hand with performance is the idea of <strong>explainability</strong>. Why did our algorithm give the result it did? Imagine how uncomfortable it would be dealing with a person who could never explain their reasoning behind their decisions!</p>
<p>One problem of the K-Nearest Neighbors algorithm is that it’s kind of difficult to explain what’s going on, or why we received a certain result. In <em>theory</em> it’s easy - “we’re taking the 20 most similar FOIA requests and picking whether they were fufilled or not” - but it’s difficult to point out exactly which columns are the important ones, or give feedback on how we might need to improve your FOIA request.</p>
<p>Maybe it’s time to look at some alternatives? As we mentioned before, there are more classification algorithms than just K-Nearest Neighbors. A few examples are logistic regression classifiers, decision trees, and random forests.</p>
<p>While there is a lot of potential math and tests for suitability between your dataset and what kind of algorithm <em>should</em> work best, at the end of the day the only thing that really matters is which one <em>does</em> work best. To figure it out… you just try all of the different algorithms and compare the results!</p>
</div>
</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="training-our-algorithm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="other-classifiers.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 1
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

</body>

</html>
